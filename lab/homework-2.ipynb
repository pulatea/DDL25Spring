{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ae6b03df",
   "metadata": {},
   "source": [
    "# Homework - Vertical FL and Generative Modeling\n",
    "Vertical federated learning (VFL) and generative modeling are two techniques for privacy preservation. The former enables collaborative training across vertically partitioned data. At the same time, the latter creates synthetic data as an alternative to using real sensitive data. In this assignment, you'll further explore some factors affecting model performance in VFL and how it can be bridged with generative modeling. \n",
    "\n",
    "# Instructions\n",
    "\n",
    "Submit your assignment in ILIAS as only the Jupyter notebook with all relevant execution outputs and plots visible. Clearly indicate the relevant steps in your code, such as data preprocessing, model definition, training, etc. Partial grades can be given for incomplete problems provided the steps are clearly indicated.\n",
    "\n",
    "## Exercise 1: Feature permutation in VFL (4 points)\n",
    "\n",
    "Using the template code from [lab_vfl.ipynb](https://github.com/lydiaYchen/DDL25Spring/blob/main/lab/tutorial_2b/lab-vfl.ipynb), experiment with how shuffling the order of feature assignments to clients affects the performance. Use 4 clients with the default hyperparameters. Experiment with **3** random feature permutations and plot the training loss. Report whether/how shuffling features significantly affects the convergence rates and the reasoning behind it.\n",
    "\n",
    "Scoring:\n",
    "- _(1 point)_ Create 5 feature permutations with seeded Python/NumPy random functions and run them through the discriminative VFL model.\n",
    "- _(1 point)_ Log the losses over time of the training runs and compile them into one plot.\n",
    "- _(2 points)_ Describe what impact (if any) the permutations have on the loss and explain the observed pattern.\n",
    "\n",
    "## Exercise 2: Scaling clients in VFL (5 points)\n",
    "\n",
    "With the same template as above, experiment with how increasing the number of clients affects model performance. Explain the policy chosen for distributing features for different numbers of clients.\n",
    "\n",
    "Scoring:\n",
    "- _(1 point)_ Explain your scheme for partitioning the feature space under increasing number of clients.\n",
    "- _(1 point)_ Implement the above explained partition mechanism for the requested client counts for the discriminative VFL model.\n",
    "- _(1 point)_ Log the losses over time of the training runs and compile them into one plot.\n",
    "- _(2 points)_ State what impact (if any) adding more clients has on the loss and explain the observed pattern.\n",
    "\n",
    "## Exercise 3: Bridging VFL and generative modeling (10 points)\n",
    "\n",
    "In this exercise, you'll explore how synthetic data can be generated when the data is constrained to be vertically partitioned. Combine VFL with variational autoencoders (VAEs) using the architecture described as follows. Each client uses a local encoder, i.e., a multi-layer perceptron (MLP) to embed its sensitive features into latents. These latents are concatenated at the server and passed through a VAE. The VAE produces synthetic latents which are partitioned and then converted back into the actual input space using another local MLP (decoder) at each client. Show the model's training progress per epoch. \n",
    "\n",
    "Scoring:\n",
    "- _(1 point)_ Preprocess the dataset and partition the features.\n",
    "- _(2 points)_ Define the encoder and decoder MLPs held by each.\n",
    "- _(2 points)_ Define the VAE used at the server over the concatenated feature representations from the clients.\n",
    "- _(2 points)_ Define the VFL network that fits together the client networks and that of the server.\n",
    "- _(1 point)_ Create and run the training loop of the complete model, printing the loss at every epoch.\n",
    "- _(0.5 points)_ Consider, without implementing, an alternative scheme wherein the MLPs are first locally trained at the clients, followed by a separate training loop for the VAE at the server. How does this change what should be provided as input to the server?\n",
    "- _(1.5 points)_ What are the pros and cons of the above mentioned alternative compared to the one implemented? Focus on the following aspects: privacy, communication costs, and performance.\n",
    "\n",
    "### For any questions regarding this assignment, send an email to a.shankar@tudelft.nl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5312bf5-6e6d-4bba-bccd-44f4efe6bdab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
