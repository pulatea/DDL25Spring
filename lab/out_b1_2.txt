WE HAVE TOKENIZER
loaded tokenizer
<sentencepiece.SentencePieceProcessor; proxy of <Swig Object of type 'sentencepiece::SentencePieceProcessor *' at 0x3117ac990> >
DONE
WE HAVE TOKENIZER
loaded tokenizer
<sentencepiece.SentencePieceProcessor; proxy of <Swig Object of type 'sentencepiece::SentencePieceProcessor *' at 0x3117aca50> >
DONE
TINYSTORIES DATASET LOADED...
Rank 2 | Iteration 0 | Training in Progress...
Iteration 0, Loss: 10.517070770263672
Iteration 1, Loss: 9.766342163085938
Iteration 2, Loss: 9.567436218261719
Iteration 3, Loss: 9.37014389038086
Iteration 4, Loss: 9.193830490112305
Iteration 5, Loss: 8.856544494628906
Iteration 6, Loss: 8.670781135559082
Iteration 7, Loss: 8.735679626464844
Iteration 8, Loss: 8.150790214538574
Iteration 9, Loss: 7.861904144287109
Iteration 10, Loss: 7.810094833374023
Iteration 11, Loss: 7.519920825958252
Iteration 12, Loss: 7.50683069229126
Iteration 13, Loss: 6.840742588043213
Iteration 14, Loss: 6.969614028930664
Iteration 15, Loss: 6.90114164352417
Iteration 16, Loss: 7.104297637939453
Iteration 17, Loss: 6.946547985076904
Iteration 18, Loss: 6.865747928619385
Iteration 19, Loss: 6.384466171264648
Iteration 20, Loss: 6.472582817077637
Iteration 21, Loss: 6.3583149909973145
Iteration 22, Loss: 6.506499767303467
Iteration 23, Loss: 6.700385570526123
Iteration 24, Loss: 6.58329439163208
Iteration 25, Loss: 6.380946159362793
Iteration 26, Loss: 6.169789791107178
Iteration 27, Loss: 6.706486225128174
Iteration 28, Loss: 6.477933883666992
Iteration 29, Loss: 6.194549083709717
Iteration 30, Loss: 6.371636390686035
Iteration 31, Loss: 6.44946813583374
Iteration 32, Loss: 6.7428998947143555
Iteration 33, Loss: 6.354372024536133
Iteration 34, Loss: 6.597029209136963
Iteration 35, Loss: 6.528505802154541
Iteration 36, Loss: 6.640676975250244
Iteration 37, Loss: 6.260455131530762
Iteration 38, Loss: 6.174992084503174
Iteration 39, Loss: 6.195402145385742
Iteration 40, Loss: 6.32167387008667
Iteration 41, Loss: 5.970532417297363
Iteration 42, Loss: 6.356695175170898
Iteration 43, Loss: 6.8663716316223145
Iteration 44, Loss: 6.453125953674316
Iteration 45, Loss: 6.258249282836914
Iteration 46, Loss: 6.5277814865112305
Iteration 47, Loss: 6.897445201873779
Iteration 48, Loss: 6.378800392150879
Iteration 49, Loss: 6.464775085449219
Iteration 50, Loss: 6.171427249908447
Iteration 51, Loss: 6.297352313995361
Iteration 52, Loss: 6.211401462554932
Iteration 53, Loss: 6.419883728027344
Iteration 54, Loss: 6.753532886505127
Iteration 55, Loss: 6.455416202545166
Iteration 56, Loss: 6.177093982696533
Iteration 57, Loss: 5.725956439971924
Iteration 58, Loss: 6.193458080291748
Iteration 59, Loss: 6.282688140869141
Iteration 60, Loss: 6.347072601318359
Iteration 61, Loss: 6.144671440124512
Iteration 62, Loss: 6.357817649841309
Iteration 63, Loss: 6.230159759521484
Iteration 64, Loss: 6.614536762237549
Iteration 65, Loss: 6.333005428314209
Iteration 66, Loss: 6.392220973968506
Iteration 67, Loss: 6.048014163970947
Iteration 68, Loss: 6.308541774749756
Iteration 69, Loss: 6.300075054168701
Iteration 70, Loss: 6.082089424133301
Iteration 71, Loss: 6.261649131774902
Iteration 72, Loss: 6.813806533813477
Iteration 73, Loss: 6.913694381713867
Iteration 74, Loss: 6.216503143310547
Iteration 75, Loss: 6.2594895362854
Iteration 76, Loss: 6.241232872009277
Iteration 77, Loss: 6.544697284698486
Iteration 78, Loss: 6.533957481384277
Iteration 79, Loss: 5.9807562828063965
Iteration 80, Loss: 6.201085567474365
Iteration 81, Loss: 6.164574146270752
Iteration 82, Loss: 6.002673149108887
Iteration 83, Loss: 6.056978225708008
Iteration 84, Loss: 5.783742427825928
Iteration 85, Loss: 5.831954002380371
Iteration 86, Loss: 6.231345176696777
Iteration 87, Loss: 6.088032245635986
Iteration 88, Loss: 6.580190658569336
Iteration 89, Loss: 6.403349876403809
Iteration 90, Loss: 6.58036470413208
Iteration 91, Loss: 6.2395853996276855
Iteration 92, Loss: 5.978331565856934
Iteration 93, Loss: 6.593795299530029
Iteration 94, Loss: 5.78893518447876
Iteration 95, Loss: 6.2873215675354
Iteration 96, Loss: 6.447025299072266
Iteration 97, Loss: 6.330716133117676
Iteration 98, Loss: 6.0917067527771
Iteration 99, Loss: 6.280430316925049
Rank 2 | Iteration 100 | Training in Progress...
Iteration 100, Loss: 6.189723968505859
Iteration 101, Loss: 6.183673858642578
Iteration 102, Loss: 6.123537540435791
Iteration 103, Loss: 6.009079933166504
Iteration 104, Loss: 6.367794036865234
Iteration 105, Loss: 6.476871967315674
Iteration 106, Loss: 5.737303256988525
Iteration 107, Loss: 6.248892307281494
Iteration 108, Loss: 5.852479457855225
Iteration 109, Loss: 5.8778181076049805
Iteration 110, Loss: 6.392646312713623
Iteration 111, Loss: 6.315919876098633
Iteration 112, Loss: 6.319639682769775
Iteration 113, Loss: 6.118048667907715
Iteration 114, Loss: 6.1552910804748535
Iteration 115, Loss: 6.4561967849731445
Iteration 116, Loss: 5.9186015129089355
Iteration 117, Loss: 5.906007289886475
Iteration 118, Loss: 6.121876239776611
Iteration 119, Loss: 6.314688682556152
Iteration 120, Loss: 6.4207072257995605
Iteration 121, Loss: 6.208920478820801
Iteration 122, Loss: 5.869805812835693
Iteration 123, Loss: 5.930850505828857
Iteration 124, Loss: 6.5062127113342285
Iteration 125, Loss: 5.968193054199219
Iteration 126, Loss: 5.988587379455566
Iteration 127, Loss: 6.269638538360596
Iteration 128, Loss: 6.050008296966553
Iteration 129, Loss: 5.851423740386963
Iteration 130, Loss: 5.99786901473999
Iteration 131, Loss: 6.252279281616211
Iteration 132, Loss: 6.321905136108398
Iteration 133, Loss: 6.325459957122803
Iteration 134, Loss: 6.459496021270752
Iteration 135, Loss: 6.015191555023193
Iteration 136, Loss: 5.857571125030518
Iteration 137, Loss: 5.841799259185791
Iteration 138, Loss: 5.98057746887207
Iteration 139, Loss: 5.83950662612915
Iteration 140, Loss: 6.502293109893799
Iteration 141, Loss: 6.019139289855957
Iteration 142, Loss: 6.274428844451904
Iteration 143, Loss: 6.038442134857178
Iteration 144, Loss: 6.019039630889893
Iteration 145, Loss: 5.758343696594238
Iteration 146, Loss: 5.783035755157471
Iteration 147, Loss: 6.638206481933594
Iteration 148, Loss: 6.099034786224365
Iteration 149, Loss: 6.303379535675049
Iteration 150, Loss: 6.438015937805176
Iteration 151, Loss: 6.111018657684326
Iteration 152, Loss: 6.214846134185791
Iteration 153, Loss: 6.5250678062438965
Iteration 154, Loss: 5.943103313446045
Iteration 155, Loss: 5.955291271209717
Iteration 156, Loss: 6.21826171875
Iteration 157, Loss: 6.236577033996582
Iteration 158, Loss: 6.4042863845825195
Iteration 159, Loss: 6.166082859039307
Iteration 160, Loss: 6.203160285949707
Iteration 161, Loss: 6.198672771453857
Iteration 162, Loss: 6.544047832489014
Iteration 163, Loss: 6.086617469787598
Iteration 164, Loss: 6.415768146514893
Iteration 165, Loss: 5.763273239135742
Iteration 166, Loss: 5.814241409301758
Iteration 167, Loss: 6.536142349243164
Iteration 168, Loss: 5.956805229187012
Iteration 169, Loss: 6.0434980392456055
Iteration 170, Loss: 6.016866683959961
Iteration 171, Loss: 6.073861122131348
Iteration 172, Loss: 6.213178634643555
Iteration 173, Loss: 6.134441375732422
Iteration 174, Loss: 5.647853374481201
Iteration 175, Loss: 6.5101542472839355
Iteration 176, Loss: 6.272424697875977
Iteration 177, Loss: 6.168351173400879
Iteration 178, Loss: 6.339561462402344
Iteration 179, Loss: 6.176748752593994
Iteration 180, Loss: 6.502913951873779
Iteration 181, Loss: 6.193271160125732
Iteration 182, Loss: 6.29712438583374
Iteration 183, Loss: 6.466666221618652
Iteration 184, Loss: 5.999105930328369
Iteration 185, Loss: 5.896410942077637
Iteration 186, Loss: 5.85640287399292
Iteration 187, Loss: 5.950669288635254
Iteration 188, Loss: 6.287057399749756
Iteration 189, Loss: 6.008438587188721
Iteration 190, Loss: 6.655806064605713
Iteration 191, Loss: 6.430604934692383
Iteration 192, Loss: 6.261446475982666
Iteration 193, Loss: 6.494688034057617
Iteration 194, Loss: 6.2210774421691895
Iteration 195, Loss: 6.114718914031982
Iteration 196, Loss: 5.976346969604492
Iteration 197, Loss: 5.851840496063232
Iteration 198, Loss: 6.034770488739014
Iteration 199, Loss: 5.9855780601501465
Rank 2 | Iteration 200 | Training in Progress...
Iteration 200, Loss: 6.195559978485107
Iteration 201, Loss: 6.210136413574219
Iteration 202, Loss: 6.131600379943848
Iteration 203, Loss: 6.205077171325684
Iteration 204, Loss: 6.061618328094482
Iteration 205, Loss: 5.987171649932861
Iteration 206, Loss: 6.195202350616455
Iteration 207, Loss: 6.692109107971191
Iteration 208, Loss: 6.428167343139648
Iteration 209, Loss: 6.0452070236206055
Iteration 210, Loss: 5.836343288421631
Iteration 211, Loss: 6.356545448303223
Iteration 212, Loss: 5.753513336181641
Iteration 213, Loss: 6.215822696685791
Iteration 214, Loss: 6.413607120513916
Iteration 215, Loss: 5.773096561431885
Iteration 216, Loss: 6.085668563842773
Iteration 217, Loss: 6.181406497955322
Iteration 218, Loss: 6.224057674407959
Iteration 219, Loss: 6.672626972198486
Iteration 220, Loss: 6.293451309204102
Iteration 221, Loss: 6.166920185089111
Iteration 222, Loss: 5.809041976928711
Iteration 223, Loss: 6.073764801025391
Iteration 224, Loss: 6.004570960998535
Iteration 225, Loss: 5.713505268096924
Iteration 226, Loss: 6.293727397918701
Iteration 227, Loss: 6.434718132019043
Iteration 228, Loss: 6.022365093231201
Iteration 229, Loss: 5.724662780761719
Iteration 230, Loss: 6.150793075561523
Iteration 231, Loss: 6.1315436363220215
Iteration 232, Loss: 6.158326625823975
Iteration 233, Loss: 6.350100994110107
Iteration 234, Loss: 6.2170939445495605
Iteration 235, Loss: 6.2095184326171875
Iteration 236, Loss: 6.294487476348877
Iteration 237, Loss: 6.481415748596191
Iteration 238, Loss: 5.781054973602295
Iteration 239, Loss: 6.392026901245117
Iteration 240, Loss: 6.329200267791748
Iteration 241, Loss: 6.756977558135986
Iteration 242, Loss: 6.394819259643555
Iteration 243, Loss: 6.485305309295654
Iteration 244, Loss: 6.65383243560791
Iteration 245, Loss: 6.248563766479492
Iteration 246, Loss: 6.280276775360107
Iteration 247, Loss: 6.007565021514893
Iteration 248, Loss: 5.892704486846924
Iteration 249, Loss: 6.3460373878479
Iteration 250, Loss: 6.404184341430664
Iteration 251, Loss: 6.4478912353515625
Iteration 252, Loss: 5.933322906494141
Iteration 253, Loss: 5.953952312469482
Iteration 254, Loss: 6.559319972991943
Iteration 255, Loss: 6.261173248291016
Iteration 256, Loss: 5.832497596740723
Iteration 257, Loss: 6.365206241607666
Iteration 258, Loss: 6.263343334197998
Iteration 259, Loss: 6.011845111846924
Iteration 260, Loss: 5.603927135467529
Iteration 261, Loss: 6.550541400909424
Iteration 262, Loss: 6.335799217224121
Iteration 263, Loss: 6.093575477600098
Iteration 264, Loss: 6.527022838592529
Iteration 265, Loss: 5.696434497833252
Iteration 266, Loss: 6.156771659851074
Iteration 267, Loss: 5.77017879486084
Iteration 268, Loss: 6.377096652984619
Iteration 269, Loss: 5.769476413726807
Iteration 270, Loss: 6.0454206466674805
Iteration 271, Loss: 6.313656806945801
Iteration 272, Loss: 6.310124397277832
Iteration 273, Loss: 6.524238586425781
Iteration 274, Loss: 6.171539783477783
Iteration 275, Loss: 6.1019392013549805
Iteration 276, Loss: 6.259882926940918
Iteration 277, Loss: 6.075921535491943
Iteration 278, Loss: 6.096161842346191
Iteration 279, Loss: 5.93084192276001
Iteration 280, Loss: 6.096580505371094
Iteration 281, Loss: 6.247330665588379
Iteration 282, Loss: 6.067206382751465
Iteration 283, Loss: 6.342056751251221
Iteration 284, Loss: 5.936751365661621
Iteration 285, Loss: 6.187074661254883
Iteration 286, Loss: 6.193044662475586
Iteration 287, Loss: 6.330240726470947
Iteration 288, Loss: 6.428921222686768
Iteration 289, Loss: 6.2795257568359375
Iteration 290, Loss: 6.347137451171875
Iteration 291, Loss: 5.961333751678467
Iteration 292, Loss: 6.01685905456543
Iteration 293, Loss: 6.175533771514893
Iteration 294, Loss: 6.170502185821533
Iteration 295, Loss: 6.210885524749756
Iteration 296, Loss: 6.374589443206787
Iteration 297, Loss: 6.085445880889893
Iteration 298, Loss: 6.098010063171387
Iteration 299, Loss: 6.231123924255371
Rank 2 | Iteration 300 | Training in Progress...
Iteration 300, Loss: 6.006682395935059
Iteration 301, Loss: 6.4586052894592285
Iteration 302, Loss: 6.1020050048828125
Iteration 303, Loss: 6.167654991149902
Iteration 304, Loss: 6.266933441162109
Iteration 305, Loss: 6.0464043617248535
Iteration 306, Loss: 6.403117656707764
Iteration 307, Loss: 6.411831378936768
Iteration 308, Loss: 6.320435047149658
Iteration 309, Loss: 5.662113189697266
Iteration 310, Loss: 6.394607067108154
Iteration 311, Loss: 6.078348159790039
Iteration 312, Loss: 5.737342357635498
Iteration 313, Loss: 6.124917030334473
Iteration 314, Loss: 6.223012447357178
Iteration 315, Loss: 6.090747356414795
Iteration 316, Loss: 5.979638576507568
Iteration 317, Loss: 6.190306186676025
Iteration 318, Loss: 6.578710556030273
Iteration 319, Loss: 6.169488906860352
Iteration 320, Loss: 6.459021091461182
Iteration 321, Loss: 6.266193389892578
Iteration 322, Loss: 6.148094654083252
Iteration 323, Loss: 5.7783098220825195
Iteration 324, Loss: 5.954400062561035
Iteration 325, Loss: 6.287250995635986
Iteration 326, Loss: 5.903706073760986
Iteration 327, Loss: 5.905008792877197
Iteration 328, Loss: 6.3256707191467285
Iteration 329, Loss: 5.839988708496094
Iteration 330, Loss: 5.7894287109375
Iteration 331, Loss: 6.442703723907471
Iteration 332, Loss: 6.259027481079102
Iteration 333, Loss: 6.460538864135742
Iteration 334, Loss: 6.1704864501953125
Iteration 335, Loss: 5.955748558044434
Iteration 336, Loss: 6.436401844024658
Iteration 337, Loss: 6.072643280029297
Iteration 338, Loss: 5.631802558898926
Iteration 339, Loss: 6.1004252433776855
Iteration 340, Loss: 5.949379920959473
Iteration 341, Loss: 6.060361385345459
Iteration 342, Loss: 6.592837333679199
Iteration 343, Loss: 5.832448482513428
Iteration 344, Loss: 6.641312122344971
Iteration 345, Loss: 5.9068522453308105
Iteration 346, Loss: 6.436764240264893
Iteration 347, Loss: 6.093374252319336
Iteration 348, Loss: 6.187283039093018
Iteration 349, Loss: 6.013579368591309
Iteration 350, Loss: 5.8362135887146
Iteration 351, Loss: 6.057219982147217
Iteration 352, Loss: 6.1060991287231445
Iteration 353, Loss: 6.09285306930542
Iteration 354, Loss: 6.267123222351074
Iteration 355, Loss: 6.113471508026123
Iteration 356, Loss: 5.893341541290283
Iteration 357, Loss: 6.00838041305542
Iteration 358, Loss: 6.061019420623779
Iteration 359, Loss: 5.853819847106934
Iteration 360, Loss: 6.299810886383057
Iteration 361, Loss: 6.06464958190918
Iteration 362, Loss: 6.00352144241333
Iteration 363, Loss: 6.736730575561523
Iteration 364, Loss: 6.387269020080566
Iteration 365, Loss: 6.002392292022705
Iteration 366, Loss: 6.227308750152588
Iteration 367, Loss: 6.422603130340576
Iteration 368, Loss: 6.3216962814331055
Iteration 369, Loss: 6.220306873321533
Iteration 370, Loss: 5.828208923339844
Iteration 371, Loss: 5.977749824523926
Iteration 372, Loss: 6.172276020050049
Iteration 373, Loss: 6.084075450897217
Iteration 374, Loss: 6.060510635375977
Iteration 375, Loss: 6.236863613128662
Iteration 376, Loss: 6.060253143310547
Iteration 377, Loss: 6.103163719177246
Iteration 378, Loss: 5.918341636657715
Iteration 379, Loss: 6.257308483123779
Iteration 380, Loss: 6.419774055480957
Iteration 381, Loss: 6.208786964416504
Iteration 382, Loss: 6.059704780578613
Iteration 383, Loss: 6.004946231842041
Iteration 384, Loss: 6.2315754890441895
Iteration 385, Loss: 6.275753974914551
Iteration 386, Loss: 5.879137992858887
Iteration 387, Loss: 6.398874759674072
Iteration 388, Loss: 6.301538944244385
Iteration 389, Loss: 5.890782356262207
Iteration 390, Loss: 5.62009334564209
Iteration 391, Loss: 6.171284198760986
Iteration 392, Loss: 6.163616180419922
Iteration 393, Loss: 5.860177040100098
Iteration 394, Loss: 6.076866626739502
Iteration 395, Loss: 6.238568305969238
Iteration 396, Loss: 6.412311553955078
Iteration 397, Loss: 5.961258888244629
Iteration 398, Loss: 6.242514610290527
Iteration 399, Loss: 5.974794387817383
Rank 2 | Iteration 400 | Training in Progress...
Iteration 400, Loss: 6.363882541656494
Iteration 401, Loss: 6.36909818649292
Iteration 402, Loss: 5.968011856079102
Iteration 403, Loss: 6.080743789672852
Iteration 404, Loss: 6.363345623016357
Iteration 405, Loss: 6.142879962921143
Iteration 406, Loss: 5.90322208404541
Iteration 407, Loss: 6.075540542602539
Iteration 408, Loss: 6.13875150680542
Iteration 409, Loss: 6.070333003997803
Iteration 410, Loss: 5.818788051605225
Iteration 411, Loss: 5.965974807739258
Iteration 412, Loss: 6.227452754974365
Iteration 413, Loss: 6.251135349273682
Iteration 414, Loss: 5.696245193481445
Iteration 415, Loss: 6.4335832595825195
Iteration 416, Loss: 6.1302490234375
Iteration 417, Loss: 6.288559436798096
Iteration 418, Loss: 5.9392828941345215
Iteration 419, Loss: 5.864153861999512
Iteration 420, Loss: 6.199878215789795
Iteration 421, Loss: 6.437722682952881
Iteration 422, Loss: 5.9140825271606445
Iteration 423, Loss: 5.965843677520752
Iteration 424, Loss: 6.254168510437012
Iteration 425, Loss: 6.219045162200928
Iteration 426, Loss: 6.170144557952881
Iteration 427, Loss: 5.99688196182251
Iteration 428, Loss: 6.335197925567627
Iteration 429, Loss: 6.15412712097168
Iteration 430, Loss: 6.351094722747803
Iteration 431, Loss: 5.724015235900879
Iteration 432, Loss: 7.0645294189453125
Iteration 433, Loss: 6.249445915222168
Iteration 434, Loss: 5.896010875701904
Iteration 435, Loss: 6.412928104400635
Iteration 436, Loss: 6.36848783493042
Iteration 437, Loss: 6.1972856521606445
Iteration 438, Loss: 6.201629161834717
Iteration 439, Loss: 6.308367729187012
Iteration 440, Loss: 6.12253999710083
Iteration 441, Loss: 6.22732400894165
Iteration 442, Loss: 5.923877239227295
Iteration 443, Loss: 6.233846187591553
Iteration 444, Loss: 5.987464904785156
Iteration 445, Loss: 5.767628192901611
Iteration 446, Loss: 6.028140544891357
Iteration 447, Loss: 5.864192008972168
Iteration 448, Loss: 6.300313949584961
Iteration 449, Loss: 6.663130760192871
Iteration 450, Loss: 5.778961658477783
Iteration 451, Loss: 6.637834072113037
Iteration 452, Loss: 5.847570419311523
Iteration 453, Loss: 6.381587505340576
Iteration 454, Loss: 5.968924045562744
Iteration 455, Loss: 6.137467384338379
Iteration 456, Loss: 5.912374496459961
Iteration 457, Loss: 6.101410388946533
Iteration 458, Loss: 5.997611999511719
Iteration 459, Loss: 6.5105109214782715
Iteration 460, Loss: 5.861419677734375
Iteration 461, Loss: 6.034667015075684
Iteration 462, Loss: 6.147597312927246
Iteration 463, Loss: 6.168854713439941
Iteration 464, Loss: 6.215417385101318
Iteration 465, Loss: 6.556859016418457
Iteration 466, Loss: 5.967589855194092
Iteration 467, Loss: 6.706641674041748
Iteration 468, Loss: 6.1306071281433105
Iteration 469, Loss: 6.384025573730469
Iteration 470, Loss: 6.075283527374268
Iteration 471, Loss: 5.85271692276001
Iteration 472, Loss: 6.384037494659424
Iteration 473, Loss: 6.611170291900635
Iteration 474, Loss: 6.192739009857178
Iteration 475, Loss: 5.897097587585449
Iteration 476, Loss: 6.0972747802734375
Iteration 477, Loss: 5.904996871948242
Iteration 478, Loss: 6.222450256347656
Iteration 479, Loss: 6.083017349243164
Iteration 480, Loss: 6.034486293792725
Iteration 481, Loss: 6.57025671005249
Iteration 482, Loss: 6.289723873138428
Iteration 483, Loss: 6.19532585144043
Iteration 484, Loss: 6.124017238616943
Iteration 485, Loss: 5.768104553222656
Iteration 486, Loss: 6.154464244842529
Iteration 487, Loss: 6.278874397277832
Iteration 488, Loss: 5.720679759979248
Iteration 489, Loss: 6.180227279663086
Iteration 490, Loss: 6.310327529907227
Iteration 491, Loss: 5.954778671264648
Iteration 492, Loss: 5.971815586090088
Iteration 493, Loss: 6.673408508300781
Iteration 494, Loss: 5.759103775024414
Iteration 495, Loss: 5.852970123291016
Iteration 496, Loss: 6.2947797775268555
Iteration 497, Loss: 6.29538106918335
Iteration 498, Loss: 6.401893138885498
Iteration 499, Loss: 5.813099384307861
Rank 2 | Iteration 500 | Training in Progress...
Iteration 500, Loss: 6.12401008605957
Iteration 501, Loss: 6.722468376159668
Iteration 502, Loss: 6.132713794708252
Iteration 503, Loss: 5.761381149291992
Iteration 504, Loss: 5.980038642883301
Iteration 505, Loss: 6.465205669403076
Iteration 506, Loss: 6.368502140045166
Iteration 507, Loss: 5.6718831062316895
Iteration 508, Loss: 6.351508140563965
Iteration 509, Loss: 6.677549839019775
Iteration 510, Loss: 6.387383937835693
Iteration 511, Loss: 6.217517375946045
Iteration 512, Loss: 6.638326168060303
Iteration 513, Loss: 6.105072498321533
Iteration 514, Loss: 6.346004486083984
Iteration 515, Loss: 6.099076271057129
Iteration 516, Loss: 6.153146266937256
Iteration 517, Loss: 6.078253269195557
Iteration 518, Loss: 5.852139949798584
Iteration 519, Loss: 5.784339904785156
Iteration 520, Loss: 6.239588260650635
Iteration 521, Loss: 6.262454032897949
Iteration 522, Loss: 6.446377754211426
Iteration 523, Loss: 6.384057521820068
Iteration 524, Loss: 6.147796154022217
Iteration 525, Loss: 6.19540548324585
Iteration 526, Loss: 6.593566417694092
Iteration 527, Loss: 6.457705020904541
Iteration 528, Loss: 6.06049108505249
Iteration 529, Loss: 6.10397481918335
Iteration 530, Loss: 6.2084221839904785
Iteration 531, Loss: 6.1089253425598145
Iteration 532, Loss: 5.884274482727051
Iteration 533, Loss: 6.059516429901123
Iteration 534, Loss: 6.330904960632324
Iteration 535, Loss: 6.531407356262207
Iteration 536, Loss: 6.055088520050049
Iteration 537, Loss: 5.981194496154785
Iteration 538, Loss: 6.29365348815918
Iteration 539, Loss: 6.313684940338135
Iteration 540, Loss: 6.18211030960083
Iteration 541, Loss: 5.811159133911133
Iteration 542, Loss: 6.093677520751953
Iteration 543, Loss: 6.067140102386475
Iteration 544, Loss: 6.2203898429870605
Iteration 545, Loss: 5.866270065307617
Iteration 546, Loss: 6.287973880767822
Iteration 547, Loss: 6.2095513343811035
Iteration 548, Loss: 6.336835861206055
Iteration 549, Loss: 6.0815043449401855
Iteration 550, Loss: 6.0434064865112305
Iteration 551, Loss: 5.960120677947998
Iteration 552, Loss: 6.648233890533447
Iteration 553, Loss: 5.670681953430176
Iteration 554, Loss: 6.2111945152282715
Iteration 555, Loss: 6.172044277191162
Iteration 556, Loss: 6.5718560218811035
Iteration 557, Loss: 6.205072402954102
Iteration 558, Loss: 6.267004489898682
Iteration 559, Loss: 6.28203010559082
Iteration 560, Loss: 6.158703327178955
Iteration 561, Loss: 6.147185802459717
Iteration 562, Loss: 6.231011390686035
Iteration 563, Loss: 6.019930839538574
Iteration 564, Loss: 5.924987316131592
Iteration 565, Loss: 6.018441677093506
Iteration 566, Loss: 6.237955570220947
Iteration 567, Loss: 6.008945941925049
Iteration 568, Loss: 6.115353584289551
Iteration 569, Loss: 6.16187047958374
Iteration 570, Loss: 6.181897163391113
Iteration 571, Loss: 5.651645183563232
Iteration 572, Loss: 5.8916401863098145
Iteration 573, Loss: 6.2280097007751465
Iteration 574, Loss: 6.3593244552612305
Iteration 575, Loss: 6.0701422691345215
Iteration 576, Loss: 6.152904033660889
Iteration 577, Loss: 6.188326835632324
Iteration 578, Loss: 6.193291664123535
Iteration 579, Loss: 5.986309051513672
Iteration 580, Loss: 6.249156475067139
Iteration 581, Loss: 6.321169853210449
Iteration 582, Loss: 6.123444080352783
Iteration 583, Loss: 6.4428205490112305
Iteration 584, Loss: 5.795279502868652
Iteration 585, Loss: 5.966930389404297
Iteration 586, Loss: 6.749166488647461
Iteration 587, Loss: 5.878857135772705
Iteration 588, Loss: 6.122544288635254
Iteration 589, Loss: 6.351811408996582
Iteration 590, Loss: 6.129960536956787
Iteration 591, Loss: 6.06482458114624
Iteration 592, Loss: 5.979983329772949
Iteration 593, Loss: 5.963005542755127
Iteration 594, Loss: 6.249081134796143
Iteration 595, Loss: 6.323024749755859
Iteration 596, Loss: 6.101289749145508
Iteration 597, Loss: 6.182649612426758
Iteration 598, Loss: 6.255692481994629
Iteration 599, Loss: 6.5873236656188965
Rank 2 | Iteration 600 | Training in Progress...
Iteration 600, Loss: 6.137770175933838
Iteration 601, Loss: 5.865481853485107
Iteration 602, Loss: 5.978363990783691
Iteration 603, Loss: 6.125791072845459
Iteration 604, Loss: 6.0884294509887695
Iteration 605, Loss: 5.983273983001709
Iteration 606, Loss: 6.259490013122559
Iteration 607, Loss: 6.2097320556640625
Iteration 608, Loss: 5.7665228843688965
Iteration 609, Loss: 6.576050281524658
Iteration 610, Loss: 6.11002779006958
Iteration 611, Loss: 6.188906669616699
Iteration 612, Loss: 5.96732234954834
Iteration 613, Loss: 5.971709728240967
Iteration 614, Loss: 6.083898067474365
Iteration 615, Loss: 5.935369491577148
Iteration 616, Loss: 6.2563157081604
Iteration 617, Loss: 6.062862873077393
Iteration 618, Loss: 6.199649810791016
Iteration 619, Loss: 6.152859210968018
Iteration 620, Loss: 6.310297966003418
Iteration 621, Loss: 6.208277702331543
Iteration 622, Loss: 6.290979862213135
Iteration 623, Loss: 6.155045986175537
Iteration 624, Loss: 6.232308387756348
Iteration 625, Loss: 6.138319969177246
Iteration 626, Loss: 5.917674541473389
Iteration 627, Loss: 5.891740322113037
Iteration 628, Loss: 5.970967769622803
Iteration 629, Loss: 6.4805192947387695
Iteration 630, Loss: 6.504592418670654
Iteration 631, Loss: 6.213972091674805
Iteration 632, Loss: 6.143805980682373
Iteration 633, Loss: 5.849723815917969
Iteration 634, Loss: 6.191537857055664
Iteration 635, Loss: 6.293550491333008
Iteration 636, Loss: 6.372061252593994
Iteration 637, Loss: 6.062024116516113
Iteration 638, Loss: 6.27988862991333
Iteration 639, Loss: 5.99251127243042
Iteration 640, Loss: 6.049391269683838
Iteration 641, Loss: 6.406713008880615
Iteration 642, Loss: 6.208450794219971
Iteration 643, Loss: 6.20888090133667
Iteration 644, Loss: 6.428769588470459
Iteration 645, Loss: 6.052265167236328
Iteration 646, Loss: 6.0959696769714355
Iteration 647, Loss: 6.065582275390625
Iteration 648, Loss: 6.489448547363281
Iteration 649, Loss: 6.082006454467773
Iteration 650, Loss: 6.245848178863525
Iteration 651, Loss: 6.393218040466309
Iteration 652, Loss: 5.9213104248046875
Iteration 653, Loss: 6.834232807159424
Iteration 654, Loss: 5.897672653198242
Iteration 655, Loss: 6.182931900024414
Iteration 656, Loss: 5.9641194343566895
Iteration 657, Loss: 5.985678195953369
Iteration 658, Loss: 5.946959972381592
Iteration 659, Loss: 6.011999607086182
Iteration 660, Loss: 6.058018684387207
Iteration 661, Loss: 5.832459926605225
Iteration 662, Loss: 6.160503387451172
Iteration 663, Loss: 6.415499210357666
Iteration 664, Loss: 5.9553117752075195
Iteration 665, Loss: 6.2284979820251465
Iteration 666, Loss: 6.312790393829346
Iteration 667, Loss: 6.0835957527160645
Iteration 668, Loss: 6.053096771240234
Iteration 669, Loss: 5.844928741455078
Iteration 670, Loss: 6.026555061340332
Iteration 671, Loss: 6.069342136383057
Iteration 672, Loss: 6.621631622314453
Iteration 673, Loss: 6.177399635314941
Iteration 674, Loss: 6.202610015869141
Iteration 675, Loss: 6.188353538513184
Iteration 676, Loss: 6.447110176086426
Iteration 677, Loss: 6.010557174682617
Iteration 678, Loss: 6.2098164558410645
Iteration 679, Loss: 6.2386088371276855
Iteration 680, Loss: 6.2926554679870605
Iteration 681, Loss: 6.236836910247803
Iteration 682, Loss: 6.084342956542969
Iteration 683, Loss: 5.9577507972717285
Iteration 684, Loss: 6.32324743270874
Iteration 685, Loss: 6.399962902069092
Iteration 686, Loss: 6.641878604888916
Iteration 687, Loss: 6.083072185516357
Iteration 688, Loss: 6.5581889152526855
Iteration 689, Loss: 6.27700662612915
Iteration 690, Loss: 5.946254730224609
Iteration 691, Loss: 6.151401042938232
Iteration 692, Loss: 6.360612392425537
Iteration 693, Loss: 6.3086419105529785
Iteration 694, Loss: 6.033808708190918
Iteration 695, Loss: 6.230355739593506
Iteration 696, Loss: 6.069366455078125
Iteration 697, Loss: 6.470174312591553
Iteration 698, Loss: 6.350859642028809
Iteration 699, Loss: 6.238978862762451
Rank 2 | Iteration 700 | Training in Progress...
Iteration 700, Loss: 6.543181896209717
Iteration 701, Loss: 5.840703010559082
Iteration 702, Loss: 6.29705286026001
Iteration 703, Loss: 6.109588623046875
Iteration 704, Loss: 6.378941535949707
Iteration 705, Loss: 6.096282958984375
Iteration 706, Loss: 6.2389678955078125
Iteration 707, Loss: 6.1951212882995605
Iteration 708, Loss: 5.907531261444092
Iteration 709, Loss: 6.076589107513428
Iteration 710, Loss: 6.019552707672119
Iteration 711, Loss: 6.040008544921875
Iteration 712, Loss: 6.141217231750488
Iteration 713, Loss: 6.302849769592285
Iteration 714, Loss: 6.030875205993652
Iteration 715, Loss: 6.109931468963623
Iteration 716, Loss: 6.0601630210876465
Iteration 717, Loss: 6.366878032684326
Iteration 718, Loss: 6.307706832885742
Iteration 719, Loss: 6.431154727935791
Iteration 720, Loss: 6.028526306152344
Iteration 721, Loss: 6.148250102996826
Iteration 722, Loss: 6.380302429199219
Iteration 723, Loss: 6.11812162399292
Iteration 724, Loss: 6.311450958251953
Iteration 725, Loss: 5.782133102416992
Iteration 726, Loss: 5.987976551055908
Iteration 727, Loss: 6.266880989074707
Iteration 728, Loss: 5.943116664886475
Iteration 729, Loss: 5.685110092163086
Iteration 730, Loss: 6.101677894592285
Iteration 731, Loss: 6.252438545227051
Iteration 732, Loss: 5.83432149887085
Iteration 733, Loss: 6.077495574951172
Iteration 734, Loss: 6.306963920593262
Iteration 735, Loss: 6.028256893157959
Iteration 736, Loss: 6.461156845092773
Iteration 737, Loss: 6.041213512420654
Iteration 738, Loss: 6.606942653656006
Iteration 739, Loss: 6.313959121704102
Iteration 740, Loss: 5.901265621185303
Iteration 741, Loss: 6.2670979499816895
Iteration 742, Loss: 6.313328742980957
Iteration 743, Loss: 6.234231948852539
Iteration 744, Loss: 6.372056007385254
Iteration 745, Loss: 5.764747142791748
Iteration 746, Loss: 6.132792949676514
Iteration 747, Loss: 6.055593490600586
Iteration 748, Loss: 6.119941711425781
Iteration 749, Loss: 6.122163772583008
Iteration 750, Loss: 6.016946792602539
Iteration 751, Loss: 5.556297302246094
Iteration 752, Loss: 5.81680154800415
Iteration 753, Loss: 6.238248825073242
Iteration 754, Loss: 5.869112968444824
Iteration 755, Loss: 6.313817977905273
Iteration 756, Loss: 6.219108581542969
Iteration 757, Loss: 5.841058731079102
Iteration 758, Loss: 6.3041510581970215
Iteration 759, Loss: 6.229156017303467
Iteration 760, Loss: 5.8800859451293945
Iteration 761, Loss: 6.538481712341309
Iteration 762, Loss: 6.370272159576416
Iteration 763, Loss: 6.065718650817871
Iteration 764, Loss: 6.406205654144287
Iteration 765, Loss: 6.315980434417725
Iteration 766, Loss: 6.163577079772949
Iteration 767, Loss: 6.157148361206055
Iteration 768, Loss: 6.152313232421875
Iteration 769, Loss: 6.336126804351807
Iteration 770, Loss: 6.220171928405762
Iteration 771, Loss: 6.322762489318848
Iteration 772, Loss: 6.280437469482422
Iteration 773, Loss: 6.0791544914245605
Iteration 774, Loss: 6.074830532073975
Iteration 775, Loss: 6.670396327972412
Iteration 776, Loss: 5.729630947113037
Iteration 777, Loss: 6.408622741699219
Iteration 778, Loss: 6.019715785980225
Iteration 779, Loss: 6.256351947784424
Iteration 780, Loss: 6.074032306671143
Iteration 781, Loss: 6.191417694091797
Iteration 782, Loss: 6.014366626739502
Iteration 783, Loss: 6.367506504058838
Iteration 784, Loss: 6.447297096252441
Iteration 785, Loss: 6.278555870056152
Iteration 786, Loss: 6.416123390197754
Iteration 787, Loss: 6.042319297790527
Iteration 788, Loss: 5.778348922729492
Iteration 789, Loss: 6.622682571411133
Iteration 790, Loss: 6.182769298553467
Iteration 791, Loss: 6.11780309677124
Iteration 792, Loss: 6.090807914733887
Iteration 793, Loss: 6.157046794891357
Iteration 794, Loss: 6.330548286437988
Iteration 795, Loss: 6.178985118865967
Iteration 796, Loss: 5.70455265045166
Iteration 797, Loss: 6.243859767913818
Iteration 798, Loss: 6.028353214263916
Iteration 799, Loss: 6.085829734802246
Rank 2 | Iteration 800 | Training in Progress...
Iteration 800, Loss: 6.074406623840332
Iteration 801, Loss: 6.246040344238281
Iteration 802, Loss: 6.105864524841309
Iteration 803, Loss: 6.027927875518799
Iteration 804, Loss: 6.35405969619751
Iteration 805, Loss: 6.174692630767822
Iteration 806, Loss: 6.057159900665283
Iteration 807, Loss: 5.822342872619629
Iteration 808, Loss: 5.824036598205566
Iteration 809, Loss: 6.267104625701904
Iteration 810, Loss: 6.224917411804199
Iteration 811, Loss: 6.292104244232178
Iteration 812, Loss: 6.295853614807129
Iteration 813, Loss: 5.947841644287109
Iteration 814, Loss: 5.760565280914307
Iteration 815, Loss: 6.652732849121094
Iteration 816, Loss: 6.067372798919678
Iteration 817, Loss: 5.879122257232666
Iteration 818, Loss: 6.272040367126465
Iteration 819, Loss: 5.961920738220215
Iteration 820, Loss: 6.583296775817871
Iteration 821, Loss: 6.031115531921387
Iteration 822, Loss: 6.035341262817383
Iteration 823, Loss: 6.134582996368408
Iteration 824, Loss: 6.382582664489746
Iteration 825, Loss: 5.750126838684082
Iteration 826, Loss: 5.907567977905273
Iteration 827, Loss: 6.235495090484619
Iteration 828, Loss: 5.957867622375488
Iteration 829, Loss: 6.225952625274658
Iteration 830, Loss: 6.37852144241333
Iteration 831, Loss: 6.148816108703613
Iteration 832, Loss: 6.49381685256958
Iteration 833, Loss: 5.9388227462768555
Iteration 834, Loss: 6.196970462799072
Iteration 835, Loss: 6.154841423034668
Iteration 836, Loss: 6.249032974243164
Iteration 837, Loss: 6.042568683624268
Iteration 838, Loss: 6.205631732940674
Iteration 839, Loss: 5.992565631866455
Iteration 840, Loss: 6.322261333465576
Iteration 841, Loss: 6.253681659698486
Iteration 842, Loss: 6.1400980949401855
Iteration 843, Loss: 6.314764022827148
Iteration 844, Loss: 6.119529724121094
Iteration 845, Loss: 5.863285064697266
Iteration 846, Loss: 5.858882904052734
Iteration 847, Loss: 6.042629241943359
Iteration 848, Loss: 6.0926032066345215
Iteration 849, Loss: 5.995179176330566
Iteration 850, Loss: 5.820174694061279
Iteration 851, Loss: 6.300434589385986
Iteration 852, Loss: 6.040268421173096
Iteration 853, Loss: 6.353449821472168
Iteration 854, Loss: 6.158503532409668
Iteration 855, Loss: 6.316459655761719
Iteration 856, Loss: 6.114444255828857
Iteration 857, Loss: 6.098151683807373
Iteration 858, Loss: 6.018896579742432
Iteration 859, Loss: 6.241616725921631
Iteration 860, Loss: 6.246874809265137
Iteration 861, Loss: 5.882599353790283
Iteration 862, Loss: 6.230348110198975
Iteration 863, Loss: 6.187869071960449
Iteration 864, Loss: 5.955406665802002
Iteration 865, Loss: 6.327995300292969
Iteration 866, Loss: 6.390527248382568
Iteration 867, Loss: 6.0053558349609375
Iteration 868, Loss: 5.868105888366699
Iteration 869, Loss: 5.903663158416748
Iteration 870, Loss: 6.161369800567627
Iteration 871, Loss: 5.902280330657959
Iteration 872, Loss: 6.021618366241455
Iteration 873, Loss: 5.660013675689697
Iteration 874, Loss: 5.90487003326416
Iteration 875, Loss: 6.1718010902404785
Iteration 876, Loss: 5.893276214599609
Iteration 877, Loss: 6.215773582458496
Iteration 878, Loss: 5.642526149749756
Iteration 879, Loss: 6.059160232543945
Iteration 880, Loss: 5.893388271331787
Iteration 881, Loss: 6.200948715209961
Iteration 882, Loss: 5.933793067932129
Iteration 883, Loss: 5.761536598205566
Iteration 884, Loss: 6.357922554016113
Iteration 885, Loss: 6.199025630950928
Iteration 886, Loss: 6.149797439575195
Iteration 887, Loss: 5.8704705238342285
Iteration 888, Loss: 6.032468795776367
Iteration 889, Loss: 5.962843418121338
Iteration 890, Loss: 6.287461757659912
Iteration 891, Loss: 6.325469017028809
Iteration 892, Loss: 6.189294338226318
Iteration 893, Loss: 5.92756986618042
Iteration 894, Loss: 6.064711093902588
Iteration 895, Loss: 5.815908432006836
Iteration 896, Loss: 6.534997463226318
Iteration 897, Loss: 6.160038471221924
Iteration 898, Loss: 6.2561869621276855
Iteration 899, Loss: 6.185243606567383
Rank 2 | Iteration 900 | Training in Progress...
Iteration 900, Loss: 5.893500804901123
Iteration 901, Loss: 5.966329097747803
Iteration 902, Loss: 6.115180492401123
Iteration 903, Loss: 6.087176322937012
Iteration 904, Loss: 6.31239128112793
Iteration 905, Loss: 5.9528961181640625
Iteration 906, Loss: 5.955866813659668
Iteration 907, Loss: 6.006413459777832
Iteration 908, Loss: 6.447687149047852
Iteration 909, Loss: 5.811774730682373
Iteration 910, Loss: 5.8407301902771
Iteration 911, Loss: 6.205958366394043
Iteration 912, Loss: 5.899322032928467
Iteration 913, Loss: 6.594008445739746
Iteration 914, Loss: 6.267580032348633
Iteration 915, Loss: 5.961899280548096
Iteration 916, Loss: 5.983275890350342
Iteration 917, Loss: 6.047942161560059
Iteration 918, Loss: 6.226785182952881
Iteration 919, Loss: 6.017321586608887
Iteration 920, Loss: 6.183650016784668
Iteration 921, Loss: 5.818822383880615
Iteration 922, Loss: 6.197261810302734
Iteration 923, Loss: 5.945430755615234
Iteration 924, Loss: 5.791141033172607
Iteration 925, Loss: 6.175848960876465
Iteration 926, Loss: 6.241878032684326
Iteration 927, Loss: 6.044628143310547
Iteration 928, Loss: 6.096414566040039
Iteration 929, Loss: 5.878917694091797
Iteration 930, Loss: 6.193808555603027
Iteration 931, Loss: 6.729848384857178
Iteration 932, Loss: 6.083599090576172
Iteration 933, Loss: 6.57734489440918
Iteration 934, Loss: 5.930172443389893
Iteration 935, Loss: 6.095085620880127
Iteration 936, Loss: 6.010342121124268
Iteration 937, Loss: 5.827197074890137
Iteration 938, Loss: 6.459059715270996
Iteration 939, Loss: 6.143158435821533
Iteration 940, Loss: 6.174869060516357
Iteration 941, Loss: 6.1933746337890625
Iteration 942, Loss: 6.6529412269592285
Iteration 943, Loss: 6.4123077392578125
Iteration 944, Loss: 6.195107460021973
Iteration 945, Loss: 6.372837066650391
Iteration 946, Loss: 5.966772556304932
Iteration 947, Loss: 6.41005277633667
Iteration 948, Loss: 5.8862175941467285
Iteration 949, Loss: 6.458429336547852
Iteration 950, Loss: 6.308294296264648
Iteration 951, Loss: 6.320522785186768
Iteration 952, Loss: 6.0854573249816895
Iteration 953, Loss: 6.10731840133667
Iteration 954, Loss: 6.111863613128662
Iteration 955, Loss: 5.962745189666748
Iteration 956, Loss: 5.872269630432129
Iteration 957, Loss: 6.264455795288086
Iteration 958, Loss: 5.937366485595703
Iteration 959, Loss: 6.196925640106201
Iteration 960, Loss: 5.750978946685791
Iteration 961, Loss: 6.524807929992676
Iteration 962, Loss: 6.000916957855225
Iteration 963, Loss: 6.014584541320801
Iteration 964, Loss: 5.856165885925293
Iteration 965, Loss: 5.930416584014893
Iteration 966, Loss: 6.34025764465332
Iteration 967, Loss: 6.014397621154785
Iteration 968, Loss: 6.022705078125
Iteration 969, Loss: 6.484462738037109
Iteration 970, Loss: 5.852148532867432
Iteration 971, Loss: 5.913843631744385
Iteration 972, Loss: 5.841868877410889
Iteration 973, Loss: 6.134388446807861
Iteration 974, Loss: 6.07492208480835
Iteration 975, Loss: 5.945575714111328
Iteration 976, Loss: 5.879226207733154
Iteration 977, Loss: 6.228487491607666
Iteration 978, Loss: 6.323657512664795
Iteration 979, Loss: 6.056387901306152
Iteration 980, Loss: 6.101734638214111
Iteration 981, Loss: 5.981876850128174
Iteration 982, Loss: 6.106183052062988
Iteration 983, Loss: 6.083415985107422
Iteration 984, Loss: 5.720676422119141
Iteration 985, Loss: 6.122429370880127
Iteration 986, Loss: 6.116389751434326
Iteration 987, Loss: 6.15941858291626
Iteration 988, Loss: 6.4098944664001465
Iteration 989, Loss: 6.06892204284668
Iteration 990, Loss: 6.321661949157715
Iteration 991, Loss: 6.169342041015625
Iteration 992, Loss: 6.068448066711426
Iteration 993, Loss: 6.354098796844482
Iteration 994, Loss: 6.331347942352295
Iteration 995, Loss: 6.550725936889648
Iteration 996, Loss: 6.04770040512085
Iteration 997, Loss: 5.847097873687744
Iteration 998, Loss: 6.390962600708008
Iteration 999, Loss: 5.984526634216309
Rank 2 | Iteration 1000 | Training in Progress...
Iteration 1000, Loss: 5.700953960418701
Iteration 1001, Loss: 5.9379777908325195
Iteration 1002, Loss: 6.243195056915283
Iteration 1003, Loss: 5.821491718292236
Iteration 1004, Loss: 5.788889408111572
Iteration 1005, Loss: 5.792119026184082
Iteration 1006, Loss: 6.161558151245117
Iteration 1007, Loss: 6.27821683883667
Iteration 1008, Loss: 6.162093639373779
Iteration 1009, Loss: 5.859124660491943
Iteration 1010, Loss: 6.291449069976807
Iteration 1011, Loss: 6.132290363311768
Iteration 1012, Loss: 6.697935581207275
Iteration 1013, Loss: 6.424215316772461
Iteration 1014, Loss: 6.4839582443237305
Iteration 1015, Loss: 6.389986038208008
Iteration 1016, Loss: 6.396726608276367
Iteration 1017, Loss: 6.044442653656006
Iteration 1018, Loss: 6.123852252960205
Iteration 1019, Loss: 6.758293628692627
Iteration 1020, Loss: 6.415410041809082
Iteration 1021, Loss: 6.120497226715088
Iteration 1022, Loss: 5.903994560241699
Iteration 1023, Loss: 6.118841171264648
Iteration 1024, Loss: 5.938459396362305
Iteration 1025, Loss: 6.415435314178467
Iteration 1026, Loss: 6.273984909057617
Iteration 1027, Loss: 6.04511833190918
Iteration 1028, Loss: 6.015213489532471
Iteration 1029, Loss: 6.03062105178833
Iteration 1030, Loss: 6.407222747802734
Iteration 1031, Loss: 6.1041035652160645
Iteration 1032, Loss: 6.6839680671691895
Iteration 1033, Loss: 6.688703536987305
Iteration 1034, Loss: 6.256593704223633
Iteration 1035, Loss: 6.235957145690918
Iteration 1036, Loss: 5.900771617889404
Iteration 1037, Loss: 6.088082790374756
Iteration 1038, Loss: 5.914216995239258
Iteration 1039, Loss: 6.047610282897949
Iteration 1040, Loss: 5.811222076416016
Iteration 1041, Loss: 6.262966156005859
Iteration 1042, Loss: 6.111495494842529
Iteration 1043, Loss: 6.051907539367676
Iteration 1044, Loss: 6.223959922790527
Iteration 1045, Loss: 6.034709930419922
Iteration 1046, Loss: 5.913188934326172
Iteration 1047, Loss: 6.016703128814697
Iteration 1048, Loss: 6.541542053222656
Iteration 1049, Loss: 5.951491355895996
Iteration 1050, Loss: 5.884305953979492
Iteration 1051, Loss: 6.321943759918213
Iteration 1052, Loss: 5.921448230743408
Iteration 1053, Loss: 5.881690979003906
Iteration 1054, Loss: 6.415538311004639
Iteration 1055, Loss: 6.0578718185424805
Iteration 1056, Loss: 6.709022521972656
Iteration 1057, Loss: 5.864991188049316
Iteration 1058, Loss: 5.884180068969727
Iteration 1059, Loss: 5.826910018920898
Iteration 1060, Loss: 6.01634407043457
Iteration 1061, Loss: 6.099240303039551
Iteration 1062, Loss: 5.922440528869629
Iteration 1063, Loss: 5.936305999755859
Iteration 1064, Loss: 6.2784905433654785
Iteration 1065, Loss: 5.882296085357666
Iteration 1066, Loss: 5.939419269561768
Iteration 1067, Loss: 6.286839485168457
Iteration 1068, Loss: 5.891510963439941
Iteration 1069, Loss: 6.314197063446045
Iteration 1070, Loss: 5.934324741363525
Iteration 1071, Loss: 6.176387310028076
Iteration 1072, Loss: 5.8126349449157715
Iteration 1073, Loss: 5.998837471008301
Iteration 1074, Loss: 6.0654144287109375
Iteration 1075, Loss: 6.531144618988037
Iteration 1076, Loss: 6.394656658172607
Iteration 1077, Loss: 6.066858291625977
Iteration 1078, Loss: 5.833914279937744
Iteration 1079, Loss: 6.309204578399658
Iteration 1080, Loss: 6.226170539855957
Iteration 1081, Loss: 6.30537748336792
Iteration 1082, Loss: 5.976721286773682
Iteration 1083, Loss: 6.079458713531494
Iteration 1084, Loss: 6.254709243774414
Iteration 1085, Loss: 6.070234775543213
Iteration 1086, Loss: 6.548731803894043
Iteration 1087, Loss: 6.2530717849731445
Iteration 1088, Loss: 5.9801025390625
Iteration 1089, Loss: 6.154886722564697
Iteration 1090, Loss: 6.387221336364746
Iteration 1091, Loss: 6.14025354385376
Iteration 1092, Loss: 6.4067702293396
Iteration 1093, Loss: 6.200891971588135
Iteration 1094, Loss: 6.11584997177124
Iteration 1095, Loss: 6.398172378540039
Iteration 1096, Loss: 6.226295471191406
Iteration 1097, Loss: 6.002345085144043
Iteration 1098, Loss: 5.928884506225586
Iteration 1099, Loss: 6.413989543914795
Rank 2 | Iteration 1100 | Training in Progress...
Iteration 1100, Loss: 6.483356475830078
Iteration 1101, Loss: 5.870803356170654
Iteration 1102, Loss: 6.035017967224121
Iteration 1103, Loss: 5.91150426864624
Iteration 1104, Loss: 6.243160247802734
Iteration 1105, Loss: 6.365287780761719
Iteration 1106, Loss: 5.896917343139648
Iteration 1107, Loss: 6.405147075653076
Iteration 1108, Loss: 6.159619331359863
Iteration 1109, Loss: 6.13212251663208
Iteration 1110, Loss: 6.221996307373047
Iteration 1111, Loss: 6.192442417144775
Iteration 1112, Loss: 6.269448757171631
Iteration 1113, Loss: 5.842162132263184
Iteration 1114, Loss: 5.716081142425537
Iteration 1115, Loss: 6.23561429977417
Iteration 1116, Loss: 5.735471725463867
Iteration 1117, Loss: 5.99967098236084
Iteration 1118, Loss: 5.887434005737305
Iteration 1119, Loss: 5.858805179595947
Iteration 1120, Loss: 5.995706558227539
Iteration 1121, Loss: 5.930145740509033
Iteration 1122, Loss: 6.0562238693237305
Iteration 1123, Loss: 6.256674289703369
Iteration 1124, Loss: 5.91298246383667
Iteration 1125, Loss: 6.357778549194336
Iteration 1126, Loss: 6.0593461990356445
Iteration 1127, Loss: 6.195677280426025
Iteration 1128, Loss: 6.646599292755127
Iteration 1129, Loss: 6.342934608459473
Iteration 1130, Loss: 6.031702041625977
Iteration 1131, Loss: 6.0143656730651855
Iteration 1132, Loss: 6.134068965911865
Iteration 1133, Loss: 6.329180717468262
Iteration 1134, Loss: 6.089042663574219
Iteration 1135, Loss: 6.460784912109375
Iteration 1136, Loss: 6.0262675285339355
Iteration 1137, Loss: 6.030195236206055
Iteration 1138, Loss: 6.093294620513916
Iteration 1139, Loss: 6.806332588195801
Iteration 1140, Loss: 6.236944675445557
Iteration 1141, Loss: 6.099003314971924
Iteration 1142, Loss: 6.157843589782715
Iteration 1143, Loss: 6.41685676574707
Iteration 1144, Loss: 6.105695724487305
Iteration 1145, Loss: 6.348116874694824
Iteration 1146, Loss: 6.240589618682861
Iteration 1147, Loss: 6.169752597808838
Iteration 1148, Loss: 6.100253105163574
Iteration 1149, Loss: 6.013706684112549
Iteration 1150, Loss: 6.380324840545654
Iteration 1151, Loss: 6.309704780578613
Iteration 1152, Loss: 5.696420192718506
Iteration 1153, Loss: 5.963835716247559
Iteration 1154, Loss: 5.788904666900635
Iteration 1155, Loss: 6.243089199066162
Iteration 1156, Loss: 6.038941383361816
Iteration 1157, Loss: 5.875967502593994
Iteration 1158, Loss: 5.991944789886475
Iteration 1159, Loss: 5.985873222351074
Iteration 1160, Loss: 6.019204139709473
Iteration 1161, Loss: 5.744531154632568
Iteration 1162, Loss: 6.192277431488037
Iteration 1163, Loss: 5.856554985046387
Iteration 1164, Loss: 6.324603080749512
Iteration 1165, Loss: 6.034233093261719
Iteration 1166, Loss: 6.228612899780273
Iteration 1167, Loss: 6.330530643463135
Iteration 1168, Loss: 6.056906223297119
Iteration 1169, Loss: 5.709312915802002
Iteration 1170, Loss: 5.951204299926758
Iteration 1171, Loss: 6.382632255554199
Iteration 1172, Loss: 5.9581451416015625
Iteration 1173, Loss: 6.173238754272461
Iteration 1174, Loss: 5.97401237487793
Iteration 1175, Loss: 5.975683212280273
Iteration 1176, Loss: 5.737039566040039
Iteration 1177, Loss: 6.36163854598999
Iteration 1178, Loss: 6.191744327545166
Iteration 1179, Loss: 6.055534362792969
Iteration 1180, Loss: 6.072705268859863
Iteration 1181, Loss: 5.734902381896973
Iteration 1182, Loss: 6.540678977966309
Iteration 1183, Loss: 5.985470294952393
Iteration 1184, Loss: 6.1815361976623535
Iteration 1185, Loss: 6.356072425842285
Iteration 1186, Loss: 6.23837947845459
Iteration 1187, Loss: 5.824120044708252
Iteration 1188, Loss: 6.2772722244262695
Iteration 1189, Loss: 6.5879364013671875
Iteration 1190, Loss: 5.806578636169434
Iteration 1191, Loss: 6.265420436859131
Iteration 1192, Loss: 6.611130237579346
Iteration 1193, Loss: 6.063297748565674
Iteration 1194, Loss: 5.890088081359863
Iteration 1195, Loss: 5.645291328430176
Iteration 1196, Loss: 6.106485366821289
Iteration 1197, Loss: 5.892341136932373
Iteration 1198, Loss: 5.8804612159729
Iteration 1199, Loss: 6.311677932739258
Rank 2 | Iteration 1200 | Training in Progress...
Iteration 1200, Loss: 5.976110458374023
Iteration 1201, Loss: 6.410678863525391
Iteration 1202, Loss: 6.532383441925049
Iteration 1203, Loss: 6.380804061889648
Iteration 1204, Loss: 6.303725242614746
Iteration 1205, Loss: 6.187114715576172
Iteration 1206, Loss: 5.936979293823242
Iteration 1207, Loss: 6.125823974609375
Iteration 1208, Loss: 6.152221202850342
Iteration 1209, Loss: 6.209741115570068
Iteration 1210, Loss: 6.440557479858398
Iteration 1211, Loss: 6.418773174285889
Iteration 1212, Loss: 6.641151428222656
Iteration 1213, Loss: 5.628468990325928
Iteration 1214, Loss: 6.01545524597168
Iteration 1215, Loss: 6.161650657653809
Iteration 1216, Loss: 5.638542652130127
Iteration 1217, Loss: 6.134555816650391
Iteration 1218, Loss: 5.923389911651611
Iteration 1219, Loss: 5.73978853225708
Iteration 1220, Loss: 6.366798400878906
Iteration 1221, Loss: 5.934990406036377
Iteration 1222, Loss: 5.925711631774902
Iteration 1223, Loss: 6.20628547668457
Iteration 1224, Loss: 6.119107246398926
Iteration 1225, Loss: 6.362852573394775
Iteration 1226, Loss: 5.672209739685059
Iteration 1227, Loss: 6.201396465301514
Iteration 1228, Loss: 6.200045585632324
Iteration 1229, Loss: 6.105545997619629
Iteration 1230, Loss: 6.485657215118408
Iteration 1231, Loss: 5.774758815765381
Iteration 1232, Loss: 5.916451930999756
Iteration 1233, Loss: 6.082314491271973
Iteration 1234, Loss: 5.787868499755859
Iteration 1235, Loss: 6.268962383270264
Iteration 1236, Loss: 6.313590049743652
Iteration 1237, Loss: 6.109607219696045
Iteration 1238, Loss: 6.05844783782959
Iteration 1239, Loss: 5.788882255554199
Iteration 1240, Loss: 6.388395309448242
Iteration 1241, Loss: 6.079890727996826
Iteration 1242, Loss: 6.128443717956543
Iteration 1243, Loss: 6.166567802429199
Iteration 1244, Loss: 6.107442378997803
Iteration 1245, Loss: 6.4711222648620605
Iteration 1246, Loss: 5.961142539978027
Iteration 1247, Loss: 5.850732803344727
Iteration 1248, Loss: 5.920866966247559
Iteration 1249, Loss: 6.161827564239502
Iteration 1250, Loss: 6.147013187408447
Iteration 1251, Loss: 5.645376682281494
Iteration 1252, Loss: 6.0228400230407715
Iteration 1253, Loss: 6.334798812866211
Iteration 1254, Loss: 5.965195178985596
Iteration 1255, Loss: 5.944103717803955
Iteration 1256, Loss: 6.072118282318115
Iteration 1257, Loss: 6.439273357391357
Iteration 1258, Loss: 6.173668384552002
Iteration 1259, Loss: 6.127234935760498
Iteration 1260, Loss: 6.10678243637085
Iteration 1261, Loss: 6.741511821746826
Iteration 1262, Loss: 6.271859169006348
Iteration 1263, Loss: 5.835183143615723
Iteration 1264, Loss: 5.817207336425781
Iteration 1265, Loss: 6.13690710067749
Iteration 1266, Loss: 6.084916591644287
Iteration 1267, Loss: 6.180019855499268
Iteration 1268, Loss: 6.209842681884766
Iteration 1269, Loss: 5.764017581939697
Iteration 1270, Loss: 5.885162830352783
Iteration 1271, Loss: 6.236008644104004
Iteration 1272, Loss: 6.149002552032471
Iteration 1273, Loss: 5.845752716064453
Iteration 1274, Loss: 6.298817157745361
Iteration 1275, Loss: 6.24414587020874
Iteration 1276, Loss: 5.871230125427246
Iteration 1277, Loss: 6.265953063964844
Iteration 1278, Loss: 6.200561046600342
Iteration 1279, Loss: 6.019718647003174
Iteration 1280, Loss: 6.010671138763428
Iteration 1281, Loss: 6.350500583648682
Iteration 1282, Loss: 6.400979518890381
Iteration 1283, Loss: 6.092089653015137
Iteration 1284, Loss: 6.026292324066162
Iteration 1285, Loss: 6.0480875968933105
Iteration 1286, Loss: 5.986317157745361
Iteration 1287, Loss: 5.809864044189453
Iteration 1288, Loss: 6.0864691734313965
Iteration 1289, Loss: 6.262824535369873
Iteration 1290, Loss: 6.157385349273682
Iteration 1291, Loss: 6.13673210144043
Iteration 1292, Loss: 6.027278423309326
Iteration 1293, Loss: 5.704596996307373
Iteration 1294, Loss: 5.985316753387451
Iteration 1295, Loss: 6.155545711517334
Iteration 1296, Loss: 6.201504230499268
Iteration 1297, Loss: 6.231362819671631
Iteration 1298, Loss: 5.883810043334961
Iteration 1299, Loss: 6.173191547393799
Rank 2 | Iteration 1300 | Training in Progress...
Iteration 1300, Loss: 5.973392486572266
Iteration 1301, Loss: 6.139697074890137
Iteration 1302, Loss: 6.445335865020752
Iteration 1303, Loss: 5.799091815948486
Iteration 1304, Loss: 6.177663803100586
Iteration 1305, Loss: 6.070724010467529
Iteration 1306, Loss: 6.319714546203613
Iteration 1307, Loss: 6.392969608306885
Iteration 1308, Loss: 6.475639820098877
Iteration 1309, Loss: 6.0685648918151855
Iteration 1310, Loss: 6.276542663574219
Iteration 1311, Loss: 6.422003269195557
Iteration 1312, Loss: 6.301313400268555
Iteration 1313, Loss: 6.416235446929932
Iteration 1314, Loss: 6.030587673187256
Iteration 1315, Loss: 5.927552223205566
Iteration 1316, Loss: 5.88100528717041
Iteration 1317, Loss: 6.236584663391113
Iteration 1318, Loss: 6.0588202476501465
Iteration 1319, Loss: 5.895023345947266
Iteration 1320, Loss: 6.118876934051514
Iteration 1321, Loss: 6.0428924560546875
Iteration 1322, Loss: 6.249296188354492
Iteration 1323, Loss: 6.098305702209473
Iteration 1324, Loss: 6.0623860359191895
Iteration 1325, Loss: 6.012727737426758
Iteration 1326, Loss: 5.917656421661377
Iteration 1327, Loss: 6.280714988708496
Iteration 1328, Loss: 6.179685115814209
Iteration 1329, Loss: 6.350059986114502
Iteration 1330, Loss: 6.098221302032471
Iteration 1331, Loss: 6.2144598960876465
Iteration 1332, Loss: 6.151756286621094
Iteration 1333, Loss: 6.203509330749512
Iteration 1334, Loss: 6.233429908752441
Iteration 1335, Loss: 6.133848190307617
Iteration 1336, Loss: 6.5526814460754395
Iteration 1337, Loss: 6.084028244018555
Iteration 1338, Loss: 6.043585300445557
Iteration 1339, Loss: 6.100805282592773
Iteration 1340, Loss: 6.1170125007629395
Iteration 1341, Loss: 6.102724075317383
Iteration 1342, Loss: 6.3097333908081055
Iteration 1343, Loss: 6.225561618804932
Iteration 1344, Loss: 5.66674280166626
Iteration 1345, Loss: 6.267645835876465
Iteration 1346, Loss: 5.942759990692139
Iteration 1347, Loss: 5.894191265106201
Iteration 1348, Loss: 6.443428993225098
Iteration 1349, Loss: 6.04127311706543
Iteration 1350, Loss: 6.035043239593506
Iteration 1351, Loss: 6.221157073974609
Iteration 1352, Loss: 6.1925787925720215
Iteration 1353, Loss: 5.994050025939941
Iteration 1354, Loss: 5.894301891326904
Iteration 1355, Loss: 6.01255464553833
Iteration 1356, Loss: 5.793327808380127
Iteration 1357, Loss: 5.8424072265625
Iteration 1358, Loss: 6.198657035827637
Iteration 1359, Loss: 6.113113880157471
Iteration 1360, Loss: 6.138668060302734
Iteration 1361, Loss: 5.846179485321045
Iteration 1362, Loss: 6.041008949279785
Iteration 1363, Loss: 5.786241054534912
Iteration 1364, Loss: 6.116588115692139
Iteration 1365, Loss: 6.263011455535889
Iteration 1366, Loss: 5.8505659103393555
Iteration 1367, Loss: 6.28015661239624
Iteration 1368, Loss: 6.2613630294799805
Iteration 1369, Loss: 6.240362167358398
Iteration 1370, Loss: 5.741864204406738
Iteration 1371, Loss: 6.026594161987305
Iteration 1372, Loss: 5.9206156730651855
Iteration 1373, Loss: 6.6116838455200195
Iteration 1374, Loss: 5.99747371673584
Iteration 1375, Loss: 6.313209533691406
Iteration 1376, Loss: 6.498618125915527
Iteration 1377, Loss: 5.775617599487305
Iteration 1378, Loss: 5.957880973815918
Iteration 1379, Loss: 5.953482627868652
Iteration 1380, Loss: 6.141048431396484
Iteration 1381, Loss: 6.207571029663086
Iteration 1382, Loss: 6.226425647735596
Iteration 1383, Loss: 6.28729772567749
Iteration 1384, Loss: 5.648374557495117
Iteration 1385, Loss: 5.9296393394470215
Iteration 1386, Loss: 6.190736770629883
Iteration 1387, Loss: 6.00298547744751
Iteration 1388, Loss: 5.667766571044922
Iteration 1389, Loss: 6.214013576507568
Iteration 1390, Loss: 6.217570781707764
Iteration 1391, Loss: 6.241609573364258
Iteration 1392, Loss: 6.281883239746094
Iteration 1393, Loss: 6.595045566558838
Iteration 1394, Loss: 6.023843765258789
Iteration 1395, Loss: 5.560885429382324
Iteration 1396, Loss: 6.170312881469727
Iteration 1397, Loss: 5.838495254516602
Iteration 1398, Loss: 6.275759696960449
Iteration 1399, Loss: 5.943386554718018
Rank 2 | Iteration 1400 | Training in Progress...
Iteration 1400, Loss: 5.729811191558838
Iteration 1401, Loss: 6.6177287101745605
Iteration 1402, Loss: 6.2843756675720215
Iteration 1403, Loss: 6.014020919799805
Iteration 1404, Loss: 6.159188747406006
Iteration 1405, Loss: 6.2467145919799805
Iteration 1406, Loss: 5.970982074737549
Iteration 1407, Loss: 6.196201801300049
Iteration 1408, Loss: 6.049466133117676
Iteration 1409, Loss: 6.2925262451171875
Iteration 1410, Loss: 6.0583600997924805
Iteration 1411, Loss: 6.132674217224121
Iteration 1412, Loss: 6.316189289093018
Iteration 1413, Loss: 6.118317127227783
Iteration 1414, Loss: 6.435225009918213
Iteration 1415, Loss: 6.353918552398682
Iteration 1416, Loss: 6.245584964752197
Iteration 1417, Loss: 6.0351691246032715
Iteration 1418, Loss: 5.908015727996826
Iteration 1419, Loss: 6.028402805328369
Iteration 1420, Loss: 5.8678789138793945
Iteration 1421, Loss: 6.238900661468506
Iteration 1422, Loss: 6.021198749542236
Iteration 1423, Loss: 5.925691604614258
Iteration 1424, Loss: 6.110192775726318
Iteration 1425, Loss: 6.228859901428223
Iteration 1426, Loss: 6.747204303741455
Iteration 1427, Loss: 6.766351222991943
Iteration 1428, Loss: 6.114044666290283
Iteration 1429, Loss: 6.001235008239746
Iteration 1430, Loss: 6.371928691864014
Iteration 1431, Loss: 6.244542598724365
Iteration 1432, Loss: 6.523266315460205
Iteration 1433, Loss: 5.752195835113525
Iteration 1434, Loss: 5.897802352905273
Iteration 1435, Loss: 6.072275638580322
Iteration 1436, Loss: 6.293796062469482
Iteration 1437, Loss: 6.248191833496094
Iteration 1438, Loss: 6.22960901260376
Iteration 1439, Loss: 5.982398986816406
Iteration 1440, Loss: 5.965216159820557
Iteration 1441, Loss: 5.9438347816467285
Iteration 1442, Loss: 6.825605392456055
Iteration 1443, Loss: 6.196638107299805
Iteration 1444, Loss: 6.3295578956604
Iteration 1445, Loss: 6.220924377441406
Iteration 1446, Loss: 6.230716228485107
Iteration 1447, Loss: 5.927555084228516
Iteration 1448, Loss: 6.005882740020752
Iteration 1449, Loss: 6.0795793533325195
Iteration 1450, Loss: 6.516082286834717
Iteration 1451, Loss: 6.119080066680908
Iteration 1452, Loss: 6.2662739753723145
Iteration 1453, Loss: 6.2147135734558105
Iteration 1454, Loss: 6.083773612976074
Iteration 1455, Loss: 6.115957736968994
Iteration 1456, Loss: 5.929347991943359
Iteration 1457, Loss: 6.271427154541016
Iteration 1458, Loss: 6.038167953491211
Iteration 1459, Loss: 6.092554569244385
Iteration 1460, Loss: 5.909690856933594
Iteration 1461, Loss: 6.234309673309326
Iteration 1462, Loss: 6.6607232093811035
Iteration 1463, Loss: 6.000522136688232
Iteration 1464, Loss: 5.82973575592041
Iteration 1465, Loss: 6.3365373611450195
Iteration 1466, Loss: 6.265585899353027
Iteration 1467, Loss: 5.990412712097168
Iteration 1468, Loss: 6.057579517364502
Iteration 1469, Loss: 6.556291103363037
Iteration 1470, Loss: 5.751732349395752
Iteration 1471, Loss: 6.081772327423096
Iteration 1472, Loss: 6.092954158782959
Iteration 1473, Loss: 6.326728343963623
Iteration 1474, Loss: 6.180015563964844
Iteration 1475, Loss: 6.272121906280518
Iteration 1476, Loss: 6.073955535888672
Iteration 1477, Loss: 6.371849060058594
Iteration 1478, Loss: 6.418834209442139
Iteration 1479, Loss: 6.357199668884277
Iteration 1480, Loss: 5.8179192543029785
Iteration 1481, Loss: 5.753975868225098
Iteration 1482, Loss: 6.016788005828857
Iteration 1483, Loss: 5.828470706939697
Iteration 1484, Loss: 6.564705848693848
Iteration 1485, Loss: 5.99269437789917
Iteration 1486, Loss: 6.392241477966309
Iteration 1487, Loss: 6.145036220550537
Iteration 1488, Loss: 5.880527973175049
Iteration 1489, Loss: 6.563572883605957
Iteration 1490, Loss: 6.072189807891846
Iteration 1491, Loss: 6.046468257904053
Iteration 1492, Loss: 6.222368240356445
Iteration 1493, Loss: 6.237610816955566
Iteration 1494, Loss: 6.0674262046813965
Iteration 1495, Loss: 6.260497093200684
Iteration 1496, Loss: 5.760101318359375
Iteration 1497, Loss: 5.923783779144287
Iteration 1498, Loss: 6.147472858428955
Iteration 1499, Loss: 6.4408721923828125
Rank 2 | Iteration 1500 | Training in Progress...
Iteration 1500, Loss: 6.3398308753967285
Iteration 1501, Loss: 5.908482551574707
Iteration 1502, Loss: 6.768948554992676
Iteration 1503, Loss: 6.605092525482178
Iteration 1504, Loss: 6.110579013824463
Iteration 1505, Loss: 5.931809902191162
Iteration 1506, Loss: 6.176042556762695
Iteration 1507, Loss: 5.733705043792725
Iteration 1508, Loss: 6.166659355163574
Iteration 1509, Loss: 6.0153727531433105
Iteration 1510, Loss: 5.994149684906006
Iteration 1511, Loss: 6.150398254394531
Iteration 1512, Loss: 6.183243274688721
Iteration 1513, Loss: 5.8267035484313965
Iteration 1514, Loss: 5.830960273742676
Iteration 1515, Loss: 6.039674758911133
Iteration 1516, Loss: 6.093095302581787
Iteration 1517, Loss: 6.15208625793457
Iteration 1518, Loss: 6.300142765045166
Iteration 1519, Loss: 5.885498523712158
Iteration 1520, Loss: 5.92734956741333
Iteration 1521, Loss: 5.955474853515625
Iteration 1522, Loss: 5.804239749908447
Iteration 1523, Loss: 5.7484846115112305
Iteration 1524, Loss: 6.093595504760742
Iteration 1525, Loss: 6.440920829772949
Iteration 1526, Loss: 6.311745643615723
Iteration 1527, Loss: 6.5284953117370605
Iteration 1528, Loss: 5.953032493591309
Iteration 1529, Loss: 6.371700763702393
Iteration 1530, Loss: 6.264149188995361
Iteration 1531, Loss: 5.928776741027832
Iteration 1532, Loss: 6.240274429321289
Iteration 1533, Loss: 6.597925186157227
Iteration 1534, Loss: 6.176593780517578
Iteration 1535, Loss: 5.97205114364624
Iteration 1536, Loss: 6.117537975311279
Iteration 1537, Loss: 6.537141799926758
Iteration 1538, Loss: 6.2283034324646
Iteration 1539, Loss: 5.7599921226501465
Iteration 1540, Loss: 6.168063163757324
Iteration 1541, Loss: 6.197841167449951
Iteration 1542, Loss: 6.049780368804932
Iteration 1543, Loss: 5.949773788452148
Iteration 1544, Loss: 6.189796447753906
Iteration 1545, Loss: 6.0811638832092285
Iteration 1546, Loss: 6.1180572509765625
Iteration 1547, Loss: 6.003825664520264
Iteration 1548, Loss: 5.93961763381958
Iteration 1549, Loss: 5.8299560546875
Iteration 1550, Loss: 5.818114280700684
Iteration 1551, Loss: 5.980107307434082
Iteration 1552, Loss: 6.379810810089111
Iteration 1553, Loss: 6.091833591461182
Iteration 1554, Loss: 5.8775129318237305
Iteration 1555, Loss: 6.0029730796813965
Iteration 1556, Loss: 6.281398296356201
Iteration 1557, Loss: 5.75010347366333
Iteration 1558, Loss: 6.453938961029053
Iteration 1559, Loss: 6.310694217681885
Iteration 1560, Loss: 5.8462605476379395
Iteration 1561, Loss: 5.964221000671387
Iteration 1562, Loss: 6.051429271697998
Iteration 1563, Loss: 6.235110282897949
Iteration 1564, Loss: 5.899651527404785
Iteration 1565, Loss: 6.186460494995117
Iteration 1566, Loss: 6.020002841949463
Iteration 1567, Loss: 5.712517261505127
Iteration 1568, Loss: 6.26664924621582
Iteration 1569, Loss: 6.439655780792236
Iteration 1570, Loss: 5.7870917320251465
Iteration 1571, Loss: 6.001006603240967
Iteration 1572, Loss: 6.047748565673828
Iteration 1573, Loss: 5.9498090744018555
Iteration 1574, Loss: 6.093999862670898
Iteration 1575, Loss: 7.10774564743042
Iteration 1576, Loss: 5.860752105712891
Iteration 1577, Loss: 6.18660831451416
Iteration 1578, Loss: 5.97285270690918
Iteration 1579, Loss: 6.61726188659668
Iteration 1580, Loss: 5.9062933921813965
Iteration 1581, Loss: 5.897217273712158
Iteration 1582, Loss: 6.147091388702393
Iteration 1583, Loss: 6.186044216156006
Iteration 1584, Loss: 6.349485874176025
Iteration 1585, Loss: 5.951805591583252
Iteration 1586, Loss: 6.030456066131592
Iteration 1587, Loss: 6.085451602935791
Iteration 1588, Loss: 6.246340751647949
Iteration 1589, Loss: 5.977416515350342
Iteration 1590, Loss: 6.1689581871032715
Iteration 1591, Loss: 6.038586616516113
Iteration 1592, Loss: 6.045671463012695
Iteration 1593, Loss: 5.91731595993042
Iteration 1594, Loss: 5.9972333908081055
Iteration 1595, Loss: 6.215426445007324
Iteration 1596, Loss: 5.8533525466918945
Iteration 1597, Loss: 6.600910663604736
Iteration 1598, Loss: 6.393127918243408
Iteration 1599, Loss: 6.09855842590332
Rank 2 | Iteration 1600 | Training in Progress...
Iteration 1600, Loss: 6.031804084777832
Iteration 1601, Loss: 5.9920830726623535
Iteration 1602, Loss: 5.6351752281188965
Iteration 1603, Loss: 5.925381183624268
Iteration 1604, Loss: 6.113606929779053
Iteration 1605, Loss: 6.450616359710693
Iteration 1606, Loss: 6.183993339538574
Iteration 1607, Loss: 6.059422016143799
Iteration 1608, Loss: 6.27235221862793
Iteration 1609, Loss: 5.98878812789917
Iteration 1610, Loss: 6.297492027282715
Iteration 1611, Loss: 6.4233293533325195
Iteration 1612, Loss: 5.837785720825195
Iteration 1613, Loss: 6.129702091217041
Iteration 1614, Loss: 6.017923831939697
Iteration 1615, Loss: 6.489995002746582
Iteration 1616, Loss: 6.264809608459473
Iteration 1617, Loss: 5.919040203094482
Iteration 1618, Loss: 6.249114513397217
Iteration 1619, Loss: 6.47817850112915
Iteration 1620, Loss: 6.101255416870117
Iteration 1621, Loss: 6.044956207275391
Iteration 1622, Loss: 5.8685832023620605
Iteration 1623, Loss: 6.044609069824219
Iteration 1624, Loss: 6.131094932556152
Iteration 1625, Loss: 6.341085910797119
Iteration 1626, Loss: 6.08479118347168
Iteration 1627, Loss: 6.1617302894592285
Iteration 1628, Loss: 5.999194145202637
Iteration 1629, Loss: 5.910212516784668
Iteration 1630, Loss: 5.8081889152526855
Iteration 1631, Loss: 6.290561676025391
Iteration 1632, Loss: 6.2872772216796875
Iteration 1633, Loss: 5.9944658279418945
Iteration 1634, Loss: 5.9195427894592285
Iteration 1635, Loss: 6.027497291564941
Iteration 1636, Loss: 5.8669586181640625
Iteration 1637, Loss: 5.9909467697143555
Iteration 1638, Loss: 6.404646396636963
Iteration 1639, Loss: 5.9021830558776855
Iteration 1640, Loss: 6.018348217010498
Iteration 1641, Loss: 6.026088237762451
Iteration 1642, Loss: 6.153228759765625
Iteration 1643, Loss: 6.261789321899414
Iteration 1644, Loss: 6.06154727935791
Iteration 1645, Loss: 6.27836799621582
Iteration 1646, Loss: 6.1085004806518555
Iteration 1647, Loss: 5.867650985717773
Iteration 1648, Loss: 5.98668909072876
Iteration 1649, Loss: 5.769994258880615
Iteration 1650, Loss: 6.103638648986816
Iteration 1651, Loss: 6.249058723449707
Iteration 1652, Loss: 6.733597278594971
Iteration 1653, Loss: 5.991091251373291
Iteration 1654, Loss: 6.579946994781494
Iteration 1655, Loss: 6.067838191986084
Iteration 1656, Loss: 6.4630632400512695
Iteration 1657, Loss: 6.446577072143555
Iteration 1658, Loss: 5.988093852996826
Iteration 1659, Loss: 5.950944423675537
Iteration 1660, Loss: 5.9688005447387695
Iteration 1661, Loss: 6.151413440704346
Iteration 1662, Loss: 5.932784080505371
Iteration 1663, Loss: 6.210432529449463
Iteration 1664, Loss: 6.127233505249023
Iteration 1665, Loss: 6.276130676269531
Iteration 1666, Loss: 5.883267879486084
Iteration 1667, Loss: 5.756229400634766
Iteration 1668, Loss: 6.3921661376953125
Iteration 1669, Loss: 5.894400119781494
Iteration 1670, Loss: 5.939100742340088
Iteration 1671, Loss: 6.197568893432617
Iteration 1672, Loss: 6.070444107055664
Iteration 1673, Loss: 6.598227500915527
Iteration 1674, Loss: 6.044478416442871
Iteration 1675, Loss: 5.953125476837158
Iteration 1676, Loss: 6.196818828582764
Iteration 1677, Loss: 6.206833362579346
Iteration 1678, Loss: 6.243226051330566
Iteration 1679, Loss: 6.222118377685547
Iteration 1680, Loss: 5.840642929077148
Iteration 1681, Loss: 5.8593854904174805
Iteration 1682, Loss: 6.661159515380859
Iteration 1683, Loss: 5.6842360496521
Iteration 1684, Loss: 6.29985237121582
Iteration 1685, Loss: 5.99272346496582
Iteration 1686, Loss: 6.280323028564453
Iteration 1687, Loss: 5.981372833251953
Iteration 1688, Loss: 6.243636131286621
Iteration 1689, Loss: 6.013668060302734
Iteration 1690, Loss: 5.878309726715088
Iteration 1691, Loss: 6.074654579162598
Iteration 1692, Loss: 5.923315525054932
Iteration 1693, Loss: 5.990726470947266
Iteration 1694, Loss: 6.205124855041504
Iteration 1695, Loss: 6.6351847648620605
Iteration 1696, Loss: 5.855375289916992
Iteration 1697, Loss: 5.934282302856445
Iteration 1698, Loss: 6.29339075088501
Iteration 1699, Loss: 6.403861999511719
Rank 2 | Iteration 1700 | Training in Progress...
Iteration 1700, Loss: 6.020665645599365
Iteration 1701, Loss: 5.870487213134766
Iteration 1702, Loss: 5.996211528778076
Iteration 1703, Loss: 5.802104949951172
Iteration 1704, Loss: 5.9197821617126465
Iteration 1705, Loss: 6.2724995613098145
Iteration 1706, Loss: 6.584914684295654
Iteration 1707, Loss: 6.3980913162231445
Iteration 1708, Loss: 6.265012264251709
Iteration 1709, Loss: 6.006861209869385
Iteration 1710, Loss: 6.014030933380127
Iteration 1711, Loss: 6.070043563842773
Iteration 1712, Loss: 6.410406589508057
Iteration 1713, Loss: 5.774733066558838
Iteration 1714, Loss: 6.031406879425049
Iteration 1715, Loss: 6.139553070068359
Iteration 1716, Loss: 6.70963716506958
Iteration 1717, Loss: 6.023927688598633
Iteration 1718, Loss: 6.335069179534912
Iteration 1719, Loss: 6.042032241821289
Iteration 1720, Loss: 6.174796104431152
Iteration 1721, Loss: 6.238617420196533
Iteration 1722, Loss: 5.981092929840088
Iteration 1723, Loss: 6.471304893493652
Iteration 1724, Loss: 6.391053676605225
Iteration 1725, Loss: 6.188084602355957
Iteration 1726, Loss: 6.069342136383057
Iteration 1727, Loss: 6.053835391998291
Iteration 1728, Loss: 5.860806465148926
Iteration 1729, Loss: 5.929494857788086
Iteration 1730, Loss: 6.155585289001465
Iteration 1731, Loss: 6.359734535217285
Iteration 1732, Loss: 5.938292980194092
Iteration 1733, Loss: 5.810697555541992
Iteration 1734, Loss: 5.914920330047607
Iteration 1735, Loss: 5.884518623352051
Iteration 1736, Loss: 6.116948127746582
Iteration 1737, Loss: 6.17874813079834
Iteration 1738, Loss: 6.256855487823486
Iteration 1739, Loss: 6.490802764892578
Iteration 1740, Loss: 5.838183403015137
Iteration 1741, Loss: 6.158052921295166
Iteration 1742, Loss: 5.995395660400391
Iteration 1743, Loss: 5.897767066955566
Iteration 1744, Loss: 5.860750198364258
Iteration 1745, Loss: 6.058497428894043
Iteration 1746, Loss: 5.993992328643799
Iteration 1747, Loss: 6.209953308105469
Iteration 1748, Loss: 6.390169620513916
Iteration 1749, Loss: 6.62577486038208
Iteration 1750, Loss: 6.086873531341553
Iteration 1751, Loss: 6.204199314117432
Iteration 1752, Loss: 5.90327787399292
Iteration 1753, Loss: 5.941879749298096
Iteration 1754, Loss: 6.068212509155273
Iteration 1755, Loss: 6.531099319458008
Iteration 1756, Loss: 6.21525764465332
Iteration 1757, Loss: 5.7792253494262695
Iteration 1758, Loss: 6.193985462188721
Iteration 1759, Loss: 5.887666702270508
Iteration 1760, Loss: 6.0780863761901855
Iteration 1761, Loss: 6.209423065185547
Iteration 1762, Loss: 6.469498157501221
Iteration 1763, Loss: 6.155654430389404
Iteration 1764, Loss: 6.400180816650391
Iteration 1765, Loss: 6.06187105178833
Iteration 1766, Loss: 6.024426460266113
Iteration 1767, Loss: 6.3785295486450195
Iteration 1768, Loss: 6.316619396209717
Iteration 1769, Loss: 5.9030303955078125
Iteration 1770, Loss: 5.943289279937744
Iteration 1771, Loss: 6.4383134841918945
Iteration 1772, Loss: 6.34010648727417
Iteration 1773, Loss: 6.110284328460693
Iteration 1774, Loss: 6.3976054191589355
Iteration 1775, Loss: 6.250177383422852
Iteration 1776, Loss: 6.328368186950684
Iteration 1777, Loss: 5.93824577331543
Iteration 1778, Loss: 6.090043067932129
Iteration 1779, Loss: 5.997831344604492
Iteration 1780, Loss: 6.295628547668457
Iteration 1781, Loss: 6.111584186553955
Iteration 1782, Loss: 6.155865669250488
Iteration 1783, Loss: 5.7769269943237305
Iteration 1784, Loss: 5.989434719085693
Iteration 1785, Loss: 6.178802013397217
Iteration 1786, Loss: 5.892885208129883
Iteration 1787, Loss: 5.7651214599609375
Iteration 1788, Loss: 6.328553676605225
Iteration 1789, Loss: 6.069270133972168
Iteration 1790, Loss: 6.145476341247559
Iteration 1791, Loss: 5.99412202835083
Iteration 1792, Loss: 6.096800327301025
Iteration 1793, Loss: 5.847203254699707
Iteration 1794, Loss: 6.158318519592285
Iteration 1795, Loss: 6.026816368103027
Iteration 1796, Loss: 6.2451863288879395
Iteration 1797, Loss: 5.928525924682617
Iteration 1798, Loss: 6.344638824462891
Iteration 1799, Loss: 6.409316062927246
Rank 2 | Iteration 1800 | Training in Progress...
Iteration 1800, Loss: 6.383125305175781
Iteration 1801, Loss: 5.8837385177612305
Iteration 1802, Loss: 5.833939075469971
Iteration 1803, Loss: 6.051027774810791
Iteration 1804, Loss: 5.893398284912109
Iteration 1805, Loss: 6.122940540313721
Iteration 1806, Loss: 6.218867778778076
Iteration 1807, Loss: 6.30156946182251
Iteration 1808, Loss: 6.058270454406738
Iteration 1809, Loss: 7.040539264678955
Iteration 1810, Loss: 5.8573222160339355
Iteration 1811, Loss: 5.683000564575195
Iteration 1812, Loss: 5.78225040435791
Iteration 1813, Loss: 6.392297744750977
Iteration 1814, Loss: 6.222812652587891
Iteration 1815, Loss: 6.21315860748291
Iteration 1816, Loss: 6.0408735275268555
Iteration 1817, Loss: 6.014530658721924
Iteration 1818, Loss: 6.388952255249023
Iteration 1819, Loss: 6.36918306350708
Iteration 1820, Loss: 6.569303035736084
Iteration 1821, Loss: 6.2813262939453125
Iteration 1822, Loss: 6.194211483001709
Iteration 1823, Loss: 6.069354057312012
Iteration 1824, Loss: 6.084275245666504
Iteration 1825, Loss: 6.032083034515381
Iteration 1826, Loss: 6.497441291809082
Iteration 1827, Loss: 6.192800998687744
Iteration 1828, Loss: 6.009535312652588
Iteration 1829, Loss: 6.012388706207275
Iteration 1830, Loss: 6.110113143920898
Iteration 1831, Loss: 6.133965492248535
Iteration 1832, Loss: 6.239749908447266
Iteration 1833, Loss: 5.927711486816406
Iteration 1834, Loss: 6.267632961273193
Iteration 1835, Loss: 5.936331272125244
Iteration 1836, Loss: 6.2026262283325195
Iteration 1837, Loss: 5.895319938659668
Iteration 1838, Loss: 5.93828010559082
Iteration 1839, Loss: 5.992551803588867
Iteration 1840, Loss: 6.294038772583008
Iteration 1841, Loss: 6.297162055969238
Iteration 1842, Loss: 5.983888149261475
Iteration 1843, Loss: 5.990981578826904
Iteration 1844, Loss: 6.38346004486084
Iteration 1845, Loss: 6.101197719573975
Iteration 1846, Loss: 6.10285758972168
Iteration 1847, Loss: 6.094401836395264
Iteration 1848, Loss: 6.075553894042969
Iteration 1849, Loss: 6.348116874694824
Iteration 1850, Loss: 5.662014961242676
Iteration 1851, Loss: 6.341731071472168
Iteration 1852, Loss: 5.939123153686523
Iteration 1853, Loss: 5.974099159240723
Iteration 1854, Loss: 6.0859761238098145
Iteration 1855, Loss: 6.246412754058838
Iteration 1856, Loss: 5.812471389770508
Iteration 1857, Loss: 5.749719142913818
Iteration 1858, Loss: 6.048734664916992
Iteration 1859, Loss: 5.970823764801025
Iteration 1860, Loss: 6.007017135620117
Iteration 1861, Loss: 6.253306865692139
Iteration 1862, Loss: 6.083083152770996
Iteration 1863, Loss: 6.25368070602417
Iteration 1864, Loss: 6.368198871612549
Iteration 1865, Loss: 5.999194622039795
Iteration 1866, Loss: 6.143045902252197
Iteration 1867, Loss: 6.396589279174805
Iteration 1868, Loss: 6.139440536499023
Iteration 1869, Loss: 6.048141002655029
Iteration 1870, Loss: 5.858931541442871
Iteration 1871, Loss: 5.920444011688232
Iteration 1872, Loss: 6.017859935760498
Iteration 1873, Loss: 6.132216930389404
Iteration 1874, Loss: 5.83596658706665
Iteration 1875, Loss: 6.018989086151123
Iteration 1876, Loss: 5.867748260498047
Iteration 1877, Loss: 6.09240198135376
Iteration 1878, Loss: 6.043656826019287
Iteration 1879, Loss: 5.624544143676758
Iteration 1880, Loss: 6.446402549743652
Iteration 1881, Loss: 5.909193515777588
Iteration 1882, Loss: 6.252309322357178
Iteration 1883, Loss: 6.508896350860596
Iteration 1884, Loss: 6.816433906555176
Iteration 1885, Loss: 5.856219291687012
Iteration 1886, Loss: 6.249627113342285
Iteration 1887, Loss: 5.928245544433594
Iteration 1888, Loss: 6.46235466003418
Iteration 1889, Loss: 6.1413373947143555
Iteration 1890, Loss: 6.226380825042725
Iteration 1891, Loss: 5.928311347961426
Iteration 1892, Loss: 6.174568176269531
Iteration 1893, Loss: 5.667296886444092
Iteration 1894, Loss: 6.3160810470581055
Iteration 1895, Loss: 6.343052387237549
Iteration 1896, Loss: 6.537330627441406
Iteration 1897, Loss: 6.272120475769043
Iteration 1898, Loss: 5.7141218185424805
Iteration 1899, Loss: 6.261203765869141
Rank 2 | Iteration 1900 | Training in Progress...
Iteration 1900, Loss: 6.266201972961426
Iteration 1901, Loss: 5.811963081359863
Iteration 1902, Loss: 6.240649223327637
Iteration 1903, Loss: 5.912135124206543
Iteration 1904, Loss: 5.856662273406982
Iteration 1905, Loss: 6.548094272613525
Iteration 1906, Loss: 6.151914596557617
Iteration 1907, Loss: 6.1245198249816895
Iteration 1908, Loss: 6.210125923156738
Iteration 1909, Loss: 5.7773871421813965
Iteration 1910, Loss: 5.766617774963379
Iteration 1911, Loss: 5.90492057800293
Iteration 1912, Loss: 6.2105278968811035
Iteration 1913, Loss: 5.954085826873779
Iteration 1914, Loss: 6.16239070892334
Iteration 1915, Loss: 5.933963298797607
Iteration 1916, Loss: 6.295910358428955
Iteration 1917, Loss: 6.049811363220215
Iteration 1918, Loss: 6.291713714599609
Iteration 1919, Loss: 6.439255237579346
Iteration 1920, Loss: 5.839271068572998
Iteration 1921, Loss: 6.1644673347473145
Iteration 1922, Loss: 6.239748001098633
Iteration 1923, Loss: 6.204839706420898
Iteration 1924, Loss: 7.0136871337890625
Iteration 1925, Loss: 6.113178253173828
Iteration 1926, Loss: 5.993876934051514
Iteration 1927, Loss: 6.0656232833862305
Iteration 1928, Loss: 6.290741443634033
Iteration 1929, Loss: 6.006557941436768
Iteration 1930, Loss: 6.128208160400391
Iteration 1931, Loss: 6.1633806228637695
Iteration 1932, Loss: 6.283874988555908
Iteration 1933, Loss: 5.757521629333496
Iteration 1934, Loss: 5.8642778396606445
Iteration 1935, Loss: 5.753743648529053
Iteration 1936, Loss: 5.99344539642334
Iteration 1937, Loss: 6.048162937164307
Iteration 1938, Loss: 5.925591468811035
Iteration 1939, Loss: 5.871692657470703
Iteration 1940, Loss: 6.133940696716309
Iteration 1941, Loss: 6.258881092071533
Iteration 1942, Loss: 6.225973606109619
Iteration 1943, Loss: 6.043912887573242
Iteration 1944, Loss: 6.718916893005371
Iteration 1945, Loss: 6.0525078773498535
Iteration 1946, Loss: 5.901444435119629
Iteration 1947, Loss: 6.092179775238037
Iteration 1948, Loss: 6.239229202270508
Iteration 1949, Loss: 6.077479362487793
Iteration 1950, Loss: 6.068375110626221
Iteration 1951, Loss: 6.046604156494141
Iteration 1952, Loss: 6.183969974517822
Iteration 1953, Loss: 6.2898454666137695
Iteration 1954, Loss: 5.898505210876465
Iteration 1955, Loss: 5.888097286224365
Iteration 1956, Loss: 6.138341426849365
Iteration 1957, Loss: 6.048610210418701
Iteration 1958, Loss: 6.174317359924316
Iteration 1959, Loss: 5.860694408416748
Iteration 1960, Loss: 5.958116054534912
Iteration 1961, Loss: 6.199077606201172
Iteration 1962, Loss: 5.902528285980225
Iteration 1963, Loss: 5.728580951690674
Iteration 1964, Loss: 6.390082836151123
Iteration 1965, Loss: 6.388203144073486
Iteration 1966, Loss: 6.089700222015381
Iteration 1967, Loss: 6.009272575378418
Iteration 1968, Loss: 6.0750203132629395
Iteration 1969, Loss: 6.289369106292725
Iteration 1970, Loss: 6.101298809051514
Iteration 1971, Loss: 6.295431613922119
Iteration 1972, Loss: 6.429754257202148
Iteration 1973, Loss: 6.08500862121582
Iteration 1974, Loss: 6.0268940925598145
Iteration 1975, Loss: 6.051000118255615
Iteration 1976, Loss: 6.017813205718994
Iteration 1977, Loss: 6.108818054199219
Iteration 1978, Loss: 6.221271514892578
Iteration 1979, Loss: 6.153043270111084
Iteration 1980, Loss: 6.164155006408691
Iteration 1981, Loss: 6.193364143371582
Iteration 1982, Loss: 6.280914783477783
Iteration 1983, Loss: 6.084021091461182
Iteration 1984, Loss: 6.320296287536621
Iteration 1985, Loss: 6.011571884155273
Iteration 1986, Loss: 6.072709560394287
Iteration 1987, Loss: 5.887323379516602
Iteration 1988, Loss: 6.189798831939697
Iteration 1989, Loss: 6.260756492614746
Iteration 1990, Loss: 6.003332138061523
Iteration 1991, Loss: 5.617397308349609
Iteration 1992, Loss: 6.222349166870117
Iteration 1993, Loss: 6.30311918258667
Iteration 1994, Loss: 6.315005779266357
Iteration 1995, Loss: 5.929535865783691
Iteration 1996, Loss: 5.987532138824463
Iteration 1997, Loss: 6.358097553253174
Iteration 1998, Loss: 5.934237003326416
Iteration 1999, Loss: 5.9824113845825195
Rank 2 | Iteration 2000 | Training in Progress...
Iteration 2000, Loss: 5.960844993591309
Iteration 2001, Loss: 5.790703773498535
Iteration 2002, Loss: 5.805925369262695
Iteration 2003, Loss: 5.941681861877441
Iteration 2004, Loss: 5.910171985626221
Iteration 2005, Loss: 6.126147747039795
Iteration 2006, Loss: 5.913514614105225
Iteration 2007, Loss: 5.6997809410095215
Iteration 2008, Loss: 6.241695880889893
Iteration 2009, Loss: 6.052206516265869
Iteration 2010, Loss: 5.989712238311768
Iteration 2011, Loss: 5.9510626792907715
Iteration 2012, Loss: 6.3757781982421875
Iteration 2013, Loss: 5.9790167808532715
Iteration 2014, Loss: 6.057982921600342
Iteration 2015, Loss: 5.89030122756958
Iteration 2016, Loss: 5.928627967834473
Iteration 2017, Loss: 6.23016881942749
Iteration 2018, Loss: 6.090982437133789
Iteration 2019, Loss: 6.147093296051025
Iteration 2020, Loss: 6.092625617980957
Iteration 2021, Loss: 6.15676736831665
Iteration 2022, Loss: 6.380425930023193
Iteration 2023, Loss: 6.003531455993652
Iteration 2024, Loss: 6.23383903503418
Iteration 2025, Loss: 5.499860763549805
Iteration 2026, Loss: 6.098086357116699
Iteration 2027, Loss: 6.184497356414795
Iteration 2028, Loss: 6.3353471755981445
Iteration 2029, Loss: 6.083804130554199
Iteration 2030, Loss: 5.855500221252441
Iteration 2031, Loss: 6.145418167114258
Iteration 2032, Loss: 6.145206928253174
Iteration 2033, Loss: 6.3410964012146
Iteration 2034, Loss: 5.989563941955566
Iteration 2035, Loss: 6.210262298583984
Iteration 2036, Loss: 5.857295036315918
Iteration 2037, Loss: 5.98552942276001
Iteration 2038, Loss: 6.356884479522705
Iteration 2039, Loss: 5.868799686431885
Iteration 2040, Loss: 6.246429920196533
Iteration 2041, Loss: 5.908519268035889
Iteration 2042, Loss: 6.066294193267822
Iteration 2043, Loss: 5.572051525115967
Iteration 2044, Loss: 5.987398624420166
Iteration 2045, Loss: 6.1429314613342285
Iteration 2046, Loss: 6.0556960105896
Iteration 2047, Loss: 5.9843220710754395
Iteration 2048, Loss: 6.272010803222656
Iteration 2049, Loss: 5.954463958740234
Iteration 2050, Loss: 5.848226547241211
Iteration 2051, Loss: 5.725425720214844
Iteration 2052, Loss: 5.784961223602295
Iteration 2053, Loss: 5.9139227867126465
Iteration 2054, Loss: 6.105802059173584
Iteration 2055, Loss: 6.101472854614258
Iteration 2056, Loss: 5.777015686035156
Iteration 2057, Loss: 6.103760242462158
Iteration 2058, Loss: 6.275218963623047
Iteration 2059, Loss: 6.0151567459106445
Iteration 2060, Loss: 6.140072345733643
Iteration 2061, Loss: 5.988364219665527
Iteration 2062, Loss: 5.7057294845581055
Iteration 2063, Loss: 5.65062952041626
Iteration 2064, Loss: 6.066334247589111
Iteration 2065, Loss: 5.953396797180176
Iteration 2066, Loss: 5.962065696716309
Iteration 2067, Loss: 6.080231189727783
Iteration 2068, Loss: 5.850936412811279
Iteration 2069, Loss: 6.028371810913086
Iteration 2070, Loss: 6.231521129608154
Iteration 2071, Loss: 6.24158239364624
Iteration 2072, Loss: 6.40343713760376
Iteration 2073, Loss: 5.881287574768066
Iteration 2074, Loss: 6.20549201965332
Iteration 2075, Loss: 6.159529209136963
Iteration 2076, Loss: 6.29103946685791
Iteration 2077, Loss: 6.475642204284668
Iteration 2078, Loss: 6.100128650665283
Iteration 2079, Loss: 5.749512195587158
Iteration 2080, Loss: 6.017027854919434
Iteration 2081, Loss: 6.367364883422852
Iteration 2082, Loss: 6.126497268676758
Iteration 2083, Loss: 6.024641036987305
Iteration 2084, Loss: 5.738942623138428
Iteration 2085, Loss: 6.0204339027404785
Iteration 2086, Loss: 6.041996002197266
Iteration 2087, Loss: 6.15187931060791
Iteration 2088, Loss: 6.384151935577393
Iteration 2089, Loss: 6.334059238433838
Iteration 2090, Loss: 5.928792953491211
Iteration 2091, Loss: 6.214982509613037
Iteration 2092, Loss: 6.4282073974609375
Iteration 2093, Loss: 5.853107452392578
Iteration 2094, Loss: 6.1421122550964355
Iteration 2095, Loss: 6.234282493591309
Iteration 2096, Loss: 6.395084857940674
Iteration 2097, Loss: 6.495215892791748
Iteration 2098, Loss: 6.113612174987793
Iteration 2099, Loss: 5.9738383293151855
Rank 2 | Iteration 2100 | Training in Progress...
Iteration 2100, Loss: 6.086861610412598
Iteration 2101, Loss: 5.864749431610107
Iteration 2102, Loss: 6.118042469024658
Iteration 2103, Loss: 6.444908618927002
Iteration 2104, Loss: 5.992938995361328
Iteration 2105, Loss: 5.874584197998047
Iteration 2106, Loss: 6.361326694488525
Iteration 2107, Loss: 5.9851393699646
Iteration 2108, Loss: 6.392885208129883
Iteration 2109, Loss: 6.124448299407959
Iteration 2110, Loss: 5.75998592376709
Iteration 2111, Loss: 6.00820255279541
Iteration 2112, Loss: 6.414826393127441
Iteration 2113, Loss: 5.9771575927734375
Iteration 2114, Loss: 5.8441033363342285
Iteration 2115, Loss: 5.8249688148498535
Iteration 2116, Loss: 6.461517333984375
Iteration 2117, Loss: 6.348579406738281
Iteration 2118, Loss: 6.131936073303223
Iteration 2119, Loss: 6.205909252166748
Iteration 2120, Loss: 6.286433219909668
Iteration 2121, Loss: 6.142754077911377
Iteration 2122, Loss: 6.12849760055542
Iteration 2123, Loss: 6.025309085845947
Iteration 2124, Loss: 6.0789103507995605
Iteration 2125, Loss: 6.179271221160889
Iteration 2126, Loss: 5.9152631759643555
Iteration 2127, Loss: 5.899698734283447
Iteration 2128, Loss: 5.899603843688965
Iteration 2129, Loss: 6.298588275909424
Iteration 2130, Loss: 6.1199798583984375
Iteration 2131, Loss: 5.993520259857178
Iteration 2132, Loss: 6.3246331214904785
Iteration 2133, Loss: 6.279238700866699
Iteration 2134, Loss: 5.926784038543701
Iteration 2135, Loss: 6.095046043395996
Iteration 2136, Loss: 5.865812301635742
Iteration 2137, Loss: 6.005927085876465
Iteration 2138, Loss: 5.833298206329346
Iteration 2139, Loss: 5.892746925354004
Iteration 2140, Loss: 5.905086517333984
Iteration 2141, Loss: 5.948429107666016
Iteration 2142, Loss: 6.558866024017334
Iteration 2143, Loss: 6.1707763671875
Iteration 2144, Loss: 5.921097755432129
Iteration 2145, Loss: 5.868102550506592
Iteration 2146, Loss: 5.922539710998535
Iteration 2147, Loss: 6.378624439239502
Iteration 2148, Loss: 5.956121444702148
Iteration 2149, Loss: 6.099309921264648
Iteration 2150, Loss: 5.8038530349731445
Iteration 2151, Loss: 6.00247049331665
Iteration 2152, Loss: 5.953914642333984
Iteration 2153, Loss: 6.083065032958984
Iteration 2154, Loss: 5.74391508102417
Iteration 2155, Loss: 5.945562362670898
Iteration 2156, Loss: 6.3705339431762695
Iteration 2157, Loss: 5.8775858879089355
Iteration 2158, Loss: 6.120724201202393
Iteration 2159, Loss: 5.892853260040283
Iteration 2160, Loss: 6.1331467628479
Iteration 2161, Loss: 5.873996257781982
Iteration 2162, Loss: 6.071095943450928
Iteration 2163, Loss: 5.83396053314209
Iteration 2164, Loss: 6.043741703033447
Iteration 2165, Loss: 5.942693710327148
Iteration 2166, Loss: 6.0266642570495605
Iteration 2167, Loss: 6.174318313598633
Iteration 2168, Loss: 6.1134490966796875
Iteration 2169, Loss: 6.309321880340576
Iteration 2170, Loss: 6.240974426269531
Iteration 2171, Loss: 6.379064559936523
Iteration 2172, Loss: 6.058653831481934
Iteration 2173, Loss: 6.276188373565674
Iteration 2174, Loss: 5.959397315979004
Iteration 2175, Loss: 5.9666523933410645
Iteration 2176, Loss: 6.076453685760498
Iteration 2177, Loss: 6.121910095214844
Iteration 2178, Loss: 5.845431804656982
Iteration 2179, Loss: 5.989063739776611
Iteration 2180, Loss: 6.037111282348633
Iteration 2181, Loss: 5.9077372550964355
Iteration 2182, Loss: 5.983188152313232
Iteration 2183, Loss: 6.044454097747803
Iteration 2184, Loss: 6.221799850463867
Iteration 2185, Loss: 5.847131252288818
Iteration 2186, Loss: 6.756874084472656
Iteration 2187, Loss: 6.586681365966797
Iteration 2188, Loss: 5.973346710205078
Iteration 2189, Loss: 5.8215861320495605
Iteration 2190, Loss: 5.8710832595825195
Iteration 2191, Loss: 6.1831955909729
Iteration 2192, Loss: 6.194916725158691
Iteration 2193, Loss: 6.031006813049316
Iteration 2194, Loss: 6.360881328582764
Iteration 2195, Loss: 6.6278605461120605
Iteration 2196, Loss: 6.4487128257751465
Iteration 2197, Loss: 6.281881809234619
Iteration 2198, Loss: 6.244935989379883
Iteration 2199, Loss: 6.20459508895874
Rank 2 | Iteration 2200 | Training in Progress...
Iteration 2200, Loss: 6.46157693862915
Iteration 2201, Loss: 5.943404674530029
Iteration 2202, Loss: 6.063441753387451
Iteration 2203, Loss: 6.074621677398682
Iteration 2204, Loss: 5.9573588371276855
Iteration 2205, Loss: 5.996879577636719
Iteration 2206, Loss: 6.032892227172852
Iteration 2207, Loss: 6.152765274047852
Iteration 2208, Loss: 6.167280673980713
Iteration 2209, Loss: 6.276430130004883
Iteration 2210, Loss: 5.747580051422119
Iteration 2211, Loss: 6.214951038360596
Iteration 2212, Loss: 6.159178733825684
Iteration 2213, Loss: 6.0027618408203125
Iteration 2214, Loss: 5.862940788269043
Iteration 2215, Loss: 6.201690196990967
Iteration 2216, Loss: 6.0629096031188965
Iteration 2217, Loss: 6.138225078582764
Iteration 2218, Loss: 6.309000492095947
Iteration 2219, Loss: 6.3090691566467285
Iteration 2220, Loss: 5.879517555236816
Iteration 2221, Loss: 5.957481861114502
Iteration 2222, Loss: 5.94314432144165
Iteration 2223, Loss: 6.1368255615234375
Iteration 2224, Loss: 6.309874534606934
Iteration 2225, Loss: 5.9425435066223145
Iteration 2226, Loss: 6.372252464294434
Iteration 2227, Loss: 5.965121746063232
Iteration 2228, Loss: 6.432740211486816
Iteration 2229, Loss: 6.152017116546631
Iteration 2230, Loss: 5.8669586181640625
Iteration 2231, Loss: 6.358279228210449
Iteration 2232, Loss: 6.192681789398193
Iteration 2233, Loss: 6.170604705810547
Iteration 2234, Loss: 6.465857028961182
Iteration 2235, Loss: 5.873855113983154
Iteration 2236, Loss: 6.278487682342529
Iteration 2237, Loss: 6.350924491882324
Iteration 2238, Loss: 6.172998428344727
Iteration 2239, Loss: 6.005643844604492
Iteration 2240, Loss: 5.591795444488525
Iteration 2241, Loss: 6.2472920417785645
Iteration 2242, Loss: 6.196047306060791
Iteration 2243, Loss: 6.171320915222168
Iteration 2244, Loss: 6.225368499755859
Iteration 2245, Loss: 5.94526481628418
Iteration 2246, Loss: 6.272076606750488
Iteration 2247, Loss: 6.331470489501953
Iteration 2248, Loss: 6.125297546386719
Iteration 2249, Loss: 6.118151664733887
Iteration 2250, Loss: 6.308337211608887
Iteration 2251, Loss: 6.425676345825195
Iteration 2252, Loss: 6.106301307678223
Iteration 2253, Loss: 6.053602695465088
Iteration 2254, Loss: 6.164148330688477
Iteration 2255, Loss: 6.102391719818115
Iteration 2256, Loss: 6.169593334197998
Iteration 2257, Loss: 6.140381336212158
Iteration 2258, Loss: 6.377448081970215
Iteration 2259, Loss: 6.127874851226807
Iteration 2260, Loss: 6.195348262786865
Iteration 2261, Loss: 6.009301662445068
Iteration 2262, Loss: 5.9842023849487305
Iteration 2263, Loss: 5.7927961349487305
Iteration 2264, Loss: 6.183142185211182
Iteration 2265, Loss: 6.138174533843994
Iteration 2266, Loss: 6.035368919372559
Iteration 2267, Loss: 6.395429611206055
Iteration 2268, Loss: 6.339827060699463
Iteration 2269, Loss: 6.164790630340576
Iteration 2270, Loss: 6.021583080291748
Iteration 2271, Loss: 6.034224510192871
Iteration 2272, Loss: 5.979443550109863
Iteration 2273, Loss: 5.8978047370910645
Iteration 2274, Loss: 6.4980669021606445
Iteration 2275, Loss: 5.982313632965088
Iteration 2276, Loss: 5.965080261230469
Iteration 2277, Loss: 5.86712121963501
Iteration 2278, Loss: 5.983355522155762
Iteration 2279, Loss: 5.858112812042236
Iteration 2280, Loss: 5.938887596130371
Iteration 2281, Loss: 6.073896408081055
Iteration 2282, Loss: 5.962214469909668
Iteration 2283, Loss: 5.933434009552002
Iteration 2284, Loss: 6.2445526123046875
Iteration 2285, Loss: 6.02385950088501
Iteration 2286, Loss: 6.21554708480835
Iteration 2287, Loss: 5.821098327636719
Iteration 2288, Loss: 6.135283470153809
Iteration 2289, Loss: 6.3875346183776855
Iteration 2290, Loss: 6.108349323272705
Iteration 2291, Loss: 6.588413238525391
Iteration 2292, Loss: 6.212957859039307
Iteration 2293, Loss: 6.094696044921875
Iteration 2294, Loss: 6.318094253540039
Iteration 2295, Loss: 6.509782791137695
Iteration 2296, Loss: 5.960147857666016
Iteration 2297, Loss: 5.95240592956543
Iteration 2298, Loss: 5.754821300506592
Iteration 2299, Loss: 6.016076564788818
Rank 2 | Iteration 2300 | Training in Progress...
Iteration 2300, Loss: 5.95387601852417
Iteration 2301, Loss: 6.713415145874023
Iteration 2302, Loss: 5.927196025848389
Iteration 2303, Loss: 6.327696800231934
Iteration 2304, Loss: 6.1633172035217285
Iteration 2305, Loss: 6.196778297424316
Iteration 2306, Loss: 6.477080821990967
Iteration 2307, Loss: 6.185249328613281
Iteration 2308, Loss: 6.181136608123779
Iteration 2309, Loss: 6.311190128326416
Iteration 2310, Loss: 5.939551830291748
Iteration 2311, Loss: 6.048050880432129
Iteration 2312, Loss: 6.41310977935791
Iteration 2313, Loss: 6.317659854888916
Iteration 2314, Loss: 6.010434627532959
Iteration 2315, Loss: 6.009574890136719
Iteration 2316, Loss: 6.115828514099121
Iteration 2317, Loss: 6.195156097412109
Iteration 2318, Loss: 6.088263988494873
Iteration 2319, Loss: 6.429448127746582
Iteration 2320, Loss: 6.1409525871276855
Iteration 2321, Loss: 6.1674675941467285
Iteration 2322, Loss: 6.305772304534912
Iteration 2323, Loss: 5.83448600769043
Iteration 2324, Loss: 6.375957489013672
Iteration 2325, Loss: 5.937082767486572
Iteration 2326, Loss: 6.164418697357178
Iteration 2327, Loss: 5.834438323974609
Iteration 2328, Loss: 6.193609237670898
Iteration 2329, Loss: 5.969620704650879
Iteration 2330, Loss: 6.385564804077148
Iteration 2331, Loss: 6.186585426330566
Iteration 2332, Loss: 5.967565059661865
Iteration 2333, Loss: 6.33085298538208
Iteration 2334, Loss: 5.943778038024902
Iteration 2335, Loss: 5.797720432281494
Iteration 2336, Loss: 6.223444938659668
Iteration 2337, Loss: 5.869143962860107
Iteration 2338, Loss: 5.881657123565674
Iteration 2339, Loss: 6.27651309967041
Iteration 2340, Loss: 6.112213134765625
Iteration 2341, Loss: 6.2777533531188965
Iteration 2342, Loss: 6.296527862548828
Iteration 2343, Loss: 5.9884934425354
Iteration 2344, Loss: 5.900776386260986
Iteration 2345, Loss: 6.0769548416137695
Iteration 2346, Loss: 6.243711471557617
Iteration 2347, Loss: 6.090043544769287
Iteration 2348, Loss: 6.441189289093018
Iteration 2349, Loss: 6.113627910614014
Iteration 2350, Loss: 5.784170627593994
Iteration 2351, Loss: 6.173665523529053
Iteration 2352, Loss: 6.202249050140381
Iteration 2353, Loss: 5.934700965881348
Iteration 2354, Loss: 5.95682954788208
Iteration 2355, Loss: 6.2516350746154785
Iteration 2356, Loss: 5.699338912963867
Iteration 2357, Loss: 6.129903793334961
Iteration 2358, Loss: 6.165804386138916
Iteration 2359, Loss: 6.051269054412842
Iteration 2360, Loss: 5.885624408721924
Iteration 2361, Loss: 6.056451797485352
Iteration 2362, Loss: 5.793806552886963
Iteration 2363, Loss: 6.124232769012451
Iteration 2364, Loss: 6.0049896240234375
Iteration 2365, Loss: 6.339011192321777
Iteration 2366, Loss: 5.943234443664551
Iteration 2367, Loss: 6.4605712890625
Iteration 2368, Loss: 5.719473838806152
Iteration 2369, Loss: 5.927897930145264
Iteration 2370, Loss: 6.484219551086426
Iteration 2371, Loss: 6.128583908081055
Iteration 2372, Loss: 5.87172269821167
Iteration 2373, Loss: 6.064796447753906
Iteration 2374, Loss: 6.478731632232666
Iteration 2375, Loss: 5.906976699829102
Iteration 2376, Loss: 5.9111328125
Iteration 2377, Loss: 5.810948371887207
Iteration 2378, Loss: 6.623701095581055
Iteration 2379, Loss: 6.1120452880859375
Iteration 2380, Loss: 5.850183486938477
Iteration 2381, Loss: 6.037594795227051
Iteration 2382, Loss: 5.7928314208984375
Iteration 2383, Loss: 5.875532150268555
Iteration 2384, Loss: 5.7674641609191895
Iteration 2385, Loss: 6.029164791107178
Iteration 2386, Loss: 5.836774826049805
Iteration 2387, Loss: 6.009949207305908
Iteration 2388, Loss: 6.385605335235596
Iteration 2389, Loss: 6.008566856384277
Iteration 2390, Loss: 6.129975318908691
Iteration 2391, Loss: 6.106109619140625
Iteration 2392, Loss: 6.095699787139893
Iteration 2393, Loss: 6.241825580596924
Iteration 2394, Loss: 5.978619575500488
Iteration 2395, Loss: 5.826146602630615
Iteration 2396, Loss: 6.104213714599609
Iteration 2397, Loss: 6.20451545715332
Iteration 2398, Loss: 5.754417896270752
Iteration 2399, Loss: 6.246706962585449
Rank 2 | Iteration 2400 | Training in Progress...
Iteration 2400, Loss: 5.792562007904053
Iteration 2401, Loss: 6.026397228240967
Iteration 2402, Loss: 5.918689250946045
Iteration 2403, Loss: 5.910613059997559
Iteration 2404, Loss: 5.998631477355957
Iteration 2405, Loss: 6.102264881134033
Iteration 2406, Loss: 6.048472881317139
Iteration 2407, Loss: 5.741981029510498
Iteration 2408, Loss: 6.00555944442749
Iteration 2409, Loss: 5.988396167755127
Iteration 2410, Loss: 6.176985263824463
Iteration 2411, Loss: 6.510282039642334
Iteration 2412, Loss: 6.1576995849609375
Iteration 2413, Loss: 6.115530014038086
Iteration 2414, Loss: 6.139166355133057
Iteration 2415, Loss: 6.382963180541992
Iteration 2416, Loss: 6.251654624938965
Iteration 2417, Loss: 6.500761985778809
Iteration 2418, Loss: 5.803171157836914
Iteration 2419, Loss: 6.059238910675049
Iteration 2420, Loss: 6.303236961364746
Iteration 2421, Loss: 5.579725742340088
Iteration 2422, Loss: 5.979068756103516
Iteration 2423, Loss: 5.814935684204102
Iteration 2424, Loss: 6.258895397186279
Iteration 2425, Loss: 6.2344818115234375
Iteration 2426, Loss: 6.1504693031311035
Iteration 2427, Loss: 6.093457221984863
Iteration 2428, Loss: 6.042513847351074
Iteration 2429, Loss: 5.978235721588135
Iteration 2430, Loss: 6.574220657348633
Iteration 2431, Loss: 5.984078884124756
Iteration 2432, Loss: 6.051611423492432
Iteration 2433, Loss: 6.0574164390563965
Iteration 2434, Loss: 5.942507266998291
Iteration 2435, Loss: 6.000758171081543
Iteration 2436, Loss: 5.972372055053711
Iteration 2437, Loss: 6.048616409301758
Iteration 2438, Loss: 6.187950134277344
Iteration 2439, Loss: 5.741058349609375
Iteration 2440, Loss: 6.077657699584961
Iteration 2441, Loss: 5.946336269378662
Iteration 2442, Loss: 6.064043045043945
Iteration 2443, Loss: 5.8750529289245605
Iteration 2444, Loss: 5.981576442718506
Iteration 2445, Loss: 6.028875827789307
Iteration 2446, Loss: 5.94191312789917
Iteration 2447, Loss: 6.309177398681641
Iteration 2448, Loss: 5.953534126281738
Iteration 2449, Loss: 6.266453266143799
Iteration 2450, Loss: 6.875855922698975
Iteration 2451, Loss: 6.151896953582764
Iteration 2452, Loss: 5.845676898956299
Iteration 2453, Loss: 6.411382675170898
Iteration 2454, Loss: 5.895586967468262
Iteration 2455, Loss: 5.659422874450684
Iteration 2456, Loss: 6.167853832244873
Iteration 2457, Loss: 6.144588947296143
Iteration 2458, Loss: 6.091996669769287
Iteration 2459, Loss: 5.940412521362305
Iteration 2460, Loss: 5.921818256378174
Iteration 2461, Loss: 5.717578411102295
Iteration 2462, Loss: 6.4714674949646
Iteration 2463, Loss: 6.152615547180176
Iteration 2464, Loss: 5.987189292907715
Iteration 2465, Loss: 5.894865989685059
Iteration 2466, Loss: 5.941362380981445
Iteration 2467, Loss: 6.6767659187316895
Iteration 2468, Loss: 5.909707069396973
Iteration 2469, Loss: 6.5973896980285645
Iteration 2470, Loss: 6.071419715881348
Iteration 2471, Loss: 5.742214202880859
Iteration 2472, Loss: 6.415607452392578
Iteration 2473, Loss: 5.8994951248168945
Iteration 2474, Loss: 6.18059778213501
Iteration 2475, Loss: 6.118155002593994
Iteration 2476, Loss: 6.395369052886963
Iteration 2477, Loss: 5.921687602996826
Iteration 2478, Loss: 6.061726093292236
Iteration 2479, Loss: 5.988316535949707
Iteration 2480, Loss: 6.044915199279785
Iteration 2481, Loss: 6.209832668304443
Iteration 2482, Loss: 6.366128921508789
Iteration 2483, Loss: 6.28219747543335
Iteration 2484, Loss: 6.162463188171387
Iteration 2485, Loss: 6.264904499053955
Iteration 2486, Loss: 6.070316314697266
Iteration 2487, Loss: 6.302779674530029
Iteration 2488, Loss: 6.154713153839111
Iteration 2489, Loss: 5.91996955871582
Iteration 2490, Loss: 5.9005255699157715
Iteration 2491, Loss: 6.331252574920654
Iteration 2492, Loss: 6.106698513031006
Iteration 2493, Loss: 6.212645053863525
Iteration 2494, Loss: 6.04672908782959
Iteration 2495, Loss: 6.046730995178223
Iteration 2496, Loss: 6.21196174621582
Iteration 2497, Loss: 5.876865386962891
Iteration 2498, Loss: 6.010140419006348
Iteration 2499, Loss: 6.0787506103515625
Rank 2 | Iteration 2500 | Training in Progress...
Iteration 2500, Loss: 6.185706615447998
Iteration 2501, Loss: 6.546801567077637
Iteration 2502, Loss: 5.817294120788574
Iteration 2503, Loss: 5.9525227546691895
Iteration 2504, Loss: 6.133069038391113
Iteration 2505, Loss: 6.295332908630371
Iteration 2506, Loss: 5.9766058921813965
Iteration 2507, Loss: 6.3169264793396
Iteration 2508, Loss: 6.025564193725586
Iteration 2509, Loss: 6.029729843139648
Iteration 2510, Loss: 5.796008110046387
Iteration 2511, Loss: 6.0678324699401855
Iteration 2512, Loss: 6.175922870635986
Iteration 2513, Loss: 6.078600883483887
Iteration 2514, Loss: 6.161330699920654
Iteration 2515, Loss: 5.9017109870910645
Iteration 2516, Loss: 6.39858865737915
Iteration 2517, Loss: 5.946975231170654
Iteration 2518, Loss: 6.346325874328613
Iteration 2519, Loss: 5.9683637619018555
Iteration 2520, Loss: 6.124576091766357
Iteration 2521, Loss: 5.8938984870910645
Iteration 2522, Loss: 5.822645664215088
Iteration 2523, Loss: 6.262488842010498
Iteration 2524, Loss: 6.277688503265381
Iteration 2525, Loss: 6.303383827209473
Iteration 2526, Loss: 6.504577159881592
Iteration 2527, Loss: 5.988231182098389
Iteration 2528, Loss: 6.0709733963012695
Iteration 2529, Loss: 5.821285247802734
Iteration 2530, Loss: 5.970884323120117
Iteration 2531, Loss: 6.028807640075684
Iteration 2532, Loss: 6.208080768585205
Iteration 2533, Loss: 5.98228645324707
Iteration 2534, Loss: 5.913416385650635
Iteration 2535, Loss: 5.798421382904053
Iteration 2536, Loss: 5.938699722290039
Iteration 2537, Loss: 5.979219436645508
Iteration 2538, Loss: 5.792360305786133
Iteration 2539, Loss: 5.997353553771973
Iteration 2540, Loss: 6.358659744262695
Iteration 2541, Loss: 6.18264102935791
Iteration 2542, Loss: 6.120758056640625
Iteration 2543, Loss: 5.637611389160156
Iteration 2544, Loss: 5.812124729156494
Iteration 2545, Loss: 6.187889575958252
Iteration 2546, Loss: 6.581587314605713
Iteration 2547, Loss: 6.434022903442383
Iteration 2548, Loss: 5.75797176361084
Iteration 2549, Loss: 5.8176655769348145
Iteration 2550, Loss: 5.943779945373535
Iteration 2551, Loss: 5.862983703613281
Iteration 2552, Loss: 6.524791717529297
Iteration 2553, Loss: 6.209506034851074
Iteration 2554, Loss: 6.329640865325928
Iteration 2555, Loss: 5.7165961265563965
Iteration 2556, Loss: 6.307966232299805
Iteration 2557, Loss: 6.70217227935791
Iteration 2558, Loss: 5.848955154418945
Iteration 2559, Loss: 6.191652774810791
Iteration 2560, Loss: 6.06650972366333
Iteration 2561, Loss: 6.1279802322387695
Iteration 2562, Loss: 6.475133419036865
Iteration 2563, Loss: 5.873754501342773
Iteration 2564, Loss: 5.679991245269775
Iteration 2565, Loss: 6.118967056274414
Iteration 2566, Loss: 6.000950813293457
Iteration 2567, Loss: 6.534096717834473
Iteration 2568, Loss: 6.192047119140625
Iteration 2569, Loss: 5.922758102416992
Iteration 2570, Loss: 6.048954963684082
Iteration 2571, Loss: 6.331202507019043
Iteration 2572, Loss: 6.23659086227417
Iteration 2573, Loss: 6.287503719329834
Iteration 2574, Loss: 5.971628189086914
Iteration 2575, Loss: 6.133291244506836
Iteration 2576, Loss: 6.091556549072266
Iteration 2577, Loss: 6.470314979553223
Iteration 2578, Loss: 6.466907024383545
Iteration 2579, Loss: 6.277944564819336
Iteration 2580, Loss: 5.866177558898926
Iteration 2581, Loss: 6.046757221221924
Iteration 2582, Loss: 6.029677867889404
Iteration 2583, Loss: 6.190985202789307
Iteration 2584, Loss: 6.013095378875732
Iteration 2585, Loss: 6.01058292388916
Iteration 2586, Loss: 6.107458114624023
Iteration 2587, Loss: 6.028069019317627
Iteration 2588, Loss: 6.050045967102051
Iteration 2589, Loss: 6.125741958618164
Iteration 2590, Loss: 6.1074090003967285
Iteration 2591, Loss: 6.005392551422119
Iteration 2592, Loss: 5.665041446685791
Iteration 2593, Loss: 6.131241798400879
Iteration 2594, Loss: 6.042963981628418
Iteration 2595, Loss: 5.940909385681152
Iteration 2596, Loss: 6.483134746551514
Iteration 2597, Loss: 6.273688316345215
Iteration 2598, Loss: 6.684150695800781
Iteration 2599, Loss: 6.323538780212402
Rank 2 | Iteration 2600 | Training in Progress...
Iteration 2600, Loss: 5.957370758056641
Iteration 2601, Loss: 6.033586025238037
Iteration 2602, Loss: 6.309414386749268
Iteration 2603, Loss: 6.047645092010498
Iteration 2604, Loss: 6.37718391418457
Iteration 2605, Loss: 5.984487056732178
Iteration 2606, Loss: 6.008807182312012
Iteration 2607, Loss: 6.203652858734131
Iteration 2608, Loss: 5.944894790649414
Iteration 2609, Loss: 6.38551139831543
Iteration 2610, Loss: 6.1184587478637695
Iteration 2611, Loss: 6.374443054199219
Iteration 2612, Loss: 6.184456825256348
Iteration 2613, Loss: 6.199544429779053
Iteration 2614, Loss: 5.771855354309082
Iteration 2615, Loss: 6.379490852355957
Iteration 2616, Loss: 6.455437183380127
Iteration 2617, Loss: 5.916513919830322
Iteration 2618, Loss: 6.057461261749268
Iteration 2619, Loss: 6.315598011016846
Iteration 2620, Loss: 5.783115386962891
Iteration 2621, Loss: 6.025461196899414
Iteration 2622, Loss: 5.887373924255371
Iteration 2623, Loss: 5.8547492027282715
Iteration 2624, Loss: 5.972627639770508
Iteration 2625, Loss: 6.333393096923828
Iteration 2626, Loss: 6.333283424377441
Iteration 2627, Loss: 6.212815761566162
Iteration 2628, Loss: 6.225715637207031
Iteration 2629, Loss: 5.9934306144714355
Iteration 2630, Loss: 6.076226234436035
Iteration 2631, Loss: 6.137491703033447
Iteration 2632, Loss: 6.3374786376953125
Iteration 2633, Loss: 5.9973464012146
Iteration 2634, Loss: 6.298188209533691
Iteration 2635, Loss: 5.85161018371582
Iteration 2636, Loss: 5.720165729522705
Iteration 2637, Loss: 5.931889057159424
Iteration 2638, Loss: 6.161269187927246
Iteration 2639, Loss: 6.134149074554443
Iteration 2640, Loss: 5.814797878265381
Iteration 2641, Loss: 6.116353511810303
Iteration 2642, Loss: 6.206331729888916
Iteration 2643, Loss: 6.160301685333252
Iteration 2644, Loss: 6.138410568237305
Iteration 2645, Loss: 5.985654354095459
Iteration 2646, Loss: 6.509643077850342
Iteration 2647, Loss: 6.1369709968566895
Iteration 2648, Loss: 6.187204360961914
Iteration 2649, Loss: 5.8354926109313965
Iteration 2650, Loss: 6.449347972869873
Iteration 2651, Loss: 6.416957855224609
Iteration 2652, Loss: 6.127395153045654
Iteration 2653, Loss: 5.787225246429443
Iteration 2654, Loss: 6.200011253356934
Iteration 2655, Loss: 6.138528347015381
Iteration 2656, Loss: 6.125137805938721
Iteration 2657, Loss: 6.092243194580078
Iteration 2658, Loss: 6.062028884887695
Iteration 2659, Loss: 5.751654148101807
Iteration 2660, Loss: 6.019505977630615
Iteration 2661, Loss: 5.883566856384277
Iteration 2662, Loss: 6.159297943115234
Iteration 2663, Loss: 5.8859381675720215
Iteration 2664, Loss: 5.865723609924316
Iteration 2665, Loss: 5.855041980743408
Iteration 2666, Loss: 5.830781936645508
Iteration 2667, Loss: 6.042095184326172
Iteration 2668, Loss: 6.203061580657959
Iteration 2669, Loss: 6.073137283325195
Iteration 2670, Loss: 5.712676525115967
Iteration 2671, Loss: 6.292654514312744
Iteration 2672, Loss: 6.009555339813232
Iteration 2673, Loss: 5.906275272369385
Iteration 2674, Loss: 5.9223313331604
Iteration 2675, Loss: 6.136912822723389
Iteration 2676, Loss: 6.12781286239624
Iteration 2677, Loss: 6.31814432144165
Iteration 2678, Loss: 5.973410129547119
Iteration 2679, Loss: 6.079016208648682
Iteration 2680, Loss: 6.188014030456543
Iteration 2681, Loss: 6.131446361541748
Iteration 2682, Loss: 6.418879508972168
Iteration 2683, Loss: 6.283120632171631
Iteration 2684, Loss: 6.14088249206543
Iteration 2685, Loss: 6.091886043548584
Iteration 2686, Loss: 6.11860990524292
Iteration 2687, Loss: 5.733987808227539
Iteration 2688, Loss: 6.122810363769531
Iteration 2689, Loss: 6.089328765869141
Iteration 2690, Loss: 5.890819072723389
Iteration 2691, Loss: 6.029851913452148
Iteration 2692, Loss: 5.895802974700928
Iteration 2693, Loss: 6.064332962036133
Iteration 2694, Loss: 5.89625883102417
Iteration 2695, Loss: 6.435918807983398
Iteration 2696, Loss: 6.057117938995361
Iteration 2697, Loss: 5.919545650482178
Iteration 2698, Loss: 6.1784796714782715
Iteration 2699, Loss: 5.901722431182861
Rank 2 | Iteration 2700 | Training in Progress...
Iteration 2700, Loss: 6.426219463348389
Iteration 2701, Loss: 5.886826038360596
Iteration 2702, Loss: 6.12760591506958
Iteration 2703, Loss: 6.173676013946533
Iteration 2704, Loss: 5.823661804199219
Iteration 2705, Loss: 6.166268348693848
Iteration 2706, Loss: 5.9884114265441895
Iteration 2707, Loss: 6.047991752624512
Iteration 2708, Loss: 5.927318572998047
Iteration 2709, Loss: 6.729259490966797
Iteration 2710, Loss: 6.50501823425293
Iteration 2711, Loss: 5.994012355804443
Iteration 2712, Loss: 5.9684906005859375
Iteration 2713, Loss: 6.10713005065918
Iteration 2714, Loss: 5.923066139221191
Iteration 2715, Loss: 5.98786735534668
Iteration 2716, Loss: 6.334487438201904
Iteration 2717, Loss: 5.929385185241699
Iteration 2718, Loss: 6.296844482421875
Iteration 2719, Loss: 5.944519996643066
Iteration 2720, Loss: 6.322248935699463
Iteration 2721, Loss: 6.333064079284668
Iteration 2722, Loss: 5.834489822387695
Iteration 2723, Loss: 6.252211570739746
Iteration 2724, Loss: 6.002423286437988
Iteration 2725, Loss: 6.337564945220947
Iteration 2726, Loss: 6.021373271942139
Iteration 2727, Loss: 6.021862030029297
Iteration 2728, Loss: 6.3191447257995605
Iteration 2729, Loss: 6.034964084625244
Iteration 2730, Loss: 6.285855770111084
Iteration 2731, Loss: 6.202314853668213
Iteration 2732, Loss: 6.136543273925781
Iteration 2733, Loss: 5.8451666831970215
Iteration 2734, Loss: 6.237038612365723
Iteration 2735, Loss: 5.912214756011963
Iteration 2736, Loss: 6.021518230438232
Iteration 2737, Loss: 6.129109859466553
Iteration 2738, Loss: 5.881809711456299
Iteration 2739, Loss: 5.817601680755615
Iteration 2740, Loss: 6.129587650299072
Iteration 2741, Loss: 6.135777473449707
Iteration 2742, Loss: 6.348583221435547
Iteration 2743, Loss: 6.193809986114502
Iteration 2744, Loss: 5.769461631774902
Iteration 2745, Loss: 5.914978981018066
Iteration 2746, Loss: 6.006861686706543
Iteration 2747, Loss: 6.229732036590576
Iteration 2748, Loss: 6.4934186935424805
Iteration 2749, Loss: 5.946306228637695
Iteration 2750, Loss: 5.653593063354492
Iteration 2751, Loss: 6.044422149658203
Iteration 2752, Loss: 5.968877792358398
Iteration 2753, Loss: 6.1779961585998535
Iteration 2754, Loss: 5.7241997718811035
Iteration 2755, Loss: 5.921092987060547
Iteration 2756, Loss: 6.207406520843506
Iteration 2757, Loss: 5.942981243133545
Iteration 2758, Loss: 6.149981498718262
Iteration 2759, Loss: 5.980611801147461
Iteration 2760, Loss: 6.181574821472168
Iteration 2761, Loss: 6.036963939666748
Iteration 2762, Loss: 6.048712730407715
Iteration 2763, Loss: 6.211512088775635
Iteration 2764, Loss: 6.297027111053467
Iteration 2765, Loss: 6.3106465339660645
Iteration 2766, Loss: 6.230130672454834
Iteration 2767, Loss: 6.352919101715088
Iteration 2768, Loss: 6.110920429229736
Iteration 2769, Loss: 6.501134872436523
Iteration 2770, Loss: 6.284746170043945
Iteration 2771, Loss: 6.344092845916748
Iteration 2772, Loss: 6.037850856781006
Iteration 2773, Loss: 6.061679840087891
Iteration 2774, Loss: 5.9620280265808105
Iteration 2775, Loss: 6.013247013092041
Iteration 2776, Loss: 6.089662551879883
Iteration 2777, Loss: 6.71481466293335
Iteration 2778, Loss: 6.372401237487793
Iteration 2779, Loss: 6.172536849975586
Iteration 2780, Loss: 5.803180694580078
Iteration 2781, Loss: 6.169127941131592
Iteration 2782, Loss: 5.994935512542725
Iteration 2783, Loss: 5.802123546600342
Iteration 2784, Loss: 6.132422924041748
Iteration 2785, Loss: 5.807821273803711
Iteration 2786, Loss: 6.075826168060303
Iteration 2787, Loss: 6.108799457550049
Iteration 2788, Loss: 6.179111480712891
Iteration 2789, Loss: 5.967466831207275
Iteration 2790, Loss: 5.796670913696289
Iteration 2791, Loss: 5.924198627471924
Iteration 2792, Loss: 6.300758361816406
Iteration 2793, Loss: 6.370568752288818
Iteration 2794, Loss: 6.2714080810546875
Iteration 2795, Loss: 6.2984724044799805
Iteration 2796, Loss: 6.261239528656006
Iteration 2797, Loss: 6.079524040222168
Iteration 2798, Loss: 6.296991348266602
Iteration 2799, Loss: 6.056736946105957
Rank 2 | Iteration 2800 | Training in Progress...
Iteration 2800, Loss: 5.80441951751709
Iteration 2801, Loss: 6.195624828338623
Iteration 2802, Loss: 5.814411640167236
Iteration 2803, Loss: 6.049093246459961
Iteration 2804, Loss: 6.2221150398254395
Iteration 2805, Loss: 5.984277248382568
Iteration 2806, Loss: 5.894824504852295
Iteration 2807, Loss: 6.24550199508667
Iteration 2808, Loss: 6.1028289794921875
Iteration 2809, Loss: 6.062192916870117
Iteration 2810, Loss: 6.121382236480713
Iteration 2811, Loss: 6.239777088165283
Iteration 2812, Loss: 6.590905666351318
Iteration 2813, Loss: 6.0742340087890625
Iteration 2814, Loss: 6.033285617828369
Iteration 2815, Loss: 6.072153091430664
Iteration 2816, Loss: 5.679323196411133
Iteration 2817, Loss: 6.126802444458008
Iteration 2818, Loss: 5.8960723876953125
Iteration 2819, Loss: 6.063300609588623
Iteration 2820, Loss: 5.71030855178833
Iteration 2821, Loss: 6.012523174285889
Iteration 2822, Loss: 6.232822895050049
Iteration 2823, Loss: 5.955382347106934
Iteration 2824, Loss: 5.939792633056641
Iteration 2825, Loss: 6.322382926940918
Iteration 2826, Loss: 6.213071823120117
Iteration 2827, Loss: 5.962474346160889
Iteration 2828, Loss: 6.080013751983643
Iteration 2829, Loss: 6.253603935241699
Iteration 2830, Loss: 6.141633033752441
Iteration 2831, Loss: 6.103569507598877
Iteration 2832, Loss: 5.988489151000977
Iteration 2833, Loss: 6.240256309509277
Iteration 2834, Loss: 6.2371134757995605
Iteration 2835, Loss: 6.181834697723389
Iteration 2836, Loss: 6.038850784301758
Iteration 2837, Loss: 6.1120991706848145
Iteration 2838, Loss: 6.168181896209717
Iteration 2839, Loss: 6.237428665161133
Iteration 2840, Loss: 6.05076789855957
Iteration 2841, Loss: 5.927228927612305
Iteration 2842, Loss: 6.0815749168396
Iteration 2843, Loss: 6.286971569061279
Iteration 2844, Loss: 6.146047115325928
Iteration 2845, Loss: 5.728835105895996
Iteration 2846, Loss: 5.985563278198242
Iteration 2847, Loss: 5.88695764541626
Iteration 2848, Loss: 6.197605133056641
Iteration 2849, Loss: 6.230803489685059
Iteration 2850, Loss: 6.101700782775879
Iteration 2851, Loss: 6.223884105682373
Iteration 2852, Loss: 6.211093425750732
Iteration 2853, Loss: 6.0655436515808105
Iteration 2854, Loss: 6.076415538787842
Iteration 2855, Loss: 5.992038726806641
Iteration 2856, Loss: 6.3451361656188965
Iteration 2857, Loss: 6.586373329162598
Iteration 2858, Loss: 6.417052745819092
Iteration 2859, Loss: 5.781126976013184
Iteration 2860, Loss: 6.265242099761963
Iteration 2861, Loss: 5.806685924530029
Iteration 2862, Loss: 5.810074329376221
Iteration 2863, Loss: 6.030402183532715
Iteration 2864, Loss: 6.109827518463135
Iteration 2865, Loss: 6.298737525939941
Iteration 2866, Loss: 6.214524269104004
Iteration 2867, Loss: 6.007978439331055
Iteration 2868, Loss: 6.177798748016357
Iteration 2869, Loss: 6.277053356170654
Iteration 2870, Loss: 6.280518531799316
Iteration 2871, Loss: 5.949921131134033
Iteration 2872, Loss: 6.327953815460205
Iteration 2873, Loss: 5.902323246002197
Iteration 2874, Loss: 6.141493320465088
Iteration 2875, Loss: 5.776148796081543
Iteration 2876, Loss: 6.340641021728516
Iteration 2877, Loss: 6.217556476593018
Iteration 2878, Loss: 6.0830841064453125
Iteration 2879, Loss: 6.569051265716553
Iteration 2880, Loss: 6.412791728973389
Iteration 2881, Loss: 5.8499250411987305
Iteration 2882, Loss: 6.425808429718018
Iteration 2883, Loss: 5.853471279144287
Iteration 2884, Loss: 5.762995719909668
Iteration 2885, Loss: 5.8000102043151855
Iteration 2886, Loss: 6.0771989822387695
Iteration 2887, Loss: 6.043700695037842
Iteration 2888, Loss: 6.125418186187744
Iteration 2889, Loss: 6.188871383666992
Iteration 2890, Loss: 6.415068626403809
Iteration 2891, Loss: 6.246606826782227
Iteration 2892, Loss: 6.100296974182129
Iteration 2893, Loss: 6.418336868286133
Iteration 2894, Loss: 5.9019341468811035
Iteration 2895, Loss: 6.162203788757324
Iteration 2896, Loss: 6.236344337463379
Iteration 2897, Loss: 6.022374153137207
Iteration 2898, Loss: 6.028221607208252
Iteration 2899, Loss: 6.3104777336120605
Rank 2 | Iteration 2900 | Training in Progress...
Iteration 2900, Loss: 5.744100570678711
Iteration 2901, Loss: 6.226174354553223
Iteration 2902, Loss: 6.271024703979492
Iteration 2903, Loss: 5.755650043487549
Iteration 2904, Loss: 6.285634994506836
Iteration 2905, Loss: 5.881615161895752
Iteration 2906, Loss: 6.1386590003967285
Iteration 2907, Loss: 5.913844108581543
Iteration 2908, Loss: 5.634232044219971
Iteration 2909, Loss: 6.014425277709961
Iteration 2910, Loss: 5.97991418838501
Iteration 2911, Loss: 6.099476337432861
Iteration 2912, Loss: 6.32619571685791
Iteration 2913, Loss: 6.233968734741211
Iteration 2914, Loss: 6.091503143310547
Iteration 2915, Loss: 5.710136413574219
Iteration 2916, Loss: 5.721844673156738
Iteration 2917, Loss: 6.044571876525879
Iteration 2918, Loss: 5.912163257598877
Iteration 2919, Loss: 5.8736090660095215
Iteration 2920, Loss: 6.272974967956543
Iteration 2921, Loss: 6.1662726402282715
Iteration 2922, Loss: 6.219137668609619
Iteration 2923, Loss: 5.904538631439209
Iteration 2924, Loss: 6.136632919311523
Iteration 2925, Loss: 6.114688396453857
Iteration 2926, Loss: 6.159572601318359
Iteration 2927, Loss: 6.141232967376709
Iteration 2928, Loss: 6.136251926422119
Iteration 2929, Loss: 6.310286045074463
Iteration 2930, Loss: 6.138614654541016
Iteration 2931, Loss: 6.145874977111816
Iteration 2932, Loss: 6.10139799118042
Iteration 2933, Loss: 6.21351432800293
Iteration 2934, Loss: 6.1812920570373535
Iteration 2935, Loss: 5.8038177490234375
Iteration 2936, Loss: 6.385600566864014
Iteration 2937, Loss: 5.695510387420654
Iteration 2938, Loss: 5.834293842315674
Iteration 2939, Loss: 5.922743797302246
Iteration 2940, Loss: 5.969046592712402
Iteration 2941, Loss: 6.052914619445801
Iteration 2942, Loss: 6.0472307205200195
Iteration 2943, Loss: 5.876028060913086
Iteration 2944, Loss: 5.617489337921143
Iteration 2945, Loss: 6.282100200653076
Iteration 2946, Loss: 6.416482925415039
Iteration 2947, Loss: 6.044033050537109
Iteration 2948, Loss: 6.2902960777282715
Iteration 2949, Loss: 5.9422760009765625
Iteration 2950, Loss: 6.124344825744629
Iteration 2951, Loss: 6.018803119659424
Iteration 2952, Loss: 6.328676223754883
Iteration 2953, Loss: 5.799735069274902
Iteration 2954, Loss: 6.2468109130859375
Iteration 2955, Loss: 5.999783992767334
Iteration 2956, Loss: 6.5199761390686035
Iteration 2957, Loss: 6.1175312995910645
Iteration 2958, Loss: 6.127857685089111
Iteration 2959, Loss: 6.18084192276001
Iteration 2960, Loss: 6.02895450592041
Iteration 2961, Loss: 5.961368083953857
Iteration 2962, Loss: 6.211158275604248
Iteration 2963, Loss: 5.999329566955566
Iteration 2964, Loss: 5.765350341796875
Iteration 2965, Loss: 6.35459041595459
Iteration 2966, Loss: 6.420319080352783
Iteration 2967, Loss: 5.825720310211182
Iteration 2968, Loss: 6.6303277015686035
Iteration 2969, Loss: 5.766373157501221
Iteration 2970, Loss: 6.512193202972412
Iteration 2971, Loss: 6.025650978088379
Iteration 2972, Loss: 5.813577651977539
Iteration 2973, Loss: 5.94071102142334
Iteration 2974, Loss: 5.862364292144775
Iteration 2975, Loss: 5.844964027404785
Iteration 2976, Loss: 6.175138473510742
Iteration 2977, Loss: 6.0084614753723145
Iteration 2978, Loss: 5.955557823181152
Iteration 2979, Loss: 6.174441337585449
Iteration 2980, Loss: 6.100079536437988
Iteration 2981, Loss: 5.849681377410889
Iteration 2982, Loss: 6.129209518432617
Iteration 2983, Loss: 6.218296051025391
Iteration 2984, Loss: 6.181656360626221
Iteration 2985, Loss: 5.842939853668213
Iteration 2986, Loss: 6.011164665222168
Iteration 2987, Loss: 6.457676887512207
Iteration 2988, Loss: 5.803168773651123
Iteration 2989, Loss: 5.960063457489014
Iteration 2990, Loss: 5.901155471801758
Iteration 2991, Loss: 6.1604228019714355
Iteration 2992, Loss: 6.106672763824463
Iteration 2993, Loss: 6.135710716247559
Iteration 2994, Loss: 6.188040256500244
Iteration 2995, Loss: 6.021744251251221
Iteration 2996, Loss: 6.044719219207764
Iteration 2997, Loss: 5.746598720550537
Iteration 2998, Loss: 5.600198745727539
Iteration 2999, Loss: 5.8993916511535645
Rank 2 | Iteration 3000 | Training in Progress...
Iteration 3000, Loss: 6.1701741218566895
Iteration 3001, Loss: 6.28083610534668
Iteration 3002, Loss: 6.048769950866699
Iteration 3003, Loss: 6.410427570343018
Iteration 3004, Loss: 6.104657173156738
Iteration 3005, Loss: 6.187907695770264
Iteration 3006, Loss: 5.791524887084961
Iteration 3007, Loss: 5.858718395233154
Iteration 3008, Loss: 5.955784797668457
Iteration 3009, Loss: 6.042263031005859
Iteration 3010, Loss: 6.238131999969482
Iteration 3011, Loss: 6.019469738006592
Iteration 3012, Loss: 6.026950836181641
Iteration 3013, Loss: 5.89390230178833
Iteration 3014, Loss: 6.058751583099365
Iteration 3015, Loss: 6.358342170715332
Iteration 3016, Loss: 6.1588969230651855
Iteration 3017, Loss: 6.10275411605835
Iteration 3018, Loss: 6.213776111602783
Iteration 3019, Loss: 5.833489894866943
Iteration 3020, Loss: 6.361198902130127
Iteration 3021, Loss: 6.103270530700684
Iteration 3022, Loss: 6.031444072723389
Iteration 3023, Loss: 6.116537570953369
Iteration 3024, Loss: 6.061278343200684
Iteration 3025, Loss: 6.034975051879883
Iteration 3026, Loss: 6.095849514007568
Iteration 3027, Loss: 5.775088310241699
Iteration 3028, Loss: 6.191993236541748
Iteration 3029, Loss: 5.976495265960693
Iteration 3030, Loss: 6.335473537445068
Iteration 3031, Loss: 5.770387649536133
Iteration 3032, Loss: 6.252246856689453
Iteration 3033, Loss: 5.92147970199585
Iteration 3034, Loss: 6.116517066955566
Iteration 3035, Loss: 6.2986555099487305
Iteration 3036, Loss: 5.887101173400879
Iteration 3037, Loss: 6.0594563484191895
Iteration 3038, Loss: 6.516421318054199
Iteration 3039, Loss: 6.0044074058532715
Iteration 3040, Loss: 6.327140808105469
Iteration 3041, Loss: 6.37436056137085
Iteration 3042, Loss: 6.134274959564209
Iteration 3043, Loss: 6.137665271759033
Iteration 3044, Loss: 6.4897356033325195
Iteration 3045, Loss: 6.084800720214844
Iteration 3046, Loss: 6.221691608428955
Iteration 3047, Loss: 5.939953804016113
Iteration 3048, Loss: 6.360466003417969
Iteration 3049, Loss: 5.998233318328857
Iteration 3050, Loss: 5.844283580780029
Iteration 3051, Loss: 6.068148136138916
Iteration 3052, Loss: 5.892866134643555
Iteration 3053, Loss: 6.078572750091553
Iteration 3054, Loss: 6.022618770599365
Iteration 3055, Loss: 5.68604850769043
Iteration 3056, Loss: 5.934081554412842
Iteration 3057, Loss: 6.186333656311035
Iteration 3058, Loss: 5.924795627593994
Iteration 3059, Loss: 5.842209339141846
Iteration 3060, Loss: 6.636013507843018
Iteration 3061, Loss: 6.130699634552002
Iteration 3062, Loss: 5.973680019378662
Iteration 3063, Loss: 6.411646366119385
Iteration 3064, Loss: 6.003860950469971
Iteration 3065, Loss: 5.810827255249023
Iteration 3066, Loss: 6.507386684417725
Iteration 3067, Loss: 6.184770107269287
Iteration 3068, Loss: 6.068864345550537
Iteration 3069, Loss: 6.23903751373291
Iteration 3070, Loss: 6.034991264343262
Iteration 3071, Loss: 6.079111099243164
Iteration 3072, Loss: 5.8642802238464355
Iteration 3073, Loss: 5.952794551849365
Iteration 3074, Loss: 5.772578716278076
Iteration 3075, Loss: 6.388576507568359
Iteration 3076, Loss: 5.897464275360107
Iteration 3077, Loss: 6.104752063751221
Iteration 3078, Loss: 5.991405487060547
Iteration 3079, Loss: 6.02872896194458
Iteration 3080, Loss: 6.149757385253906
Iteration 3081, Loss: 6.059473514556885
Iteration 3082, Loss: 5.931403636932373
Iteration 3083, Loss: 5.991828441619873
Iteration 3084, Loss: 5.758067607879639
Iteration 3085, Loss: 6.223735332489014
Iteration 3086, Loss: 6.154433727264404
Iteration 3087, Loss: 5.997104167938232
Iteration 3088, Loss: 6.159426212310791
Iteration 3089, Loss: 5.805974960327148
Iteration 3090, Loss: 6.155299663543701
Iteration 3091, Loss: 6.262749195098877
Iteration 3092, Loss: 6.076700210571289
Iteration 3093, Loss: 6.03075647354126
Iteration 3094, Loss: 6.26242208480835
Iteration 3095, Loss: 5.983918190002441
Iteration 3096, Loss: 5.780031204223633
Iteration 3097, Loss: 5.973209381103516
Iteration 3098, Loss: 5.9811692237854
Iteration 3099, Loss: 5.966128349304199
Rank 2 | Iteration 3100 | Training in Progress...
Iteration 3100, Loss: 6.101139545440674
Iteration 3101, Loss: 6.323940277099609
Iteration 3102, Loss: 5.916337013244629
Iteration 3103, Loss: 5.8532795906066895
Iteration 3104, Loss: 6.274988174438477
Iteration 3105, Loss: 6.162991523742676
Iteration 3106, Loss: 5.984523773193359
Iteration 3107, Loss: 5.821997165679932
Iteration 3108, Loss: 5.784287929534912
Iteration 3109, Loss: 6.291332244873047
Iteration 3110, Loss: 6.162415981292725
Iteration 3111, Loss: 6.250495433807373
Iteration 3112, Loss: 6.174654006958008
Iteration 3113, Loss: 6.048163414001465
Iteration 3114, Loss: 6.034538745880127
Iteration 3115, Loss: 5.792731761932373
Iteration 3116, Loss: 5.979687690734863
Iteration 3117, Loss: 5.955412864685059
Iteration 3118, Loss: 6.033975601196289
Iteration 3119, Loss: 5.901493549346924
Iteration 3120, Loss: 6.172379970550537
Iteration 3121, Loss: 6.382165908813477
Iteration 3122, Loss: 6.229373455047607
Iteration 3123, Loss: 6.100919723510742
Iteration 3124, Loss: 5.986608982086182
Iteration 3125, Loss: 5.764101028442383
Iteration 3126, Loss: 6.061030864715576
Iteration 3127, Loss: 6.199539661407471
Iteration 3128, Loss: 6.16409969329834
Iteration 3129, Loss: 6.12103796005249
Iteration 3130, Loss: 5.804661750793457
Iteration 3131, Loss: 5.8423566818237305
Iteration 3132, Loss: 6.080175876617432
Iteration 3133, Loss: 6.1461181640625
Iteration 3134, Loss: 5.735363483428955
Iteration 3135, Loss: 5.834604263305664
Iteration 3136, Loss: 5.9220099449157715
Iteration 3137, Loss: 5.974417209625244
Iteration 3138, Loss: 6.209909915924072
Iteration 3139, Loss: 6.011216163635254
Iteration 3140, Loss: 6.080203056335449
Iteration 3141, Loss: 5.856395721435547
Iteration 3142, Loss: 6.278113842010498
Iteration 3143, Loss: 6.154691219329834
Iteration 3144, Loss: 6.0831122398376465
Iteration 3145, Loss: 5.797338008880615
Iteration 3146, Loss: 6.294643402099609
Iteration 3147, Loss: 6.223221302032471
Iteration 3148, Loss: 5.9711012840271
Iteration 3149, Loss: 6.12022066116333
Iteration 3150, Loss: 5.961872577667236
Iteration 3151, Loss: 5.817932605743408
Iteration 3152, Loss: 6.393398761749268
Iteration 3153, Loss: 5.827907085418701
Iteration 3154, Loss: 6.274956226348877
Iteration 3155, Loss: 6.173298358917236
Iteration 3156, Loss: 5.989583492279053
Iteration 3157, Loss: 6.1363844871521
Iteration 3158, Loss: 6.051334857940674
Iteration 3159, Loss: 6.037191867828369
Iteration 3160, Loss: 5.993659019470215
Iteration 3161, Loss: 6.205583572387695
Iteration 3162, Loss: 6.500150203704834
Iteration 3163, Loss: 5.953205108642578
Iteration 3164, Loss: 6.239055156707764
Iteration 3165, Loss: 6.043686866760254
Iteration 3166, Loss: 5.989377498626709
Iteration 3167, Loss: 5.932820796966553
Iteration 3168, Loss: 6.065975666046143
Iteration 3169, Loss: 6.322958469390869
Iteration 3170, Loss: 6.47886848449707
Iteration 3171, Loss: 6.128875732421875
Iteration 3172, Loss: 6.0050787925720215
Iteration 3173, Loss: 6.129836082458496
Iteration 3174, Loss: 5.985386371612549
Iteration 3175, Loss: 6.013155460357666
Iteration 3176, Loss: 6.06194543838501
Iteration 3177, Loss: 5.9369215965271
Iteration 3178, Loss: 6.179536819458008
Iteration 3179, Loss: 6.307787895202637
Iteration 3180, Loss: 6.099557399749756
Iteration 3181, Loss: 6.185451030731201
Iteration 3182, Loss: 5.793351650238037
Iteration 3183, Loss: 5.98209285736084
Iteration 3184, Loss: 6.15922737121582
Iteration 3185, Loss: 5.953184127807617
Iteration 3186, Loss: 6.425795555114746
Iteration 3187, Loss: 6.061469078063965
Iteration 3188, Loss: 6.0972137451171875
Iteration 3189, Loss: 6.1467132568359375
Iteration 3190, Loss: 5.93804407119751
Iteration 3191, Loss: 6.187030792236328
Iteration 3192, Loss: 6.207996845245361
Iteration 3193, Loss: 6.375062465667725
Iteration 3194, Loss: 5.762301921844482
Iteration 3195, Loss: 6.0599045753479
Iteration 3196, Loss: 6.282148361206055
Iteration 3197, Loss: 6.264432907104492
Iteration 3198, Loss: 5.857577323913574
Iteration 3199, Loss: 5.8690314292907715
Rank 2 | Iteration 3200 | Training in Progress...
Iteration 3200, Loss: 6.186197280883789
Iteration 3201, Loss: 5.8184075355529785
Iteration 3202, Loss: 5.958446502685547
Iteration 3203, Loss: 6.309170722961426
Iteration 3204, Loss: 5.887445449829102
Iteration 3205, Loss: 6.345314979553223
Iteration 3206, Loss: 6.426269054412842
Iteration 3207, Loss: 5.97537088394165
Iteration 3208, Loss: 6.27664852142334
Iteration 3209, Loss: 5.958554744720459
Iteration 3210, Loss: 6.487557888031006
Iteration 3211, Loss: 6.183699131011963
Iteration 3212, Loss: 6.331326961517334
Iteration 3213, Loss: 5.75907039642334
Iteration 3214, Loss: 6.200930118560791
Iteration 3215, Loss: 6.3636250495910645
Iteration 3216, Loss: 5.941074371337891
Iteration 3217, Loss: 6.273753643035889
Iteration 3218, Loss: 6.309736728668213
Iteration 3219, Loss: 6.010769367218018
Iteration 3220, Loss: 6.03817081451416
Iteration 3221, Loss: 6.073683738708496
Iteration 3222, Loss: 6.0195631980896
Iteration 3223, Loss: 6.658755302429199
Iteration 3224, Loss: 6.063716411590576
Iteration 3225, Loss: 6.159917831420898
Iteration 3226, Loss: 5.981081008911133
Iteration 3227, Loss: 6.011519908905029
Iteration 3228, Loss: 6.090620040893555
Iteration 3229, Loss: 6.207319736480713
Iteration 3230, Loss: 5.908233642578125
Iteration 3231, Loss: 5.9600701332092285
Iteration 3232, Loss: 6.169267654418945
Iteration 3233, Loss: 6.415302753448486
Iteration 3234, Loss: 6.181006908416748
Iteration 3235, Loss: 5.905765056610107
Iteration 3236, Loss: 6.147275447845459
Iteration 3237, Loss: 6.003395080566406
Iteration 3238, Loss: 6.03126335144043
Iteration 3239, Loss: 6.004188537597656
Iteration 3240, Loss: 5.962435245513916
Iteration 3241, Loss: 6.451533794403076
Iteration 3242, Loss: 6.0941948890686035
Iteration 3243, Loss: 6.021878242492676
Iteration 3244, Loss: 6.249306678771973
Iteration 3245, Loss: 6.113020420074463
Iteration 3246, Loss: 6.277804851531982
Iteration 3247, Loss: 5.820664405822754
Iteration 3248, Loss: 5.882706165313721
Iteration 3249, Loss: 6.198062419891357
Iteration 3250, Loss: 6.161098003387451
Iteration 3251, Loss: 6.044260025024414
Iteration 3252, Loss: 6.287929534912109
Iteration 3253, Loss: 6.219018936157227
Iteration 3254, Loss: 5.895537376403809
Iteration 3255, Loss: 5.7004852294921875
Iteration 3256, Loss: 6.117136001586914
Iteration 3257, Loss: 6.071430683135986
Iteration 3258, Loss: 5.781248092651367
Iteration 3259, Loss: 5.956215858459473
Iteration 3260, Loss: 6.559015274047852
Iteration 3261, Loss: 6.209758281707764
Iteration 3262, Loss: 6.415408611297607
Iteration 3263, Loss: 6.15136194229126
Iteration 3264, Loss: 6.073175430297852
Iteration 3265, Loss: 5.907055377960205
Iteration 3266, Loss: 6.178213596343994
Iteration 3267, Loss: 6.007080554962158
Iteration 3268, Loss: 6.046157360076904
Iteration 3269, Loss: 6.094578742980957
Iteration 3270, Loss: 5.714217185974121
Iteration 3271, Loss: 6.369568347930908
Iteration 3272, Loss: 5.988686561584473
Iteration 3273, Loss: 5.973471164703369
Iteration 3274, Loss: 6.073153018951416
Iteration 3275, Loss: 6.021963119506836
Iteration 3276, Loss: 6.093604564666748
Iteration 3277, Loss: 5.885621070861816
Iteration 3278, Loss: 6.248482704162598
Iteration 3279, Loss: 6.049813747406006
Iteration 3280, Loss: 5.955153465270996
Iteration 3281, Loss: 6.021214008331299
Iteration 3282, Loss: 6.572530269622803
Iteration 3283, Loss: 5.8769450187683105
Iteration 3284, Loss: 5.956583499908447
Iteration 3285, Loss: 6.089820861816406
Iteration 3286, Loss: 6.085846900939941
Iteration 3287, Loss: 6.306192398071289
Iteration 3288, Loss: 6.052939414978027
Iteration 3289, Loss: 6.245882034301758
Iteration 3290, Loss: 5.923569202423096
Iteration 3291, Loss: 5.882012844085693
Iteration 3292, Loss: 6.3127360343933105
Iteration 3293, Loss: 5.913607120513916
Iteration 3294, Loss: 6.068334579467773
Iteration 3295, Loss: 6.1614789962768555
Iteration 3296, Loss: 6.272311687469482
Iteration 3297, Loss: 6.081053256988525
Iteration 3298, Loss: 5.879909992218018
Iteration 3299, Loss: 5.804664134979248
Rank 2 | Iteration 3300 | Training in Progress...
Iteration 3300, Loss: 6.219526767730713
Iteration 3301, Loss: 5.729775428771973
Iteration 3302, Loss: 6.039248943328857
Iteration 3303, Loss: 5.847563743591309
Iteration 3304, Loss: 6.206201076507568
Iteration 3305, Loss: 6.23668098449707
Iteration 3306, Loss: 6.072254657745361
Iteration 3307, Loss: 6.038896083831787
Iteration 3308, Loss: 5.838505744934082
Iteration 3309, Loss: 5.797669410705566
Iteration 3310, Loss: 6.2156758308410645
Iteration 3311, Loss: 5.944879531860352
Iteration 3312, Loss: 5.7123918533325195
Iteration 3313, Loss: 6.1893720626831055
Iteration 3314, Loss: 5.855420112609863
Iteration 3315, Loss: 6.209347724914551
Iteration 3316, Loss: 5.79629373550415
Iteration 3317, Loss: 5.875948905944824
Iteration 3318, Loss: 5.793618679046631
Iteration 3319, Loss: 6.351893901824951
Iteration 3320, Loss: 6.140721797943115
Iteration 3321, Loss: 5.888453483581543
Iteration 3322, Loss: 6.128387451171875
Iteration 3323, Loss: 5.927354335784912
Iteration 3324, Loss: 6.182906150817871
Iteration 3325, Loss: 5.96050500869751
Iteration 3326, Loss: 6.0102386474609375
Iteration 3327, Loss: 6.270243167877197
Iteration 3328, Loss: 6.042062282562256
Iteration 3329, Loss: 6.2207841873168945
Iteration 3330, Loss: 6.370698928833008
Iteration 3331, Loss: 6.045279502868652
Iteration 3332, Loss: 5.9580817222595215
Iteration 3333, Loss: 5.843113422393799
Iteration 3334, Loss: 5.90762996673584
Iteration 3335, Loss: 5.920095443725586
Iteration 3336, Loss: 6.231950759887695
Iteration 3337, Loss: 5.86032247543335
Iteration 3338, Loss: 5.8393707275390625
Iteration 3339, Loss: 5.813667297363281
Iteration 3340, Loss: 5.968297958374023
Iteration 3341, Loss: 6.100108623504639
Iteration 3342, Loss: 6.33944845199585
Iteration 3343, Loss: 5.9564056396484375
Iteration 3344, Loss: 5.714385509490967
Iteration 3345, Loss: 5.84887170791626
Iteration 3346, Loss: 6.267546653747559
Iteration 3347, Loss: 5.643652439117432
Iteration 3348, Loss: 5.703779220581055
Iteration 3349, Loss: 5.886239051818848
Iteration 3350, Loss: 6.288041591644287
Iteration 3351, Loss: 5.7487101554870605
Iteration 3352, Loss: 5.981739044189453
Iteration 3353, Loss: 5.955939292907715
Iteration 3354, Loss: 6.034402370452881
Iteration 3355, Loss: 5.92197847366333
Iteration 3356, Loss: 6.212414741516113
Iteration 3357, Loss: 6.092310428619385
Iteration 3358, Loss: 5.984979152679443
Iteration 3359, Loss: 6.266321182250977
Iteration 3360, Loss: 6.013193607330322
Iteration 3361, Loss: 5.808533191680908
Iteration 3362, Loss: 6.144515514373779
Iteration 3363, Loss: 6.126397609710693
Iteration 3364, Loss: 6.3985395431518555
Iteration 3365, Loss: 6.1492743492126465
Iteration 3366, Loss: 5.96409273147583
Iteration 3367, Loss: 5.816097736358643
Iteration 3368, Loss: 5.905540466308594
Iteration 3369, Loss: 5.95359468460083
Iteration 3370, Loss: 5.762923717498779
Iteration 3371, Loss: 5.9021220207214355
Iteration 3372, Loss: 6.534445285797119
Iteration 3373, Loss: 6.303574562072754
Iteration 3374, Loss: 5.7718987464904785
Iteration 3375, Loss: 5.9525146484375
Iteration 3376, Loss: 5.992293357849121
Iteration 3377, Loss: 5.6677565574646
Iteration 3378, Loss: 6.3437418937683105
Iteration 3379, Loss: 5.697942733764648
Iteration 3380, Loss: 5.885979175567627
Iteration 3381, Loss: 6.363467693328857
Iteration 3382, Loss: 6.227393627166748
Iteration 3383, Loss: 6.164761543273926
Iteration 3384, Loss: 5.6887664794921875
Iteration 3385, Loss: 6.036412715911865
Iteration 3386, Loss: 6.296864986419678
Iteration 3387, Loss: 5.765499114990234
Iteration 3388, Loss: 5.939117908477783
Iteration 3389, Loss: 5.840860366821289
Iteration 3390, Loss: 6.237213134765625
Iteration 3391, Loss: 6.021483421325684
Iteration 3392, Loss: 5.82333517074585
Iteration 3393, Loss: 6.086493968963623
Iteration 3394, Loss: 6.103728294372559
Iteration 3395, Loss: 5.52923059463501
Iteration 3396, Loss: 5.966531753540039
Iteration 3397, Loss: 6.096338272094727
Iteration 3398, Loss: 6.12294864654541
Iteration 3399, Loss: 6.167507171630859
Rank 2 | Iteration 3400 | Training in Progress...
Iteration 3400, Loss: 6.242263317108154
Iteration 3401, Loss: 6.083407402038574
Iteration 3402, Loss: 5.816215991973877
Iteration 3403, Loss: 6.300010681152344
Iteration 3404, Loss: 5.963077068328857
Iteration 3405, Loss: 6.276406764984131
Iteration 3406, Loss: 6.120697021484375
Iteration 3407, Loss: 6.116162300109863
Iteration 3408, Loss: 6.508506774902344
Iteration 3409, Loss: 6.558252334594727
Iteration 3410, Loss: 5.996634483337402
Iteration 3411, Loss: 5.706585884094238
Iteration 3412, Loss: 5.998445510864258
Iteration 3413, Loss: 6.35996675491333
Iteration 3414, Loss: 6.226677894592285
Iteration 3415, Loss: 6.093422889709473
Iteration 3416, Loss: 6.221195697784424
Iteration 3417, Loss: 6.134891033172607
Iteration 3418, Loss: 5.892716407775879
Iteration 3419, Loss: 5.931602478027344
Iteration 3420, Loss: 5.999117374420166
Iteration 3421, Loss: 5.940042018890381
Iteration 3422, Loss: 5.734929084777832
Iteration 3423, Loss: 5.902224063873291
Iteration 3424, Loss: 5.941703796386719
Iteration 3425, Loss: 5.975057125091553
Iteration 3426, Loss: 5.984384536743164
Iteration 3427, Loss: 6.012415409088135
Iteration 3428, Loss: 6.334871292114258
Iteration 3429, Loss: 6.213701248168945
Iteration 3430, Loss: 6.210379600524902
Iteration 3431, Loss: 6.023212432861328
Iteration 3432, Loss: 6.209759712219238
Iteration 3433, Loss: 6.155320167541504
Iteration 3434, Loss: 6.103568077087402
Iteration 3435, Loss: 6.389277935028076
Iteration 3436, Loss: 5.922800064086914
Iteration 3437, Loss: 5.996696949005127
Iteration 3438, Loss: 6.175383567810059
Iteration 3439, Loss: 5.878331184387207
Iteration 3440, Loss: 6.162507057189941
Iteration 3441, Loss: 6.271553993225098
Iteration 3442, Loss: 6.0573039054870605
Iteration 3443, Loss: 6.321615219116211
Iteration 3444, Loss: 6.245872497558594
Iteration 3445, Loss: 6.7405571937561035
Iteration 3446, Loss: 6.088319778442383
Iteration 3447, Loss: 6.121129512786865
Iteration 3448, Loss: 5.940390586853027
Iteration 3449, Loss: 5.809279918670654
Iteration 3450, Loss: 6.058393955230713
Iteration 3451, Loss: 6.234436988830566
Iteration 3452, Loss: 5.978450775146484
Iteration 3453, Loss: 5.988887310028076
Iteration 3454, Loss: 6.194545269012451
Iteration 3455, Loss: 5.9420342445373535
Iteration 3456, Loss: 6.295505046844482
Iteration 3457, Loss: 6.165584564208984
Iteration 3458, Loss: 6.1509294509887695
Iteration 3459, Loss: 6.162981033325195
Iteration 3460, Loss: 5.741757869720459
Iteration 3461, Loss: 5.710962295532227
Iteration 3462, Loss: 5.686429977416992
Iteration 3463, Loss: 5.871511936187744
Iteration 3464, Loss: 6.386350154876709
Iteration 3465, Loss: 6.18568754196167
Iteration 3466, Loss: 6.031679153442383
Iteration 3467, Loss: 6.070418834686279
Iteration 3468, Loss: 6.16151762008667
Iteration 3469, Loss: 5.858695983886719
Iteration 3470, Loss: 6.122687339782715
Iteration 3471, Loss: 6.125452518463135
Iteration 3472, Loss: 6.152920246124268
Iteration 3473, Loss: 5.869154930114746
Iteration 3474, Loss: 6.055188179016113
Iteration 3475, Loss: 5.904982566833496
Iteration 3476, Loss: 5.996578693389893
Iteration 3477, Loss: 5.797512054443359
Iteration 3478, Loss: 5.9936747550964355
Iteration 3479, Loss: 5.931290149688721
Iteration 3480, Loss: 6.184835433959961
Iteration 3481, Loss: 6.140025615692139
Iteration 3482, Loss: 6.196632385253906
Iteration 3483, Loss: 6.162320613861084
Iteration 3484, Loss: 5.777573108673096
Iteration 3485, Loss: 6.093656063079834
Iteration 3486, Loss: 5.73928165435791
Iteration 3487, Loss: 5.7623291015625
Iteration 3488, Loss: 5.879950523376465
Iteration 3489, Loss: 6.028259754180908
Iteration 3490, Loss: 5.691155910491943
Iteration 3491, Loss: 6.168792724609375
Iteration 3492, Loss: 5.918984889984131
Iteration 3493, Loss: 6.295260429382324
Iteration 3494, Loss: 6.057289123535156
Iteration 3495, Loss: 6.012662410736084
Iteration 3496, Loss: 5.936268329620361
Iteration 3497, Loss: 6.119668006896973
Iteration 3498, Loss: 6.2725934982299805
Iteration 3499, Loss: 6.735500335693359
Rank 2 | Iteration 3500 | Training in Progress...
Iteration 3500, Loss: 5.859211444854736
Iteration 3501, Loss: 5.953991889953613
Iteration 3502, Loss: 5.802807331085205
Iteration 3503, Loss: 5.9326171875
Iteration 3504, Loss: 6.390944004058838
Iteration 3505, Loss: 6.229246139526367
Iteration 3506, Loss: 6.073623180389404
Iteration 3507, Loss: 6.130282878875732
Iteration 3508, Loss: 6.057281970977783
Iteration 3509, Loss: 5.856332302093506
Iteration 3510, Loss: 5.957895755767822
Iteration 3511, Loss: 6.258960723876953
Iteration 3512, Loss: 6.530886173248291
Iteration 3513, Loss: 6.186881065368652
Iteration 3514, Loss: 6.150442600250244
Iteration 3515, Loss: 5.953360557556152
Iteration 3516, Loss: 6.296906471252441
Iteration 3517, Loss: 6.068568706512451
Iteration 3518, Loss: 5.854471683502197
Iteration 3519, Loss: 5.939362049102783
Iteration 3520, Loss: 6.5449538230896
Iteration 3521, Loss: 5.9575724601745605
Iteration 3522, Loss: 5.855169773101807
Iteration 3523, Loss: 6.017532825469971
Iteration 3524, Loss: 5.911946773529053
Iteration 3525, Loss: 6.777106285095215
Iteration 3526, Loss: 6.168178081512451
Iteration 3527, Loss: 6.416373252868652
Iteration 3528, Loss: 6.033156871795654
Iteration 3529, Loss: 5.780971527099609
Iteration 3530, Loss: 6.130398750305176
Iteration 3531, Loss: 6.482199192047119
Iteration 3532, Loss: 5.948965549468994
Iteration 3533, Loss: 6.223324298858643
Iteration 3534, Loss: 5.874275207519531
Iteration 3535, Loss: 5.814867973327637
Iteration 3536, Loss: 5.98622989654541
Iteration 3537, Loss: 6.061581134796143
Iteration 3538, Loss: 6.121540546417236
Iteration 3539, Loss: 6.160192012786865
Iteration 3540, Loss: 5.888487815856934
Iteration 3541, Loss: 6.469333648681641
Iteration 3542, Loss: 6.413606643676758
Iteration 3543, Loss: 6.048337936401367
Iteration 3544, Loss: 6.088510513305664
Iteration 3545, Loss: 6.166798114776611
Iteration 3546, Loss: 6.197432041168213
Iteration 3547, Loss: 5.894216060638428
Iteration 3548, Loss: 6.062292575836182
Iteration 3549, Loss: 6.094461917877197
Iteration 3550, Loss: 5.954250812530518
Iteration 3551, Loss: 6.308917045593262
Iteration 3552, Loss: 6.036868095397949
Iteration 3553, Loss: 6.288748264312744
Iteration 3554, Loss: 6.176558017730713
Iteration 3555, Loss: 5.882843494415283
Iteration 3556, Loss: 5.837258338928223
Iteration 3557, Loss: 6.132644176483154
Iteration 3558, Loss: 5.953520774841309
Iteration 3559, Loss: 5.78580904006958
Iteration 3560, Loss: 5.596264839172363
Iteration 3561, Loss: 6.099163055419922
Iteration 3562, Loss: 6.460002422332764
Iteration 3563, Loss: 5.938074111938477
Iteration 3564, Loss: 6.002359390258789
Iteration 3565, Loss: 5.9512763023376465
Iteration 3566, Loss: 6.033766269683838
Iteration 3567, Loss: 6.067213535308838
Iteration 3568, Loss: 5.81439733505249
Iteration 3569, Loss: 6.267571449279785
Iteration 3570, Loss: 6.224321365356445
Iteration 3571, Loss: 6.205812931060791
Iteration 3572, Loss: 6.140463352203369
Iteration 3573, Loss: 6.097245216369629
Iteration 3574, Loss: 5.9430131912231445
Iteration 3575, Loss: 5.897678852081299
Iteration 3576, Loss: 6.090652942657471
Iteration 3577, Loss: 5.932289123535156
Iteration 3578, Loss: 6.161526679992676
Iteration 3579, Loss: 5.781194686889648
Iteration 3580, Loss: 6.402191638946533
Iteration 3581, Loss: 6.156484127044678
Iteration 3582, Loss: 5.952627182006836
Iteration 3583, Loss: 6.227970123291016
Iteration 3584, Loss: 5.7409257888793945
Iteration 3585, Loss: 6.070560932159424
Iteration 3586, Loss: 6.1089863777160645
Iteration 3587, Loss: 6.114438533782959
Iteration 3588, Loss: 5.98530387878418
Iteration 3589, Loss: 6.140305519104004
Iteration 3590, Loss: 6.373236656188965
Iteration 3591, Loss: 5.952050685882568
Iteration 3592, Loss: 6.297316074371338
Iteration 3593, Loss: 6.025295734405518
Iteration 3594, Loss: 5.969348907470703
Iteration 3595, Loss: 6.011194705963135
Iteration 3596, Loss: 6.09467887878418
Iteration 3597, Loss: 5.872682571411133
Iteration 3598, Loss: 5.8929948806762695
Iteration 3599, Loss: 6.537341594696045
Rank 2 | Iteration 3600 | Training in Progress...
Iteration 3600, Loss: 6.1596784591674805
Iteration 3601, Loss: 5.817652225494385
Iteration 3602, Loss: 6.561161041259766
Iteration 3603, Loss: 5.7143425941467285
Iteration 3604, Loss: 5.914335250854492
Iteration 3605, Loss: 6.437611103057861
Iteration 3606, Loss: 6.020786285400391
Iteration 3607, Loss: 5.972105979919434
Iteration 3608, Loss: 5.861001491546631
Iteration 3609, Loss: 5.811924934387207
Iteration 3610, Loss: 6.080685138702393
Iteration 3611, Loss: 6.047516345977783
Iteration 3612, Loss: 5.909596920013428
Iteration 3613, Loss: 5.822076797485352
Iteration 3614, Loss: 6.198988437652588
Iteration 3615, Loss: 5.965517044067383
Iteration 3616, Loss: 6.334405422210693
Iteration 3617, Loss: 6.603417873382568
Iteration 3618, Loss: 6.580204486846924
Iteration 3619, Loss: 6.034428596496582
Iteration 3620, Loss: 6.300210475921631
Iteration 3621, Loss: 6.408005237579346
Iteration 3622, Loss: 6.507132530212402
Iteration 3623, Loss: 6.353277683258057
Iteration 3624, Loss: 5.709845066070557
Iteration 3625, Loss: 5.8614702224731445
Iteration 3626, Loss: 6.163571834564209
Iteration 3627, Loss: 6.004366397857666
Iteration 3628, Loss: 6.456064224243164
Iteration 3629, Loss: 6.045386791229248
Iteration 3630, Loss: 5.990261077880859
Iteration 3631, Loss: 6.1477837562561035
Iteration 3632, Loss: 6.185815811157227
Iteration 3633, Loss: 6.082286834716797
Iteration 3634, Loss: 5.792746067047119
Iteration 3635, Loss: 5.635097503662109
Iteration 3636, Loss: 5.926249027252197
Iteration 3637, Loss: 6.2666096687316895
Iteration 3638, Loss: 6.729797840118408
Iteration 3639, Loss: 6.138473987579346
Iteration 3640, Loss: 6.298399925231934
Iteration 3641, Loss: 5.735031604766846
Iteration 3642, Loss: 6.075098037719727
Iteration 3643, Loss: 5.991671085357666
Iteration 3644, Loss: 6.367171764373779
Iteration 3645, Loss: 6.015611171722412
Iteration 3646, Loss: 5.88649320602417
Iteration 3647, Loss: 5.890188694000244
Iteration 3648, Loss: 5.927454471588135
Iteration 3649, Loss: 6.203463554382324
Iteration 3650, Loss: 5.635859489440918
Iteration 3651, Loss: 5.895349502563477
Iteration 3652, Loss: 5.766526699066162
Iteration 3653, Loss: 5.964330196380615
Iteration 3654, Loss: 5.922528266906738
Iteration 3655, Loss: 6.236512660980225
Iteration 3656, Loss: 6.032162666320801
Iteration 3657, Loss: 6.057983875274658
Iteration 3658, Loss: 5.914554119110107
Iteration 3659, Loss: 6.00562858581543
Iteration 3660, Loss: 5.525516986846924
Iteration 3661, Loss: 5.789641857147217
Iteration 3662, Loss: 6.115205764770508
Iteration 3663, Loss: 5.967677593231201
Iteration 3664, Loss: 5.86436653137207
Iteration 3665, Loss: 5.856653690338135
Iteration 3666, Loss: 6.084105491638184
Iteration 3667, Loss: 5.954163074493408
Iteration 3668, Loss: 6.189565658569336
Iteration 3669, Loss: 6.003264427185059
Iteration 3670, Loss: 6.012209415435791
Iteration 3671, Loss: 5.972799777984619
Iteration 3672, Loss: 5.859659194946289
Iteration 3673, Loss: 6.09169340133667
Iteration 3674, Loss: 6.323118686676025
Iteration 3675, Loss: 6.452566623687744
Iteration 3676, Loss: 6.4059977531433105
Iteration 3677, Loss: 5.73884391784668
Iteration 3678, Loss: 6.201245307922363
Iteration 3679, Loss: 5.956313133239746
Iteration 3680, Loss: 6.241598129272461
Iteration 3681, Loss: 6.115752220153809
Iteration 3682, Loss: 6.067904949188232
Iteration 3683, Loss: 6.024843692779541
Iteration 3684, Loss: 6.354065895080566
Iteration 3685, Loss: 6.186221599578857
Iteration 3686, Loss: 6.072516441345215
Iteration 3687, Loss: 6.391485214233398
Iteration 3688, Loss: 5.857309341430664
Iteration 3689, Loss: 5.707589626312256
Iteration 3690, Loss: 5.997942924499512
Iteration 3691, Loss: 5.876918315887451
Iteration 3692, Loss: 6.2911810874938965
Iteration 3693, Loss: 5.834753036499023
Iteration 3694, Loss: 6.427940845489502
Iteration 3695, Loss: 6.020872592926025
Iteration 3696, Loss: 6.003715515136719
Iteration 3697, Loss: 5.712726593017578
Iteration 3698, Loss: 6.714901447296143
Iteration 3699, Loss: 5.915178298950195
Rank 2 | Iteration 3700 | Training in Progress...
Iteration 3700, Loss: 6.196580410003662
Iteration 3701, Loss: 6.031210899353027
Iteration 3702, Loss: 6.175633907318115
Iteration 3703, Loss: 6.022560119628906
Iteration 3704, Loss: 6.1827216148376465
Iteration 3705, Loss: 6.3777995109558105
Iteration 3706, Loss: 6.171692371368408
Iteration 3707, Loss: 6.4312005043029785
Iteration 3708, Loss: 6.261035919189453
Iteration 3709, Loss: 5.7939066886901855
Iteration 3710, Loss: 6.257081031799316
Iteration 3711, Loss: 6.287759304046631
Iteration 3712, Loss: 6.136332035064697
Iteration 3713, Loss: 5.945489406585693
Iteration 3714, Loss: 5.936572074890137
Iteration 3715, Loss: 6.45928430557251
Iteration 3716, Loss: 6.02982234954834
Iteration 3717, Loss: 6.2533488273620605
Iteration 3718, Loss: 6.167742729187012
Iteration 3719, Loss: 6.1296844482421875
Iteration 3720, Loss: 5.949542999267578
Iteration 3721, Loss: 6.118875503540039
Iteration 3722, Loss: 5.769385814666748
Iteration 3723, Loss: 5.9285888671875
Iteration 3724, Loss: 6.039255619049072
Iteration 3725, Loss: 5.84712553024292
Iteration 3726, Loss: 6.095632076263428
Iteration 3727, Loss: 5.956996440887451
Iteration 3728, Loss: 6.3409905433654785
Iteration 3729, Loss: 6.167603015899658
Iteration 3730, Loss: 6.5102972984313965
Iteration 3731, Loss: 5.900660991668701
Iteration 3732, Loss: 6.0249247550964355
Iteration 3733, Loss: 5.89993143081665
Iteration 3734, Loss: 6.3893022537231445
Iteration 3735, Loss: 5.843698978424072
Iteration 3736, Loss: 6.287476062774658
Iteration 3737, Loss: 6.354236602783203
Iteration 3738, Loss: 5.8031392097473145
Iteration 3739, Loss: 5.826322078704834
Iteration 3740, Loss: 6.121530055999756
Iteration 3741, Loss: 5.980045795440674
Iteration 3742, Loss: 6.503280162811279
Iteration 3743, Loss: 5.893350601196289
Iteration 3744, Loss: 5.930006980895996
Iteration 3745, Loss: 5.815090656280518
Iteration 3746, Loss: 6.144771099090576
Iteration 3747, Loss: 5.9463372230529785
Iteration 3748, Loss: 5.96732759475708
Iteration 3749, Loss: 5.800572872161865
Iteration 3750, Loss: 6.468022346496582
Iteration 3751, Loss: 5.857027530670166
Iteration 3752, Loss: 6.383932113647461
Iteration 3753, Loss: 5.958249568939209
Iteration 3754, Loss: 5.981325149536133
Iteration 3755, Loss: 6.38188362121582
Iteration 3756, Loss: 6.112892150878906
Iteration 3757, Loss: 5.955068588256836
Iteration 3758, Loss: 6.1407623291015625
Iteration 3759, Loss: 6.209498405456543
Iteration 3760, Loss: 6.100264072418213
Iteration 3761, Loss: 5.814133167266846
Iteration 3762, Loss: 6.329294681549072
Iteration 3763, Loss: 6.164839267730713
Iteration 3764, Loss: 6.1117072105407715
Iteration 3765, Loss: 5.853653430938721
Iteration 3766, Loss: 5.813499450683594
Iteration 3767, Loss: 6.116491794586182
Iteration 3768, Loss: 6.268399238586426
Iteration 3769, Loss: 5.783150672912598
Iteration 3770, Loss: 6.027220249176025
Iteration 3771, Loss: 6.021750450134277
Iteration 3772, Loss: 6.441935062408447
Iteration 3773, Loss: 6.346362113952637
Iteration 3774, Loss: 5.9930033683776855
Iteration 3775, Loss: 6.242344379425049
Iteration 3776, Loss: 6.473660945892334
Iteration 3777, Loss: 6.251039981842041
Iteration 3778, Loss: 6.1967453956604
Iteration 3779, Loss: 5.987994194030762
Iteration 3780, Loss: 6.244017601013184
Iteration 3781, Loss: 6.0413923263549805
Iteration 3782, Loss: 5.943207263946533
Iteration 3783, Loss: 6.130776405334473
Iteration 3784, Loss: 5.856573104858398
Iteration 3785, Loss: 6.1346116065979
Iteration 3786, Loss: 5.9503912925720215
Iteration 3787, Loss: 6.364902973175049
Iteration 3788, Loss: 6.168305397033691
Iteration 3789, Loss: 6.430915832519531
Iteration 3790, Loss: 5.8677191734313965
Iteration 3791, Loss: 6.2594733238220215
Iteration 3792, Loss: 5.730611324310303
Iteration 3793, Loss: 6.200409889221191
Iteration 3794, Loss: 5.89836311340332
Iteration 3795, Loss: 6.305224895477295
Iteration 3796, Loss: 5.9508466720581055
Iteration 3797, Loss: 6.479691505432129
Iteration 3798, Loss: 5.884821891784668
Iteration 3799, Loss: 5.8296380043029785
Rank 2 | Iteration 3800 | Training in Progress...
Iteration 3800, Loss: 5.875523090362549
Iteration 3801, Loss: 6.093135356903076
Iteration 3802, Loss: 6.145851135253906
Iteration 3803, Loss: 6.102672100067139
Iteration 3804, Loss: 6.0262131690979
Iteration 3805, Loss: 5.972097396850586
Iteration 3806, Loss: 5.789663791656494
Iteration 3807, Loss: 5.8058881759643555
Iteration 3808, Loss: 6.039536952972412
Iteration 3809, Loss: 5.806881904602051
Iteration 3810, Loss: 5.729583740234375
Iteration 3811, Loss: 5.825132846832275
Iteration 3812, Loss: 6.213169574737549
Iteration 3813, Loss: 6.091741561889648
Iteration 3814, Loss: 6.356540679931641
Iteration 3815, Loss: 6.227790355682373
Iteration 3816, Loss: 6.477985382080078
Iteration 3817, Loss: 6.392385959625244
Iteration 3818, Loss: 6.098639965057373
Iteration 3819, Loss: 5.968097686767578
Iteration 3820, Loss: 6.281900882720947
Iteration 3821, Loss: 6.0076398849487305
Iteration 3822, Loss: 6.671812534332275
Iteration 3823, Loss: 5.86113166809082
Iteration 3824, Loss: 6.331018447875977
Iteration 3825, Loss: 6.271993637084961
Iteration 3826, Loss: 5.989660739898682
Iteration 3827, Loss: 5.965296268463135
Iteration 3828, Loss: 6.0352463722229
Iteration 3829, Loss: 5.988666534423828
Iteration 3830, Loss: 6.314366340637207
Iteration 3831, Loss: 6.141602039337158
Iteration 3832, Loss: 5.913910388946533
Iteration 3833, Loss: 6.249532699584961
Iteration 3834, Loss: 6.215241432189941
Iteration 3835, Loss: 6.010383129119873
Iteration 3836, Loss: 5.911496162414551
Iteration 3837, Loss: 5.9096293449401855
Iteration 3838, Loss: 5.57822322845459
Iteration 3839, Loss: 6.4875569343566895
Iteration 3840, Loss: 6.16710901260376
Iteration 3841, Loss: 6.089881896972656
Iteration 3842, Loss: 5.959883689880371
Iteration 3843, Loss: 5.874196529388428
Iteration 3844, Loss: 6.319026470184326
Iteration 3845, Loss: 6.580038070678711
Iteration 3846, Loss: 5.992064476013184
Iteration 3847, Loss: 6.109272003173828
Iteration 3848, Loss: 6.288362503051758
Iteration 3849, Loss: 6.080765724182129
Iteration 3850, Loss: 6.0607147216796875
Iteration 3851, Loss: 5.824767589569092
Iteration 3852, Loss: 6.098381519317627
Iteration 3853, Loss: 5.94296932220459
Iteration 3854, Loss: 6.107664585113525
Iteration 3855, Loss: 6.0128045082092285
Iteration 3856, Loss: 6.26408576965332
Iteration 3857, Loss: 6.29466438293457
Iteration 3858, Loss: 5.850610733032227
Iteration 3859, Loss: 6.116184711456299
Iteration 3860, Loss: 5.924964427947998
Iteration 3861, Loss: 6.259106636047363
Iteration 3862, Loss: 5.877845287322998
Iteration 3863, Loss: 5.712789058685303
Iteration 3864, Loss: 6.1745405197143555
Iteration 3865, Loss: 5.908792495727539
Iteration 3866, Loss: 5.934994697570801
Iteration 3867, Loss: 6.044496536254883
Iteration 3868, Loss: 6.163034915924072
Iteration 3869, Loss: 6.32233190536499
Iteration 3870, Loss: 5.9509196281433105
Iteration 3871, Loss: 5.794571399688721
Iteration 3872, Loss: 6.125209808349609
Iteration 3873, Loss: 5.806942939758301
Iteration 3874, Loss: 6.1739654541015625
Iteration 3875, Loss: 6.092543125152588
Iteration 3876, Loss: 6.1013712882995605
Iteration 3877, Loss: 5.868647575378418
Iteration 3878, Loss: 5.7435479164123535
Iteration 3879, Loss: 6.132178783416748
Iteration 3880, Loss: 6.152613162994385
Iteration 3881, Loss: 6.006080627441406
Iteration 3882, Loss: 5.785980224609375
Iteration 3883, Loss: 6.3025665283203125
Iteration 3884, Loss: 6.102827548980713
Iteration 3885, Loss: 6.171169757843018
Iteration 3886, Loss: 6.094894886016846
Iteration 3887, Loss: 6.016872406005859
Iteration 3888, Loss: 6.1113080978393555
Iteration 3889, Loss: 6.225259304046631
Iteration 3890, Loss: 5.8958539962768555
Iteration 3891, Loss: 5.767266750335693
Iteration 3892, Loss: 5.87347936630249
Iteration 3893, Loss: 6.032386302947998
Iteration 3894, Loss: 5.8938703536987305
Iteration 3895, Loss: 5.923814296722412
Iteration 3896, Loss: 6.073479652404785
Iteration 3897, Loss: 5.925355911254883
Iteration 3898, Loss: 5.7795939445495605
Iteration 3899, Loss: 5.903166770935059
Rank 2 | Iteration 3900 | Training in Progress...
Iteration 3900, Loss: 6.160078525543213
Iteration 3901, Loss: 5.977706432342529
Iteration 3902, Loss: 6.341804027557373
Iteration 3903, Loss: 6.284232139587402
Iteration 3904, Loss: 6.107056140899658
Iteration 3905, Loss: 5.8296217918396
Iteration 3906, Loss: 6.107320308685303
Iteration 3907, Loss: 6.154727458953857
Iteration 3908, Loss: 6.266032695770264
Iteration 3909, Loss: 6.028442859649658
Iteration 3910, Loss: 6.037203788757324
Iteration 3911, Loss: 6.110302448272705
Iteration 3912, Loss: 6.323503494262695
Iteration 3913, Loss: 5.996747016906738
Iteration 3914, Loss: 5.885932445526123
Iteration 3915, Loss: 6.092899799346924
Iteration 3916, Loss: 5.985044002532959
Iteration 3917, Loss: 6.388411998748779
Iteration 3918, Loss: 5.980495452880859
Iteration 3919, Loss: 5.939058303833008
Iteration 3920, Loss: 6.168563365936279
Iteration 3921, Loss: 6.169076442718506
Iteration 3922, Loss: 5.880402088165283
Iteration 3923, Loss: 6.24510383605957
Iteration 3924, Loss: 6.3800578117370605
Iteration 3925, Loss: 5.929867744445801
Iteration 3926, Loss: 5.962886810302734
Iteration 3927, Loss: 5.773614406585693
Iteration 3928, Loss: 6.306930065155029
Iteration 3929, Loss: 6.119778633117676
Iteration 3930, Loss: 6.006094932556152
Iteration 3931, Loss: 6.257281303405762
Iteration 3932, Loss: 6.28078556060791
Iteration 3933, Loss: 6.139155864715576
Iteration 3934, Loss: 6.180020332336426
Iteration 3935, Loss: 5.840389251708984
Iteration 3936, Loss: 5.87002420425415
Iteration 3937, Loss: 5.610610008239746
Iteration 3938, Loss: 5.773921012878418
Iteration 3939, Loss: 6.267617225646973
Iteration 3940, Loss: 5.8890886306762695
Iteration 3941, Loss: 6.114742755889893
Iteration 3942, Loss: 5.846738338470459
Iteration 3943, Loss: 5.936519622802734
Iteration 3944, Loss: 6.27461576461792
Iteration 3945, Loss: 6.122082710266113
Iteration 3946, Loss: 6.391786575317383
Iteration 3947, Loss: 6.226629734039307
Iteration 3948, Loss: 6.31365442276001
Iteration 3949, Loss: 6.047688961029053
Iteration 3950, Loss: 6.362310409545898
Iteration 3951, Loss: 6.020272731781006
Iteration 3952, Loss: 5.902835845947266
Iteration 3953, Loss: 5.81174373626709
Iteration 3954, Loss: 6.180564880371094
Iteration 3955, Loss: 5.762148857116699
Iteration 3956, Loss: 5.589447975158691
Iteration 3957, Loss: 6.290489196777344
Iteration 3958, Loss: 6.249306678771973
Iteration 3959, Loss: 6.448944568634033
Iteration 3960, Loss: 5.907878875732422
Iteration 3961, Loss: 6.240030288696289
Iteration 3962, Loss: 6.000842094421387
Iteration 3963, Loss: 5.922389507293701
Iteration 3964, Loss: 5.672516345977783
Iteration 3965, Loss: 5.948616981506348
Iteration 3966, Loss: 6.191586494445801
Iteration 3967, Loss: 6.073727130889893
Iteration 3968, Loss: 5.957667350769043
Iteration 3969, Loss: 6.36892032623291
Iteration 3970, Loss: 5.995617866516113
Iteration 3971, Loss: 5.907233715057373
Iteration 3972, Loss: 6.12108039855957
Iteration 3973, Loss: 6.191500663757324
Iteration 3974, Loss: 6.156633377075195
Iteration 3975, Loss: 6.128971576690674
Iteration 3976, Loss: 6.274753570556641
Iteration 3977, Loss: 6.353914260864258
Iteration 3978, Loss: 5.966293811798096
Iteration 3979, Loss: 6.372625827789307
Iteration 3980, Loss: 6.022665023803711
Iteration 3981, Loss: 5.714114665985107
Iteration 3982, Loss: 5.950780868530273
Iteration 3983, Loss: 6.1951141357421875
Iteration 3984, Loss: 6.096719741821289
Iteration 3985, Loss: 6.16263484954834
Iteration 3986, Loss: 6.166866302490234
Iteration 3987, Loss: 6.034087657928467
Iteration 3988, Loss: 5.846751689910889
Iteration 3989, Loss: 6.3365678787231445
Iteration 3990, Loss: 6.289423942565918
Iteration 3991, Loss: 5.891829967498779
Iteration 3992, Loss: 5.714702129364014
Iteration 3993, Loss: 6.0249762535095215
Iteration 3994, Loss: 5.717057228088379
Iteration 3995, Loss: 5.716912746429443
Iteration 3996, Loss: 6.43129301071167
Iteration 3997, Loss: 6.059719085693359
Iteration 3998, Loss: 6.047372341156006
Iteration 3999, Loss: 6.003509521484375
Rank 2 | Iteration 4000 | Training in Progress...
Iteration 4000, Loss: 5.832971572875977
Iteration 4001, Loss: 5.910827159881592
Iteration 4002, Loss: 6.433772087097168
Iteration 4003, Loss: 6.229284286499023
Iteration 4004, Loss: 5.812490940093994
Iteration 4005, Loss: 5.908562660217285
Iteration 4006, Loss: 6.538567066192627
Iteration 4007, Loss: 6.203357696533203
Iteration 4008, Loss: 5.922542095184326
Iteration 4009, Loss: 6.040345191955566
Iteration 4010, Loss: 6.3635406494140625
Iteration 4011, Loss: 6.207942008972168
Iteration 4012, Loss: 6.175299644470215
Iteration 4013, Loss: 5.921267032623291
Iteration 4014, Loss: 6.174181938171387
Iteration 4015, Loss: 6.263235092163086
Iteration 4016, Loss: 6.210178852081299
Iteration 4017, Loss: 5.970850467681885
Iteration 4018, Loss: 5.845621585845947
Iteration 4019, Loss: 6.268301963806152
Iteration 4020, Loss: 6.019680023193359
Iteration 4021, Loss: 6.06047248840332
Iteration 4022, Loss: 5.8383283615112305
Iteration 4023, Loss: 6.118236064910889
Iteration 4024, Loss: 6.038699626922607
Iteration 4025, Loss: 5.860456943511963
Iteration 4026, Loss: 6.145709037780762
Iteration 4027, Loss: 5.911838531494141
Iteration 4028, Loss: 5.790380954742432
Iteration 4029, Loss: 6.61771821975708
Iteration 4030, Loss: 6.083925247192383
Iteration 4031, Loss: 5.9634175300598145
Iteration 4032, Loss: 6.031424522399902
Iteration 4033, Loss: 5.9354023933410645
Iteration 4034, Loss: 6.195394515991211
Iteration 4035, Loss: 6.341806411743164
Iteration 4036, Loss: 6.256434440612793
Iteration 4037, Loss: 5.970609664916992
Iteration 4038, Loss: 6.176838397979736
Iteration 4039, Loss: 6.179398059844971
Iteration 4040, Loss: 6.1657843589782715
Iteration 4041, Loss: 5.982926845550537
Iteration 4042, Loss: 5.981423377990723
Iteration 4043, Loss: 6.231640815734863
Iteration 4044, Loss: 6.134055137634277
Iteration 4045, Loss: 5.956451892852783
Iteration 4046, Loss: 6.054429054260254
Iteration 4047, Loss: 6.139861106872559
Iteration 4048, Loss: 5.936169624328613
Iteration 4049, Loss: 5.978839874267578
Iteration 4050, Loss: 6.1867265701293945
Iteration 4051, Loss: 6.295402526855469
Iteration 4052, Loss: 5.951872825622559
Iteration 4053, Loss: 6.192816734313965
Iteration 4054, Loss: 5.968704700469971
Iteration 4055, Loss: 6.4669108390808105
Iteration 4056, Loss: 6.164328098297119
Iteration 4057, Loss: 6.246356010437012
Iteration 4058, Loss: 5.982612133026123
Iteration 4059, Loss: 5.956200122833252
Iteration 4060, Loss: 6.575901508331299
Iteration 4061, Loss: 6.204355716705322
Iteration 4062, Loss: 5.986086845397949
Iteration 4063, Loss: 5.706142902374268
Iteration 4064, Loss: 6.2306060791015625
Iteration 4065, Loss: 6.033072471618652
Iteration 4066, Loss: 5.88325309753418
Iteration 4067, Loss: 5.994060039520264
Iteration 4068, Loss: 6.4397125244140625
Iteration 4069, Loss: 5.906456470489502
Iteration 4070, Loss: 6.203146934509277
Iteration 4071, Loss: 6.193210601806641
Iteration 4072, Loss: 5.884772300720215
Iteration 4073, Loss: 5.780655860900879
Iteration 4074, Loss: 6.04863166809082
Iteration 4075, Loss: 6.133860111236572
Iteration 4076, Loss: 6.154904842376709
Iteration 4077, Loss: 6.001420974731445
Iteration 4078, Loss: 5.712681293487549
Iteration 4079, Loss: 6.296973705291748
Iteration 4080, Loss: 6.208822250366211
Iteration 4081, Loss: 5.7535505294799805
Iteration 4082, Loss: 6.0964035987854
Iteration 4083, Loss: 5.961458206176758
Iteration 4084, Loss: 6.0371928215026855
Iteration 4085, Loss: 6.288924217224121
Iteration 4086, Loss: 6.227663993835449
Iteration 4087, Loss: 6.133172035217285
Iteration 4088, Loss: 6.257924556732178
Iteration 4089, Loss: 6.134954452514648
Iteration 4090, Loss: 6.029699802398682
Iteration 4091, Loss: 5.962578296661377
Iteration 4092, Loss: 6.306199073791504
Iteration 4093, Loss: 6.352555751800537
Iteration 4094, Loss: 5.886845111846924
Iteration 4095, Loss: 5.940186977386475
Iteration 4096, Loss: 5.990533351898193
Iteration 4097, Loss: 6.261845588684082
Iteration 4098, Loss: 6.128992557525635
Iteration 4099, Loss: 6.143581867218018
Rank 2 | Iteration 4100 | Training in Progress...
Iteration 4100, Loss: 6.345954895019531
Iteration 4101, Loss: 5.827449321746826
Iteration 4102, Loss: 5.644114017486572
Iteration 4103, Loss: 5.554512023925781
Iteration 4104, Loss: 5.802521228790283
Iteration 4105, Loss: 6.271345138549805
Iteration 4106, Loss: 5.89795446395874
Iteration 4107, Loss: 6.122244358062744
Iteration 4108, Loss: 5.841203689575195
Iteration 4109, Loss: 5.814266204833984
Iteration 4110, Loss: 6.101635456085205
Iteration 4111, Loss: 5.881560325622559
Iteration 4112, Loss: 5.734005928039551
Iteration 4113, Loss: 5.971772193908691
Iteration 4114, Loss: 5.929440021514893
Iteration 4115, Loss: 6.006531715393066
Iteration 4116, Loss: 6.138967037200928
Iteration 4117, Loss: 5.9949822425842285
Iteration 4118, Loss: 6.084323406219482
Iteration 4119, Loss: 6.278432846069336
Iteration 4120, Loss: 5.859066486358643
Iteration 4121, Loss: 6.146388053894043
Iteration 4122, Loss: 5.8174214363098145
Iteration 4123, Loss: 6.333049297332764
Iteration 4124, Loss: 6.238104343414307
Iteration 4125, Loss: 6.0964155197143555
Iteration 4126, Loss: 6.172346115112305
Iteration 4127, Loss: 6.105172157287598
Iteration 4128, Loss: 6.131039619445801
Iteration 4129, Loss: 5.793619155883789
Iteration 4130, Loss: 6.228363513946533
Iteration 4131, Loss: 5.925333499908447
Iteration 4132, Loss: 5.924374103546143
Iteration 4133, Loss: 5.770176887512207
Iteration 4134, Loss: 6.098423480987549
Iteration 4135, Loss: 5.807395935058594
Iteration 4136, Loss: 5.936952590942383
Iteration 4137, Loss: 5.783492565155029
Iteration 4138, Loss: 6.206665515899658
Iteration 4139, Loss: 6.0952582359313965
Iteration 4140, Loss: 6.132666110992432
Iteration 4141, Loss: 6.0459184646606445
Iteration 4142, Loss: 6.042608261108398
Iteration 4143, Loss: 6.35069465637207
Iteration 4144, Loss: 6.022993087768555
Iteration 4145, Loss: 5.989080905914307
Iteration 4146, Loss: 6.1437788009643555
Iteration 4147, Loss: 6.166228294372559
Iteration 4148, Loss: 5.992767333984375
Iteration 4149, Loss: 5.751638412475586
Iteration 4150, Loss: 6.116820335388184
Iteration 4151, Loss: 5.716430187225342
Iteration 4152, Loss: 6.107112884521484
Iteration 4153, Loss: 6.28726053237915
Iteration 4154, Loss: 6.201156139373779
Iteration 4155, Loss: 5.897486209869385
Iteration 4156, Loss: 6.046228408813477
Iteration 4157, Loss: 5.808940887451172
Iteration 4158, Loss: 6.053808689117432
Iteration 4159, Loss: 6.249396324157715
Iteration 4160, Loss: 5.632478713989258
Iteration 4161, Loss: 6.405303001403809
Iteration 4162, Loss: 6.034176349639893
Iteration 4163, Loss: 5.890853404998779
Iteration 4164, Loss: 5.988571643829346
Iteration 4165, Loss: 6.319421768188477
Iteration 4166, Loss: 5.731424331665039
Iteration 4167, Loss: 5.902146339416504
Iteration 4168, Loss: 6.270419597625732
Iteration 4169, Loss: 5.639277935028076
Iteration 4170, Loss: 6.210765361785889
Iteration 4171, Loss: 6.269874572753906
Iteration 4172, Loss: 5.9941887855529785
Iteration 4173, Loss: 6.245469093322754
Iteration 4174, Loss: 6.0253119468688965
Iteration 4175, Loss: 6.051679611206055
Iteration 4176, Loss: 6.14907169342041
Iteration 4177, Loss: 6.007177829742432
Iteration 4178, Loss: 5.801396369934082
Iteration 4179, Loss: 5.827905654907227
Iteration 4180, Loss: 5.988412857055664
Iteration 4181, Loss: 5.8930511474609375
Iteration 4182, Loss: 5.6811652183532715
Iteration 4183, Loss: 6.0025763511657715
Iteration 4184, Loss: 6.138239860534668
Iteration 4185, Loss: 5.991785049438477
Iteration 4186, Loss: 6.242208957672119
Iteration 4187, Loss: 5.919055938720703
Iteration 4188, Loss: 6.136218547821045
Iteration 4189, Loss: 5.885417938232422
Iteration 4190, Loss: 5.944379806518555
Iteration 4191, Loss: 6.311328887939453
Iteration 4192, Loss: 6.428402900695801
Iteration 4193, Loss: 6.075295925140381
Iteration 4194, Loss: 6.0229926109313965
Iteration 4195, Loss: 5.8148603439331055
Iteration 4196, Loss: 5.8801655769348145
Iteration 4197, Loss: 6.086725234985352
Iteration 4198, Loss: 5.9588189125061035
Iteration 4199, Loss: 6.511575698852539
Rank 2 | Iteration 4200 | Training in Progress...
Iteration 4200, Loss: 6.284975051879883
Iteration 4201, Loss: 6.252739906311035
Iteration 4202, Loss: 6.421930313110352
Iteration 4203, Loss: 5.821931838989258
Iteration 4204, Loss: 5.8727192878723145
Iteration 4205, Loss: 5.983376979827881
Iteration 4206, Loss: 6.590311050415039
Iteration 4207, Loss: 6.484127521514893
Iteration 4208, Loss: 5.979136943817139
Iteration 4209, Loss: 5.825779914855957
Iteration 4210, Loss: 6.952586650848389
Iteration 4211, Loss: 6.003453254699707
Iteration 4212, Loss: 6.117309093475342
Iteration 4213, Loss: 5.948500633239746
Iteration 4214, Loss: 5.761932373046875
Iteration 4215, Loss: 6.06891393661499
Iteration 4216, Loss: 5.961292743682861
Iteration 4217, Loss: 6.292705059051514
Iteration 4218, Loss: 6.250155448913574
Iteration 4219, Loss: 5.877135753631592
Iteration 4220, Loss: 5.840247631072998
Iteration 4221, Loss: 5.877114295959473
Iteration 4222, Loss: 5.791453838348389
Iteration 4223, Loss: 6.019535541534424
Iteration 4224, Loss: 6.080065727233887
Iteration 4225, Loss: 6.234129428863525
Iteration 4226, Loss: 6.257589817047119
Iteration 4227, Loss: 5.880130767822266
Iteration 4228, Loss: 5.859043121337891
Iteration 4229, Loss: 5.858099937438965
Iteration 4230, Loss: 6.239694595336914
Iteration 4231, Loss: 6.432832717895508
Iteration 4232, Loss: 5.872185707092285
Iteration 4233, Loss: 5.9196391105651855
Iteration 4234, Loss: 6.232779502868652
Iteration 4235, Loss: 5.875280857086182
Iteration 4236, Loss: 6.317476272583008
Iteration 4237, Loss: 6.113875865936279
Iteration 4238, Loss: 6.251862525939941
Iteration 4239, Loss: 6.4289774894714355
Iteration 4240, Loss: 5.886690616607666
Iteration 4241, Loss: 6.462465763092041
Iteration 4242, Loss: 6.18550443649292
Iteration 4243, Loss: 6.376846790313721
Iteration 4244, Loss: 6.181572914123535
Iteration 4245, Loss: 6.444782257080078
Iteration 4246, Loss: 6.420962333679199
Iteration 4247, Loss: 5.736381530761719
Iteration 4248, Loss: 6.009376525878906
Iteration 4249, Loss: 6.328605651855469
Iteration 4250, Loss: 5.850017547607422
Iteration 4251, Loss: 6.420984745025635
Iteration 4252, Loss: 5.92171573638916
Iteration 4253, Loss: 6.167386054992676
Iteration 4254, Loss: 6.085558891296387
Iteration 4255, Loss: 6.024519443511963
Iteration 4256, Loss: 5.963768005371094
Iteration 4257, Loss: 6.047519683837891
Iteration 4258, Loss: 5.961638927459717
Iteration 4259, Loss: 5.893518924713135
Iteration 4260, Loss: 5.757472038269043
Iteration 4261, Loss: 6.067366123199463
Iteration 4262, Loss: 6.1873040199279785
Iteration 4263, Loss: 6.358580112457275
Iteration 4264, Loss: 6.1633782386779785
Iteration 4265, Loss: 6.508020401000977
Iteration 4266, Loss: 5.928072929382324
Iteration 4267, Loss: 6.171572685241699
Iteration 4268, Loss: 6.035510063171387
Iteration 4269, Loss: 5.810475826263428
Iteration 4270, Loss: 6.2728376388549805
Iteration 4271, Loss: 6.1364617347717285
Iteration 4272, Loss: 5.957132816314697
Iteration 4273, Loss: 6.127031326293945
Iteration 4274, Loss: 6.137619972229004
Iteration 4275, Loss: 6.172993183135986
Iteration 4276, Loss: 5.79809045791626
Iteration 4277, Loss: 5.901242256164551
Iteration 4278, Loss: 5.942361354827881
Iteration 4279, Loss: 6.255186557769775
Iteration 4280, Loss: 5.819526195526123
Iteration 4281, Loss: 5.876105308532715
Iteration 4282, Loss: 6.29162073135376
Iteration 4283, Loss: 5.789853096008301
Iteration 4284, Loss: 6.023752689361572
Iteration 4285, Loss: 5.819425582885742
Iteration 4286, Loss: 5.941049098968506
Iteration 4287, Loss: 6.313163757324219
Iteration 4288, Loss: 6.027528285980225
Iteration 4289, Loss: 5.8745317459106445
Iteration 4290, Loss: 5.88780403137207
Iteration 4291, Loss: 6.129021644592285
Iteration 4292, Loss: 6.333590030670166
Iteration 4293, Loss: 6.449547290802002
Iteration 4294, Loss: 5.860342979431152
Iteration 4295, Loss: 6.171711444854736
Iteration 4296, Loss: 6.152339458465576
Iteration 4297, Loss: 6.031675338745117
Iteration 4298, Loss: 6.094208240509033
Iteration 4299, Loss: 5.5357666015625
Rank 2 | Iteration 4300 | Training in Progress...
Iteration 4300, Loss: 6.049930572509766
Iteration 4301, Loss: 6.054506778717041
Iteration 4302, Loss: 5.809332370758057
Iteration 4303, Loss: 5.890715599060059
Iteration 4304, Loss: 5.991369724273682
Iteration 4305, Loss: 6.018129348754883
Iteration 4306, Loss: 5.7271575927734375
Iteration 4307, Loss: 5.861547946929932
Iteration 4308, Loss: 6.1678924560546875
Iteration 4309, Loss: 6.207606792449951
Iteration 4310, Loss: 6.3858842849731445
Iteration 4311, Loss: 6.034079074859619
Iteration 4312, Loss: 5.92152738571167
Iteration 4313, Loss: 6.12255859375
Iteration 4314, Loss: 5.872323036193848
Iteration 4315, Loss: 5.814664363861084
Iteration 4316, Loss: 6.006689071655273
Iteration 4317, Loss: 5.90878438949585
Iteration 4318, Loss: 6.261571884155273
Iteration 4319, Loss: 5.920138359069824
Iteration 4320, Loss: 5.943800926208496
Iteration 4321, Loss: 6.005883693695068
Iteration 4322, Loss: 6.033815860748291
Iteration 4323, Loss: 5.896542072296143
Iteration 4324, Loss: 5.903473377227783
Iteration 4325, Loss: 5.99095344543457
Iteration 4326, Loss: 6.0079145431518555
Iteration 4327, Loss: 6.20426607131958
Iteration 4328, Loss: 5.851393699645996
Iteration 4329, Loss: 5.933040618896484
Iteration 4330, Loss: 5.803459644317627
Iteration 4331, Loss: 5.740213394165039
Iteration 4332, Loss: 6.103166580200195
Iteration 4333, Loss: 5.926216125488281
Iteration 4334, Loss: 6.169514179229736
Iteration 4335, Loss: 6.260974884033203
Iteration 4336, Loss: 6.577648162841797
Iteration 4337, Loss: 6.0194172859191895
Iteration 4338, Loss: 5.868844985961914
Iteration 4339, Loss: 5.958388805389404
Iteration 4340, Loss: 6.004408359527588
Iteration 4341, Loss: 6.251576900482178
Iteration 4342, Loss: 6.154951572418213
Iteration 4343, Loss: 5.958580017089844
Iteration 4344, Loss: 6.412691593170166
Iteration 4345, Loss: 5.915744304656982
Iteration 4346, Loss: 6.379208087921143
Iteration 4347, Loss: 6.112457752227783
Iteration 4348, Loss: 6.519491195678711
Iteration 4349, Loss: 5.783891201019287
Iteration 4350, Loss: 6.1356520652771
Iteration 4351, Loss: 6.175217628479004
Iteration 4352, Loss: 5.693562984466553
Iteration 4353, Loss: 5.962064743041992
Iteration 4354, Loss: 5.957664489746094
Iteration 4355, Loss: 6.1938323974609375
Iteration 4356, Loss: 5.985348701477051
Iteration 4357, Loss: 5.9921875
Iteration 4358, Loss: 6.232113838195801
Iteration 4359, Loss: 6.208377361297607
Iteration 4360, Loss: 6.396636962890625
Iteration 4361, Loss: 5.9977874755859375
Iteration 4362, Loss: 6.049691677093506
Iteration 4363, Loss: 6.194565296173096
Iteration 4364, Loss: 5.94870662689209
Iteration 4365, Loss: 5.822518348693848
Iteration 4366, Loss: 5.976223468780518
Iteration 4367, Loss: 5.656906604766846
Iteration 4368, Loss: 6.092140197753906
Iteration 4369, Loss: 6.062125205993652
Iteration 4370, Loss: 6.069604873657227
Iteration 4371, Loss: 5.8899617195129395
Iteration 4372, Loss: 6.067072868347168
Iteration 4373, Loss: 6.100657939910889
Iteration 4374, Loss: 5.838768482208252
Iteration 4375, Loss: 6.155036449432373
Iteration 4376, Loss: 6.203868865966797
Iteration 4377, Loss: 6.148886680603027
Iteration 4378, Loss: 6.142736911773682
Iteration 4379, Loss: 6.109992980957031
Iteration 4380, Loss: 5.857320785522461
Iteration 4381, Loss: 6.011103630065918
Iteration 4382, Loss: 6.00117301940918
Iteration 4383, Loss: 5.9120073318481445
Iteration 4384, Loss: 6.025964736938477
Iteration 4385, Loss: 5.777929782867432
Iteration 4386, Loss: 6.363612651824951
Iteration 4387, Loss: 6.145907878875732
Iteration 4388, Loss: 5.951699733734131
Iteration 4389, Loss: 5.981316089630127
Iteration 4390, Loss: 6.276531219482422
Iteration 4391, Loss: 6.16121244430542
Iteration 4392, Loss: 6.08957052230835
Iteration 4393, Loss: 6.356328964233398
Iteration 4394, Loss: 6.192737102508545
Iteration 4395, Loss: 6.400418281555176
Iteration 4396, Loss: 6.496373653411865
Iteration 4397, Loss: 5.879709720611572
Iteration 4398, Loss: 6.173412322998047
Iteration 4399, Loss: 6.012417316436768
Rank 2 | Iteration 4400 | Training in Progress...
Iteration 4400, Loss: 5.788589954376221
Iteration 4401, Loss: 6.187138080596924
Iteration 4402, Loss: 6.125434875488281
Iteration 4403, Loss: 5.936000823974609
Iteration 4404, Loss: 6.103641510009766
Iteration 4405, Loss: 6.158041477203369
Iteration 4406, Loss: 5.841513633728027
Iteration 4407, Loss: 5.82195520401001
Iteration 4408, Loss: 6.192001819610596
Iteration 4409, Loss: 6.054916858673096
Iteration 4410, Loss: 6.110500812530518
Iteration 4411, Loss: 6.380700588226318
Iteration 4412, Loss: 6.029712677001953
Iteration 4413, Loss: 5.938814640045166
Iteration 4414, Loss: 5.833324909210205
Iteration 4415, Loss: 6.107656002044678
Iteration 4416, Loss: 6.195791244506836
Iteration 4417, Loss: 6.007089138031006
Iteration 4418, Loss: 5.986808776855469
Iteration 4419, Loss: 5.916592597961426
Iteration 4420, Loss: 5.666855812072754
Iteration 4421, Loss: 6.0010833740234375
Iteration 4422, Loss: 5.886693000793457
Iteration 4423, Loss: 6.128612995147705
Iteration 4424, Loss: 6.044032096862793
Iteration 4425, Loss: 6.447706699371338
Iteration 4426, Loss: 5.88271951675415
Iteration 4427, Loss: 5.9329118728637695
Iteration 4428, Loss: 6.1616973876953125
Iteration 4429, Loss: 6.0687079429626465
Iteration 4430, Loss: 6.058751106262207
Iteration 4431, Loss: 6.133068561553955
Iteration 4432, Loss: 5.879368305206299
Iteration 4433, Loss: 6.290722370147705
Iteration 4434, Loss: 5.7331767082214355
Iteration 4435, Loss: 5.77498197555542
Iteration 4436, Loss: 6.311532020568848
Iteration 4437, Loss: 6.135455131530762
Iteration 4438, Loss: 5.95387601852417
Iteration 4439, Loss: 6.001777648925781
Iteration 4440, Loss: 6.010859966278076
Iteration 4441, Loss: 6.148803234100342
Iteration 4442, Loss: 6.079016208648682
Iteration 4443, Loss: 5.8497233390808105
Iteration 4444, Loss: 6.3438568115234375
Iteration 4445, Loss: 6.24003791809082
Iteration 4446, Loss: 6.001584529876709
Iteration 4447, Loss: 5.72854471206665
Iteration 4448, Loss: 6.015084743499756
Iteration 4449, Loss: 6.295701503753662
Iteration 4450, Loss: 5.869154930114746
Iteration 4451, Loss: 6.286103248596191
Iteration 4452, Loss: 5.86360502243042
Iteration 4453, Loss: 5.986353397369385
Iteration 4454, Loss: 6.174872875213623
Iteration 4455, Loss: 6.159611701965332
Iteration 4456, Loss: 6.133976936340332
Iteration 4457, Loss: 5.90103816986084
Iteration 4458, Loss: 5.707626819610596
Iteration 4459, Loss: 6.109147548675537
Iteration 4460, Loss: 6.323614120483398
Iteration 4461, Loss: 5.93526554107666
Iteration 4462, Loss: 5.8817949295043945
Iteration 4463, Loss: 6.288992881774902
Iteration 4464, Loss: 6.267014980316162
Iteration 4465, Loss: 5.823155403137207
Iteration 4466, Loss: 5.991826057434082
Iteration 4467, Loss: 6.1412672996521
Iteration 4468, Loss: 5.940482139587402
Iteration 4469, Loss: 6.04340934753418
Iteration 4470, Loss: 5.869991302490234
Iteration 4471, Loss: 6.045658588409424
Iteration 4472, Loss: 6.066404819488525
Iteration 4473, Loss: 6.356181621551514
Iteration 4474, Loss: 6.292834758758545
Iteration 4475, Loss: 6.136409282684326
Iteration 4476, Loss: 6.406904220581055
Iteration 4477, Loss: 6.112628936767578
Iteration 4478, Loss: 6.221554756164551
Iteration 4479, Loss: 6.102138996124268
Iteration 4480, Loss: 6.126859664916992
Iteration 4481, Loss: 6.193200588226318
Iteration 4482, Loss: 6.098268032073975
Iteration 4483, Loss: 5.781609535217285
Iteration 4484, Loss: 5.963953018188477
Iteration 4485, Loss: 5.907076358795166
Iteration 4486, Loss: 5.934691429138184
Iteration 4487, Loss: 5.706295490264893
Iteration 4488, Loss: 5.8235297203063965
Iteration 4489, Loss: 5.9410505294799805
Iteration 4490, Loss: 6.439737796783447
Iteration 4491, Loss: 6.19526481628418
Iteration 4492, Loss: 6.415302276611328
Iteration 4493, Loss: 5.745574951171875
Iteration 4494, Loss: 5.912744998931885
Iteration 4495, Loss: 5.932693958282471
Iteration 4496, Loss: 6.261019229888916
Iteration 4497, Loss: 5.799477577209473
Iteration 4498, Loss: 6.0271077156066895
Iteration 4499, Loss: 6.069984436035156
Rank 2 | Iteration 4500 | Training in Progress...
Iteration 4500, Loss: 6.256955146789551
Iteration 4501, Loss: 6.101079940795898
Iteration 4502, Loss: 6.251655101776123
Iteration 4503, Loss: 6.0167365074157715
Iteration 4504, Loss: 5.795766353607178
Iteration 4505, Loss: 6.274425029754639
Iteration 4506, Loss: 6.11356258392334
Iteration 4507, Loss: 6.014088153839111
Iteration 4508, Loss: 5.915438652038574
Iteration 4509, Loss: 5.887594223022461
Iteration 4510, Loss: 6.079064846038818
Iteration 4511, Loss: 6.100383281707764
Iteration 4512, Loss: 6.111489295959473
Iteration 4513, Loss: 5.978673458099365
Iteration 4514, Loss: 6.191924571990967
Iteration 4515, Loss: 6.0639801025390625
Iteration 4516, Loss: 6.17668342590332
Iteration 4517, Loss: 6.124906063079834
Iteration 4518, Loss: 6.171695232391357
Iteration 4519, Loss: 5.862729072570801
Iteration 4520, Loss: 5.9648590087890625
Iteration 4521, Loss: 6.252741813659668
Iteration 4522, Loss: 6.030351161956787
Iteration 4523, Loss: 5.816959381103516
Iteration 4524, Loss: 5.798369407653809
Iteration 4525, Loss: 5.8485331535339355
Iteration 4526, Loss: 6.253602027893066
Iteration 4527, Loss: 6.07539176940918
Iteration 4528, Loss: 6.164269924163818
Iteration 4529, Loss: 6.363051891326904
Iteration 4530, Loss: 6.420982837677002
Iteration 4531, Loss: 6.1764421463012695
Iteration 4532, Loss: 5.882926940917969
Iteration 4533, Loss: 6.161408424377441
Iteration 4534, Loss: 5.7622904777526855
Iteration 4535, Loss: 6.253021717071533
Iteration 4536, Loss: 5.971735000610352
Iteration 4537, Loss: 5.710267543792725
Iteration 4538, Loss: 6.038639068603516
Iteration 4539, Loss: 6.421845436096191
Iteration 4540, Loss: 6.103230953216553
Iteration 4541, Loss: 6.083993911743164
Iteration 4542, Loss: 6.062091827392578
Iteration 4543, Loss: 6.591080188751221
Iteration 4544, Loss: 6.539325714111328
Iteration 4545, Loss: 6.0267205238342285
Iteration 4546, Loss: 5.883223533630371
Iteration 4547, Loss: 5.722655773162842
Iteration 4548, Loss: 6.575350761413574
Iteration 4549, Loss: 6.115476608276367
Iteration 4550, Loss: 5.806413650512695
Iteration 4551, Loss: 5.781754016876221
Iteration 4552, Loss: 5.911698818206787
Iteration 4553, Loss: 6.290928363800049
Iteration 4554, Loss: 5.988277435302734
Iteration 4555, Loss: 5.907825469970703
Iteration 4556, Loss: 5.876852989196777
Iteration 4557, Loss: 6.261129856109619
Iteration 4558, Loss: 5.980179309844971
Iteration 4559, Loss: 5.997673034667969
Iteration 4560, Loss: 6.257063388824463
Iteration 4561, Loss: 5.8293375968933105
Iteration 4562, Loss: 6.2179670333862305
Iteration 4563, Loss: 6.109896659851074
Iteration 4564, Loss: 6.080677032470703
Iteration 4565, Loss: 5.827185153961182
Iteration 4566, Loss: 6.174773693084717
Iteration 4567, Loss: 6.070908069610596
Iteration 4568, Loss: 6.059927463531494
Iteration 4569, Loss: 6.147389888763428
Iteration 4570, Loss: 5.865711688995361
Iteration 4571, Loss: 5.785086154937744
Iteration 4572, Loss: 6.126551628112793
Iteration 4573, Loss: 5.8025803565979
Iteration 4574, Loss: 5.987877368927002
Iteration 4575, Loss: 6.106316566467285
Iteration 4576, Loss: 5.890863418579102
Iteration 4577, Loss: 5.971048831939697
Iteration 4578, Loss: 5.747021675109863
Iteration 4579, Loss: 5.880859851837158
Iteration 4580, Loss: 6.238121032714844
Iteration 4581, Loss: 5.9473114013671875
Iteration 4582, Loss: 5.980750560760498
Iteration 4583, Loss: 6.009637355804443
Iteration 4584, Loss: 6.0735249519348145
Iteration 4585, Loss: 6.0591936111450195
Iteration 4586, Loss: 6.123494625091553
Iteration 4587, Loss: 6.374309062957764
Iteration 4588, Loss: 5.9645843505859375
Iteration 4589, Loss: 6.14806604385376
Iteration 4590, Loss: 6.130263805389404
Iteration 4591, Loss: 6.15963077545166
Iteration 4592, Loss: 6.043196678161621
Iteration 4593, Loss: 5.821008205413818
Iteration 4594, Loss: 6.201810359954834
Iteration 4595, Loss: 5.979325294494629
Iteration 4596, Loss: 6.001561641693115
Iteration 4597, Loss: 5.922378063201904
Iteration 4598, Loss: 5.806406497955322
Iteration 4599, Loss: 6.615490436553955
Rank 2 | Iteration 4600 | Training in Progress...
Iteration 4600, Loss: 6.23801326751709
Iteration 4601, Loss: 5.625360012054443
Iteration 4602, Loss: 6.067779064178467
Iteration 4603, Loss: 5.943548679351807
Iteration 4604, Loss: 5.623979091644287
Iteration 4605, Loss: 5.917732238769531
Iteration 4606, Loss: 5.788704872131348
Iteration 4607, Loss: 6.280265808105469
Iteration 4608, Loss: 5.783017158508301
Iteration 4609, Loss: 5.866419792175293
Iteration 4610, Loss: 6.024467468261719
Iteration 4611, Loss: 6.664705753326416
Iteration 4612, Loss: 6.442551136016846
Iteration 4613, Loss: 5.880581378936768
Iteration 4614, Loss: 6.158604145050049
Iteration 4615, Loss: 5.752712726593018
Iteration 4616, Loss: 5.968296051025391
Iteration 4617, Loss: 6.0570244789123535
Iteration 4618, Loss: 5.984228610992432
Iteration 4619, Loss: 5.913663387298584
Iteration 4620, Loss: 6.135773181915283
Iteration 4621, Loss: 5.777963161468506
Iteration 4622, Loss: 6.160216808319092
Iteration 4623, Loss: 6.140997886657715
Iteration 4624, Loss: 6.060023307800293
Iteration 4625, Loss: 6.032355785369873
Iteration 4626, Loss: 6.018022537231445
Iteration 4627, Loss: 6.088293075561523
Iteration 4628, Loss: 6.166141986846924
Iteration 4629, Loss: 6.130324363708496
Iteration 4630, Loss: 5.655356407165527
Iteration 4631, Loss: 6.251857757568359
Iteration 4632, Loss: 6.120157718658447
Iteration 4633, Loss: 5.7787322998046875
Iteration 4634, Loss: 6.189393520355225
Iteration 4635, Loss: 6.364528179168701
Iteration 4636, Loss: 5.970240592956543
Iteration 4637, Loss: 6.485307693481445
Iteration 4638, Loss: 5.586147308349609
Iteration 4639, Loss: 6.025955677032471
Iteration 4640, Loss: 6.090162754058838
Iteration 4641, Loss: 6.253575325012207
Iteration 4642, Loss: 6.073301315307617
Iteration 4643, Loss: 6.243358135223389
Iteration 4644, Loss: 5.628976345062256
Iteration 4645, Loss: 6.180140495300293
Iteration 4646, Loss: 6.207699775695801
Iteration 4647, Loss: 5.796266555786133
Iteration 4648, Loss: 6.166554927825928
Iteration 4649, Loss: 6.101346015930176
Iteration 4650, Loss: 6.3066935539245605
Iteration 4651, Loss: 5.971505641937256
Iteration 4652, Loss: 5.665897369384766
Iteration 4653, Loss: 6.019205570220947
Iteration 4654, Loss: 5.908348560333252
Iteration 4655, Loss: 6.01005744934082
Iteration 4656, Loss: 6.386037349700928
Iteration 4657, Loss: 6.527019500732422
Iteration 4658, Loss: 6.616240501403809
Iteration 4659, Loss: 6.116299629211426
Iteration 4660, Loss: 6.074618339538574
Iteration 4661, Loss: 6.101140975952148
Iteration 4662, Loss: 6.089949131011963
Iteration 4663, Loss: 5.95924186706543
Iteration 4664, Loss: 5.885454177856445
Iteration 4665, Loss: 5.828072547912598
Iteration 4666, Loss: 6.013966083526611
Iteration 4667, Loss: 6.24690580368042
Iteration 4668, Loss: 6.108068943023682
Iteration 4669, Loss: 6.138584613800049
Iteration 4670, Loss: 6.108328342437744
Iteration 4671, Loss: 5.722725868225098
Iteration 4672, Loss: 6.45290470123291
Iteration 4673, Loss: 6.526939868927002
Iteration 4674, Loss: 6.1164326667785645
Iteration 4675, Loss: 6.2799553871154785
Iteration 4676, Loss: 6.210819721221924
Iteration 4677, Loss: 6.290848731994629
Iteration 4678, Loss: 5.9504780769348145
Iteration 4679, Loss: 6.000300407409668
Iteration 4680, Loss: 5.882577419281006
Iteration 4681, Loss: 6.202284812927246
Iteration 4682, Loss: 6.111121654510498
Iteration 4683, Loss: 6.25337553024292
Iteration 4684, Loss: 6.330891132354736
Iteration 4685, Loss: 6.011928558349609
Iteration 4686, Loss: 5.665170192718506
Iteration 4687, Loss: 5.814268589019775
Iteration 4688, Loss: 5.939635753631592
Iteration 4689, Loss: 6.325429916381836
Iteration 4690, Loss: 6.168959140777588
Iteration 4691, Loss: 6.105457782745361
Iteration 4692, Loss: 5.980805397033691
Iteration 4693, Loss: 5.940457820892334
Iteration 4694, Loss: 5.9840898513793945
Iteration 4695, Loss: 6.090648174285889
Iteration 4696, Loss: 5.860483169555664
Iteration 4697, Loss: 6.032878398895264
Iteration 4698, Loss: 5.87919282913208
Iteration 4699, Loss: 6.10899543762207
Rank 2 | Iteration 4700 | Training in Progress...
Iteration 4700, Loss: 5.9104228019714355
Iteration 4701, Loss: 5.92555046081543
Iteration 4702, Loss: 5.784908771514893
Iteration 4703, Loss: 6.111606121063232
Iteration 4704, Loss: 5.786746978759766
Iteration 4705, Loss: 5.707669258117676
Iteration 4706, Loss: 6.113330364227295
Iteration 4707, Loss: 5.711070537567139
Iteration 4708, Loss: 6.201022148132324
Iteration 4709, Loss: 5.796816825866699
Iteration 4710, Loss: 6.126439571380615
Iteration 4711, Loss: 5.738705635070801
Iteration 4712, Loss: 5.8431315422058105
Iteration 4713, Loss: 5.903857231140137
Iteration 4714, Loss: 5.957516193389893
Iteration 4715, Loss: 6.07972526550293
Iteration 4716, Loss: 6.20382833480835
Iteration 4717, Loss: 6.1772966384887695
Iteration 4718, Loss: 6.5167131423950195
Iteration 4719, Loss: 6.098919868469238
Iteration 4720, Loss: 5.916121959686279
Iteration 4721, Loss: 6.227308750152588
Iteration 4722, Loss: 5.880807876586914
Iteration 4723, Loss: 5.981597900390625
Iteration 4724, Loss: 5.882998943328857
Iteration 4725, Loss: 6.350058555603027
Iteration 4726, Loss: 6.1743083000183105
Iteration 4727, Loss: 6.058030605316162
Iteration 4728, Loss: 5.697445869445801
Iteration 4729, Loss: 5.7618913650512695
Iteration 4730, Loss: 6.0470290184021
Iteration 4731, Loss: 6.254612445831299
Iteration 4732, Loss: 6.122069358825684
Iteration 4733, Loss: 5.937950134277344
Iteration 4734, Loss: 6.152209281921387
Iteration 4735, Loss: 6.593130111694336
Iteration 4736, Loss: 6.471644878387451
Iteration 4737, Loss: 6.055292129516602
Iteration 4738, Loss: 6.3216657638549805
Iteration 4739, Loss: 5.971346855163574
Iteration 4740, Loss: 5.987646579742432
Iteration 4741, Loss: 6.185729026794434
Iteration 4742, Loss: 5.772655010223389
Iteration 4743, Loss: 6.268288612365723
Iteration 4744, Loss: 5.997589111328125
Iteration 4745, Loss: 6.010124206542969
Iteration 4746, Loss: 6.168428897857666
Iteration 4747, Loss: 5.96476411819458
Iteration 4748, Loss: 5.984836578369141
Iteration 4749, Loss: 6.0414862632751465
Iteration 4750, Loss: 5.804235458374023
Iteration 4751, Loss: 6.034013748168945
Iteration 4752, Loss: 6.513281345367432
Iteration 4753, Loss: 5.842284679412842
Iteration 4754, Loss: 6.152576446533203
Iteration 4755, Loss: 6.249594688415527
Iteration 4756, Loss: 5.978078365325928
Iteration 4757, Loss: 5.976646423339844
Iteration 4758, Loss: 5.964546203613281
Iteration 4759, Loss: 6.28056001663208
Iteration 4760, Loss: 5.876658916473389
Iteration 4761, Loss: 5.909426689147949
Iteration 4762, Loss: 5.918609619140625
Iteration 4763, Loss: 6.239614486694336
Iteration 4764, Loss: 5.866466045379639
Iteration 4765, Loss: 5.755361080169678
Iteration 4766, Loss: 6.1688642501831055
Iteration 4767, Loss: 5.878121376037598
Iteration 4768, Loss: 6.327406406402588
Iteration 4769, Loss: 5.873648643493652
Iteration 4770, Loss: 6.2578206062316895
Iteration 4771, Loss: 6.178219795227051
Iteration 4772, Loss: 6.407014846801758
Iteration 4773, Loss: 5.740584850311279
Iteration 4774, Loss: 6.350350856781006
Iteration 4775, Loss: 6.24541711807251
Iteration 4776, Loss: 5.904128074645996
Iteration 4777, Loss: 6.374752521514893
Iteration 4778, Loss: 6.077149868011475
Iteration 4779, Loss: 5.942430019378662
Iteration 4780, Loss: 6.115874767303467
Iteration 4781, Loss: 6.096384048461914
Iteration 4782, Loss: 6.207827091217041
Iteration 4783, Loss: 5.611867904663086
Iteration 4784, Loss: 6.1488776206970215
Iteration 4785, Loss: 6.270653247833252
Iteration 4786, Loss: 5.772904396057129
Iteration 4787, Loss: 6.1285576820373535
Iteration 4788, Loss: 6.005990982055664
Iteration 4789, Loss: 6.214172840118408
Iteration 4790, Loss: 6.232062339782715
Iteration 4791, Loss: 5.8541998863220215
Iteration 4792, Loss: 6.053772926330566
Iteration 4793, Loss: 5.887815475463867
Iteration 4794, Loss: 5.831055641174316
Iteration 4795, Loss: 6.1308088302612305
Iteration 4796, Loss: 6.137779235839844
Iteration 4797, Loss: 5.824766635894775
Iteration 4798, Loss: 6.164096832275391
Iteration 4799, Loss: 5.968628406524658
Rank 2 | Iteration 4800 | Training in Progress...
Iteration 4800, Loss: 6.397374629974365
Iteration 4801, Loss: 6.440736770629883
Iteration 4802, Loss: 5.9493727684021
Iteration 4803, Loss: 6.249687194824219
Iteration 4804, Loss: 6.263352394104004
Iteration 4805, Loss: 5.711737155914307
Iteration 4806, Loss: 6.931714057922363
Iteration 4807, Loss: 5.902834415435791
Iteration 4808, Loss: 6.171331882476807
Iteration 4809, Loss: 5.915178298950195
Iteration 4810, Loss: 6.014491558074951
Iteration 4811, Loss: 6.252805233001709
Iteration 4812, Loss: 6.044137954711914
Iteration 4813, Loss: 5.97788667678833
Iteration 4814, Loss: 6.2105712890625
Iteration 4815, Loss: 5.996409893035889
Iteration 4816, Loss: 6.2149457931518555
Iteration 4817, Loss: 5.814271450042725
Iteration 4818, Loss: 6.023159027099609
Iteration 4819, Loss: 5.873152256011963
Iteration 4820, Loss: 6.029698371887207
Iteration 4821, Loss: 6.628915786743164
Iteration 4822, Loss: 5.906504154205322
Iteration 4823, Loss: 6.0005669593811035
Iteration 4824, Loss: 5.7051472663879395
Iteration 4825, Loss: 6.132065773010254
Iteration 4826, Loss: 6.302713394165039
Iteration 4827, Loss: 5.969783782958984
Iteration 4828, Loss: 6.213342666625977
Iteration 4829, Loss: 6.026297092437744
Iteration 4830, Loss: 6.376077175140381
Iteration 4831, Loss: 6.192037582397461
Iteration 4832, Loss: 6.102359771728516
Iteration 4833, Loss: 6.209562301635742
Iteration 4834, Loss: 5.731522560119629
Iteration 4835, Loss: 6.462217330932617
Iteration 4836, Loss: 5.930556297302246
Iteration 4837, Loss: 6.126686096191406
Iteration 4838, Loss: 6.4012651443481445
Iteration 4839, Loss: 6.066622257232666
Iteration 4840, Loss: 6.184859275817871
Iteration 4841, Loss: 5.875505447387695
Iteration 4842, Loss: 5.860952377319336
Iteration 4843, Loss: 5.842871189117432
Iteration 4844, Loss: 6.08901834487915
Iteration 4845, Loss: 6.022578716278076
Iteration 4846, Loss: 6.309024333953857
Iteration 4847, Loss: 6.378704071044922
Iteration 4848, Loss: 5.7818779945373535
Iteration 4849, Loss: 5.89274263381958
Iteration 4850, Loss: 5.489249229431152
Iteration 4851, Loss: 5.946009635925293
Iteration 4852, Loss: 6.0119524002075195
Iteration 4853, Loss: 5.673027515411377
Iteration 4854, Loss: 6.170644283294678
Iteration 4855, Loss: 6.190130233764648
Iteration 4856, Loss: 6.156079292297363
Iteration 4857, Loss: 5.750998497009277
Iteration 4858, Loss: 5.8959245681762695
Iteration 4859, Loss: 6.063672065734863
Iteration 4860, Loss: 6.284111022949219
Iteration 4861, Loss: 6.062868595123291
Iteration 4862, Loss: 5.895185947418213
Iteration 4863, Loss: 5.733669281005859
Iteration 4864, Loss: 5.799400329589844
Iteration 4865, Loss: 6.06564474105835
Iteration 4866, Loss: 5.855484485626221
Iteration 4867, Loss: 6.272323131561279
Iteration 4868, Loss: 6.002286911010742
Iteration 4869, Loss: 6.699688911437988
Iteration 4870, Loss: 6.355482578277588
Iteration 4871, Loss: 5.830605506896973
Iteration 4872, Loss: 6.398157119750977
Iteration 4873, Loss: 5.727375507354736
Iteration 4874, Loss: 5.938910961151123
Iteration 4875, Loss: 5.930610656738281
Iteration 4876, Loss: 5.9918413162231445
Iteration 4877, Loss: 6.394158840179443
Iteration 4878, Loss: 6.208139896392822
Iteration 4879, Loss: 5.788809299468994
Iteration 4880, Loss: 6.297934055328369
Iteration 4881, Loss: 6.084868431091309
Iteration 4882, Loss: 6.673820972442627
Iteration 4883, Loss: 5.749980449676514
Iteration 4884, Loss: 5.964874267578125
Iteration 4885, Loss: 6.194566249847412
Iteration 4886, Loss: 6.214210033416748
Iteration 4887, Loss: 6.409974575042725
Iteration 4888, Loss: 6.205723762512207
Iteration 4889, Loss: 6.267155647277832
Iteration 4890, Loss: 5.848561763763428
Iteration 4891, Loss: 6.179050922393799
Iteration 4892, Loss: 6.026904106140137
Iteration 4893, Loss: 6.1622700691223145
Iteration 4894, Loss: 6.091684341430664
Iteration 4895, Loss: 6.181021213531494
Iteration 4896, Loss: 5.867707252502441
Iteration 4897, Loss: 5.724021911621094
Iteration 4898, Loss: 6.163992404937744
Iteration 4899, Loss: 6.327836036682129
Rank 2 | Iteration 4900 | Training in Progress...
Iteration 4900, Loss: 5.900861740112305
Iteration 4901, Loss: 6.019474029541016
Iteration 4902, Loss: 6.119273662567139
Iteration 4903, Loss: 6.063099384307861
Iteration 4904, Loss: 5.958378791809082
Iteration 4905, Loss: 5.917352199554443
Iteration 4906, Loss: 5.5787200927734375
Iteration 4907, Loss: 6.040130138397217
Iteration 4908, Loss: 5.789918899536133
Iteration 4909, Loss: 5.985818386077881
Iteration 4910, Loss: 6.280139923095703
Iteration 4911, Loss: 5.86768102645874
Iteration 4912, Loss: 5.800105094909668
Iteration 4913, Loss: 6.440836429595947
Iteration 4914, Loss: 6.5326924324035645
Iteration 4915, Loss: 6.093165874481201
Iteration 4916, Loss: 6.382477760314941
Iteration 4917, Loss: 6.484814167022705
Iteration 4918, Loss: 5.963140964508057
Iteration 4919, Loss: 5.724976062774658
Iteration 4920, Loss: 5.826470375061035
Iteration 4921, Loss: 5.837935924530029
Iteration 4922, Loss: 6.176995277404785
Iteration 4923, Loss: 6.264813423156738
Iteration 4924, Loss: 5.851831912994385
Iteration 4925, Loss: 6.3913679122924805
Iteration 4926, Loss: 6.081604480743408
Iteration 4927, Loss: 5.832131385803223
Iteration 4928, Loss: 5.97825813293457
Iteration 4929, Loss: 6.465182304382324
Iteration 4930, Loss: 6.290220260620117
Iteration 4931, Loss: 6.029295444488525
Iteration 4932, Loss: 5.91629695892334
Iteration 4933, Loss: 6.038217544555664
Iteration 4934, Loss: 5.9370269775390625
Iteration 4935, Loss: 5.842769622802734
Iteration 4936, Loss: 6.081696510314941
Iteration 4937, Loss: 5.974362373352051
Iteration 4938, Loss: 5.912919044494629
Iteration 4939, Loss: 5.982262134552002
Iteration 4940, Loss: 6.216723442077637
Iteration 4941, Loss: 6.002867221832275
Iteration 4942, Loss: 6.3321146965026855
Iteration 4943, Loss: 5.842133522033691
Iteration 4944, Loss: 6.246863842010498
Iteration 4945, Loss: 6.070128440856934
Iteration 4946, Loss: 5.648907661437988
Iteration 4947, Loss: 5.651695728302002
Iteration 4948, Loss: 6.177682876586914
Iteration 4949, Loss: 6.016268253326416
Iteration 4950, Loss: 6.375394344329834
Iteration 4951, Loss: 6.076560020446777
Iteration 4952, Loss: 6.174779415130615
Iteration 4953, Loss: 6.050570487976074
Iteration 4954, Loss: 6.125290393829346
Iteration 4955, Loss: 6.0941853523254395
Iteration 4956, Loss: 6.080591201782227
Iteration 4957, Loss: 6.6099138259887695
Iteration 4958, Loss: 6.093733310699463
Iteration 4959, Loss: 6.295057773590088
Iteration 4960, Loss: 5.824811935424805
Iteration 4961, Loss: 5.9614176750183105
Iteration 4962, Loss: 6.123578071594238
Iteration 4963, Loss: 5.8928022384643555
Iteration 4964, Loss: 5.90089225769043
Iteration 4965, Loss: 6.112960338592529
Iteration 4966, Loss: 5.82807731628418
Iteration 4967, Loss: 6.070934772491455
Iteration 4968, Loss: 5.923740863800049
Iteration 4969, Loss: 6.157120704650879
Iteration 4970, Loss: 5.933717250823975
Iteration 4971, Loss: 5.867973804473877
Iteration 4972, Loss: 5.943994998931885
Iteration 4973, Loss: 5.994139194488525
Iteration 4974, Loss: 5.927038192749023
Iteration 4975, Loss: 6.283405303955078
Iteration 4976, Loss: 6.113149166107178
Iteration 4977, Loss: 5.753361701965332
Iteration 4978, Loss: 6.022035121917725
Iteration 4979, Loss: 6.047057151794434
Iteration 4980, Loss: 6.260950565338135
Iteration 4981, Loss: 6.441160202026367
Iteration 4982, Loss: 5.839623928070068
Iteration 4983, Loss: 6.354562759399414
Iteration 4984, Loss: 5.964842319488525
Iteration 4985, Loss: 6.189680576324463
Iteration 4986, Loss: 6.097748756408691
Iteration 4987, Loss: 5.908992767333984
Iteration 4988, Loss: 6.063124656677246
Iteration 4989, Loss: 6.8368377685546875
Iteration 4990, Loss: 6.064077854156494
Iteration 4991, Loss: 5.872195243835449
Iteration 4992, Loss: 5.791341304779053
Iteration 4993, Loss: 6.026608943939209
Iteration 4994, Loss: 6.1699113845825195
Iteration 4995, Loss: 6.07983922958374
Iteration 4996, Loss: 5.658939361572266
Iteration 4997, Loss: 6.076958179473877
Iteration 4998, Loss: 5.9792985916137695
Iteration 4999, Loss: 6.245643615722656
